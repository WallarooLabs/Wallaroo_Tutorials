{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842531aa-4f9f-41fc-884e-8bce107a19ee",
   "metadata": {},
   "source": [
    "# Workshop Notebook 1: Build and Deploy a Model\n",
    "\n",
    "For this workshop, let's pretend that you work for a real estate company wants to estimate the likely value of their listings portfolio. You have developed a model to predict the sale price of properties that the company has listed, based on data collected in the company's listings database.\n",
    "\n",
    "In this set of exercises, you will build a model to predict house sale prices, and deploy it to Wallaroo.\n",
    "\n",
    "Before we start, let's load some libraries that we will need for this notebook (note that this may not be a complete list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03a96b-3d13-4d5e-9aee-99913d9a37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload needed libraries \n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# used for unique connection names\n",
    "\n",
    "import string\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0873200-de10-4822-b078-57915d1b51c6",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### Exercise: Build a model\n",
    "\n",
    "Use the house price data [here](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/notebooks_in_prod/data) to build a model to predict the sales price of homes based on the features in the data set. \n",
    "\n",
    "At the end of the exercise, you should have a notebook and possibly other artifacts to produce a model for predicting house prices. For the purposes of the exercise, please use a framework that can be converted to ONNX, such as scikit-learn or XGBoost.\n",
    "\n",
    "**Note**\n",
    "\n",
    "If you prefer to shortcut this step, you can use one of the pretrained model pickle files [here](https://drive.google.com/drive/folders/1Sg3wid53L8QDw3E9XavS55epJvFoQgiZ). **_NOTE: this link is currently internal_**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89803270-615f-4159-89c1-75f1530ca007",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blank space for training model, if needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08369f3e-757d-4f7c-aaf4-d884c5a2bcee",
   "metadata": {},
   "source": [
    "## Getting Ready to deploy\n",
    "\n",
    "Wallaroo natively supports models in the ONNX and Tensorflow frameworks, and other frameworks via containerization. For this exercise, we assume that you have a model that can be converted to the ONNX framework. The first steps to deploying in Wallaroo, then, is to convert your model to ONNX, and to add some extra functions to your processing modules so Wallaroo can call them. **_NOTE: we will want to replace this step with autoconversion when that is available_**.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Exercise: Convert your Model to ONNX\n",
    "\n",
    "Take the model that you created in the previous exercises, and convert it to ONNX. If you need help, see the [Wallaroo Conversion Tutorials](https://docs.wallaroo.ai/wallaroo-tutorials/wallaroo-tutorials-conversion-tutorials/), or other [conversion documentation](https://github.com/onnx/tutorials#converting-to-onnx-format). \n",
    "\n",
    "At the end of this exercise, you should have your model as a standalone artifact, for example, a file called `model.onnx`.\n",
    "\n",
    "**Note**\n",
    "\n",
    "If you prefer to shortcut this exercise, you can use one of the pre-converted onnx files [here](https://drive.google.com/drive/folders/1Sg3wid53L8QDw3E9XavS55epJvFoQgiZ). **_NOTE: this link is currently internal_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac6061-3e7e-4ee6-bd0d-45d9b859944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank space to load for converting model, if needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c5788-1b13-44b5-9f2c-82fdc531df78",
   "metadata": {},
   "source": [
    "## Get ready to work with Wallaroo\n",
    "\n",
    "Now that you have a model ready to go, you can log into Wallaroo and set up a **workspace** to organize your deployment artifacts. A Wallaroo workspace is place to organize the deployment artifacts for a project, and to collaborate with other team members. For more information, see [Wallaroo 101](https://docs.wallaroo.ai/wallaroo-101/). \n",
    "\n",
    "\n",
    "Logging into Wallaroo via the cluster's integrated JupyterLab is quite straightfoward:\n",
    "\n",
    "```\n",
    "# Login through local Wallaroo instance \n",
    "wl = wallaroo.Client()\n",
    "```\n",
    "See [the documentation](https://docs.wallaroo.ai/wallaroo-101/#open-a-connection-to-wallaroo) if you are logging into Wallaroo some other way.\n",
    "\n",
    "Once you are logged in, you can create a workspace and set it as your working environment. To make the first exercise easier, here is a convenience function to get or create a workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44722d-e609-45eb-b1d2-aa35db3fee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the workspace called <name>, or create it if it does not exist.\n",
    "# this function assumes your connection to wallaroo is called wl\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cb3d0-aeb1-466f-8b8c-b0e7bd591637",
   "metadata": {},
   "source": [
    "Then creating a workspace looks something like this:\n",
    "\n",
    "```\n",
    "# workspace names need to be globally unique, so add a random suffix to insure this\n",
    "# especially important if the \"main\" workspace name is potentially a common one\n",
    "\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "workspace_name = \"my-workspace\"+suffix\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "# set your current workspace to the workspace that you just created\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "# optionally, examine your current workspace\n",
    "wl.get_current_workspace()\n",
    "\n",
    "```\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Exercise: Log in and create a workspace\n",
    "\n",
    "Log into wallaroo, and create a workspace for this workshop. Make sure you remember the name that you gave the workspace, as you will need it for later notebooks. Set that workspace to be your working environment.\n",
    "\n",
    "At the end of the exercise, you should be in a new workspace to do further work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d8b69-ea17-4f5e-b477-360c418429d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blank spot to log in and create workspace to work in\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7b6f7-696f-436e-acde-2f50b361b8a1",
   "metadata": {},
   "source": [
    "## Deploy a Simple Single-Step Pipeline\n",
    "\n",
    "Once your model is in the ONNX format, and you have a workspace to work in, you can easily upload your model to Wallaroo's production platform with just a few lines of code. For example, if you have a model called `model.onnx`, and you wish to upload it to Wallaroo with the name `mymodel`, then upload the model as follows (once you are in the appropriate workspace):\n",
    "\n",
    "```\n",
    "my_model = wl.upload_model(\"mymodel\", \"model.onnx\").configure()\n",
    "```\n",
    "\n",
    "The function `upload_model()` returns a handle to the uploaded model that you will continue to work with in the SDK.\n",
    "\n",
    "Once the model has been uploaded, you can create a **pipeline** that contains the model. The pipeline is the mechanism that manages deployments. A pipeline contains a series of **steps** - sequential sets of models which take in the data from the preceding step, process it through the model, then return a result. Some pipelines can have just one step, while others may have multiple models with multiple steps or arranged for A/B testing. Deployed pipelines allocate resources and can then process data either through local files or through a **deployment URL**.\n",
    "\n",
    "So for your model to accept inferences, you must add it to a pipeline. You can create a single step pipeline called `mypipeline` as follows:\n",
    "\n",
    "```\n",
    "# create the pipeline\n",
    "my_pipeline = wl.build_pipeline(\"mypipeline\").add_model_step(my_model)\n",
    "\n",
    "# deploy the pipeline\n",
    "my_pipeline = my_pipeline.deploy()\n",
    "```\n",
    "\n",
    "Deploying the pipeline means that it is ready to accept inferences. You can \"turn off\" the pipeline with the call `pipeline.undeploy()`.\n",
    "\n",
    "**More Hints**\n",
    "\n",
    "* `workspace = wl.get_current_workspace()` gives you a handle to the current workspace\n",
    "* then `workspace.models()` will return a list of the models in the workspace\n",
    "* and `workspace.pipelines()` will return a list of the pipelines in the workspace\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Exercise: Upload and deploy your model\n",
    "\n",
    "Upload and deploy the ONNX model that you created in the previous exercise. For simplicity, do any need pre-processing in the notebook.\n",
    "\n",
    "At the end of the exercise, you should have a model and a deployed pipeline in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e706bba-f56c-410e-8a64-7f5a20484076",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank space to upload model, and create the pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee7faa-261b-4177-96b9-e41ec1f42478",
   "metadata": {},
   "source": [
    "## Sending Data to your Pipeline\n",
    "\n",
    "In order to send data to your deployed pipeline, note that ONNX models generally expect their input as an array in a dictionary, keyed by input name. In Wallaroo, the default input name is \"tensor\". So (outside of Wallaroo), an ONNX model that expected three numeric values as its input would expect input data similar to the below:\n",
    "\n",
    "```\n",
    "# one datum\n",
    "singleton = {'tensor': [[1, 2, 3]] }\n",
    "\n",
    "# two datums\n",
    "two_inputs = {'tensor': [[1, 2, 3], [4, 5, 6]] }\n",
    "```\n",
    "\n",
    "In the Wallaroo SDK, you can send a pandas data frame representation of this dictionary to the pipeline, via the `pipeline.infer()` method.\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# one datum\n",
    "sdf = pd.DataFrame(singleton)\n",
    "sdf\n",
    "#       tensor\n",
    "# 0  [1, 2, 3]\n",
    "\n",
    "# send the datum to a pipeline for inference\n",
    "result = my_pipeline.infer(sdf)\n",
    "\n",
    "# two datums\n",
    "# Note that the value of 'tensor' must be a list, not a numpy array \n",
    "twodf = pd.DataFrame(two_inputs)\n",
    "twodf\n",
    "#      tensor\n",
    "# 0  [1, 2, 3]\n",
    "# 1  [4, 5, 6]\n",
    "\n",
    "# send the data to a pipeline for inference\n",
    "result = my_pipeline.infer(twodf)\n",
    "```\n",
    "\n",
    "To send data to a pipeline via the inference URL (for example, via CURL), you need the JSON representation of these data frames.\n",
    "\n",
    "```\n",
    "sdf.to_json(orient='records')\n",
    "# '[{\"tensor\":[1,2,3]}]'\n",
    "\n",
    "twodf.to_json(orient='records')\n",
    "# '[{\"tensor\":[1,2,3]},{\"tensor\":[4,5,6]}]'\n",
    "```\n",
    "\n",
    "If the JSON data is in a file, you can send it to the pipeline from within the SDK via the `pipeline.infer_from_file()` method. \n",
    "\n",
    "In either case, a successful inference will return a data frame of inference results. The model inference(s) will be in the `column out.<outputname>`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aabfd92-23a2-4e5d-9f40-4e9265f84054",
   "metadata": {},
   "source": [
    "To help with the following exercises, here are some convenience functions you might find useful. These functions convert input data in standard tabular format (in a pandas data frame) to the pandas record format that the model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92819d28-e3ae-4f04-8b06-c45770689daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a single datum from a data frame \n",
    "# and convert it to the format the model expects\n",
    "def get_singleton(df, i):\n",
    "    singleton = df.iloc[i,:].to_numpy().tolist()\n",
    "    sdict = {'tensor': [singleton]}\n",
    "    return pd.DataFrame.from_dict(sdict)\n",
    "\n",
    "\n",
    "# pull a batch of data from a data frame\n",
    "# and convert to the format the model expects\n",
    "def get_batch(df, first=0, nrows=1):\n",
    "    last = first + nrows\n",
    "    batch = df.iloc[first:last, :].to_numpy().tolist()\n",
    "    return pd.DataFrame.from_dict({'tensor': batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901f489-f12e-4327-b0da-3e99b2838ddb",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### Exercise: Send data to your pipeline for inference.\n",
    "\n",
    "Create some test data from the housing data and send it to the pipeline that you deployed in the previous exercise.  If you used the pre-provided models, then you can use `test_data.csv`, [here](https://drive.google.com/drive/folders/1Sg3wid53L8QDw3E9XavS55epJvFoQgiZ). **_NOTE: this link is currently internal_**.\n",
    "\n",
    "* Start easy, with just one datum; retrieve the inference results. You can try small batches, as well.\n",
    "* Examine the inference results; observe what the model prediction column is called; it should be of the form `out.<outputname>`.\n",
    "\n",
    "For more hints about the different ways of sending data to the pipeline, and to see an example of the inference result format, see the [\"Running Inferences\" section of Wallaroo 101](https://docs.wallaroo.ai/wallaroo-101/#running-interfences).\n",
    "\n",
    "At the end of the exercise, you should have a set of inference results that you got through the Wallaroo pipeline. \n",
    "\n",
    "**Don't forget to undeploy your pipeline after you are done**, to free up resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5b522-8949-4c69-abf8-27191069af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  blank space to create test data, and send some data to your model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3669d-b3b4-4747-8ded-e8585f38a6e5",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have now \n",
    "\n",
    "* successfully trained a model\n",
    "* converted your model and uploaded it to Wallaroo\n",
    "* created and deployed a simple single-step pipeline\n",
    "* successfully send data to your pipeline for inference\n",
    "\n",
    "In the next notebook, you will look at two different ways to evaluate your model against the real world environment.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
