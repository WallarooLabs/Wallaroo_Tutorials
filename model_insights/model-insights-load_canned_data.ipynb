{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Insights Canned Data Loader\n",
    "\n",
    "The following Model Insights Canned Dat Loader is created to support the [Model Insights Tutorial](model-insights.ipynb).  That tutorial is best run with actual historical inference data from a Wallaroo pipeline, but for organizations that do not have access to historical inference data, this will load canned historical data into a sample workspace and pipeline with a supplied model.\n",
    "\n",
    "This loader should only be run if an organization does not have their own historical data for the Model Insights Tutorial.\n",
    "\n",
    "This loader will use the following default workspaces, pipeline and model name.  Note that if these are changed, update the [Model Insights Tutorial](model-insights.ipynb) to match.\n",
    "\n",
    "* `workspace_name` = 'housepricedrift'\n",
    "* `pipeline_name` = 'housepricepipe'\n",
    "* `model_name` = 'housepricemodel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Load Libraries\n",
    "\n",
    "The first step is to load the required libraries for the data loader.  Part of this includes the Python script `upload_data.py` that is included with this loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import joblib\n",
    "import requests\n",
    "\n",
    "import wallaroo\n",
    "import wallaroo_client\n",
    "from wallaroo.assay_config import *\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "import wallaroo.assay\n",
    "\n",
    "from upload_data import upload_data # custom code to load canned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace, Pipeline and Model\n",
    "\n",
    "Set the name of the workspace, pipeline and model that will be used to upload the canned historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'housepricedrift'\n",
    "pipeline_name = 'housepricepipe'\n",
    "model_name = 'housepricemodel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo Instance\n",
    "\n",
    "Connect with your Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the wallaroo client\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Workspace, Pipeline and Upload Model\n",
    "\n",
    "The following segments will use the existing workspace, pipeline and model with the names defined above.  If they do not exist, then they will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'houseprice-drift2', 'id': 8, 'archived': False, 'created_by': 'd962c620-c758-4c39-bce2-710d77024e38', 'created_at': '2022-06-27T19:38:19.621168+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s .... ok\n"
     ]
    }
   ],
   "source": [
    "# Get or create a pipeline. The pipeline is not executed/run/active/deployed in this demo but\n",
    "# is used to create associated assays. These names are the default names used by upload_data()\n",
    "\n",
    "try:\n",
    "    pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "except EntityNotFoundError:\n",
    "    price = wl.upload_model(model_name, 'keras_ccfraud.onnx')\n",
    "    p = wl.build_pipeline(pipeline_name)\n",
    "    p = p.add_model_step(price)\n",
    "    pipeline = p.deploy()\n",
    "    \n",
    "topic = wl.get_topic_name(pipeline.id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Canned Historical Data\n",
    "\n",
    "If there is no history of past inferences, then this historical data will be uploaded into the pipeline.  If historical data exists, then this canned historical data will **not** be uploaded.\n",
    "\n",
    "This process may take 5-10 minutes depending on the performance of your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url: http://plateau:3030/topic/workspace-8-pipeline-houseprice-pipe2-inference/partition/part-1\n",
      "PARAMS 1640995200000 {'time': '2022-01-01T00:00:00+00:00'}\n",
      "0 2022-01-01 00:00:00+00:00, 10000 2022-01-06 12:26:35.730000+00:00, 20000 2022-01-12 00:53:11.460000+00:00, 30000 2022-01-17 13:19:47.190000+00:00, 40000 2022-01-23 01:46:22.920000+00:00, 50000 2022-01-28 14:12:58.650000+00:00, \n",
      "Final: 56174 2022-01-31 23:59:12.333702+00:00\n",
      "\n",
      " Uploaded 56175 canned logs\n"
     ]
    }
   ],
   "source": [
    "# Check to see if there are any inferences at all\n",
    "past_inferences = wl.get_raw_pipeline_inference_logs(pipeline_name, datetime.fromtimestamp(0), datetime.now(), model_name, limit=1)\n",
    "if len(past_inferences) == 0:\n",
    "    canned_inference_records = joblib.load('inference_records.pkl')\n",
    "    uploaded_logs =  upload_data(canned_inference_records, pipeline = pipeline_name, model = model_name, topic=topic)\n",
    "    num_uploaded_logs = len(uploaded_logs)\n",
    "    print(f\"\\n Uploaded {num_uploaded_logs} canned logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s ................................ ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>houseprice-pipe2</td></tr><tr><th>created</th> <td>2022-06-27 19:38:20.622514+00:00</td></tr><tr><th>last_updated</th> <td>2022-06-27 19:38:20.706593+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>houseprice-model2</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'houseprice-pipe2', 'create_time': datetime.datetime(2022, 6, 27, 19, 38, 20, 622514, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'houseprice-model2', 'version': '73db3a42-ad59-4fa7-bd19-135ff58143d4', 'sha': 'bc85ce596945f876256f41515c7501c399fd97ebcb9ab3dd41bf03f8937b4507'}]}}]\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
