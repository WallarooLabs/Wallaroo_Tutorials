{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "Here we will import the libraries needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.1.0+9c085b4a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wallaroo.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrow Support\n",
    "\n",
    "As of the 2023.1 release, Wallaroo provides support for dataframe and Arrow for inference inputs.  This tutorial allows users to adjust their experience based on whether they have enabled Arrow support in their Wallaroo instance or not.\n",
    "\n",
    "If Arrow support has been enabled, `arrowEnabled=True`. If disabled or you're not sure, set it to `arrowEnabled=False`\n",
    "\n",
    "The examples below will be shown in an arrow enabled environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Only set the below to make the OS environment ARROW_ENABLED to TRUE.  Otherwise, leave as is.\n",
    "# os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "if \"ARROW_ENABLED\" not in os.environ or os.environ[\"ARROW_ENABLED\"].casefold() == \"False\".casefold():\n",
    "    arrowEnabled = False\n",
    "else:\n",
    "    arrowEnabled = True\n",
    "print(arrowEnabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "This command will be used to set up a connection to the Wallaroo cluster and allow creating and use of Wallaroo inference engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client connection from local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "# SSO login through keycloak\n",
    "\n",
    "# wallarooPrefix = \"squishy-wallaroo-6187\"\n",
    "# wallarooSuffix = \"wallaroo.dev\"\n",
    "\n",
    "# wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "#                     auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "#                     auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workspace\n",
    "\n",
    "We will create a workspace to manage our pipeline and models.  The following variables will set the name of our sample workspace then set it as the current workspace for all other commands.\n",
    "\n",
    "To allow this tutorial to be run multiple times or by multiple users in the same Wallaroo instance, a random 4 character prefix will be added to the workspace, pipeline, and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'houseprice-abtesting-nbz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'houseprice-abtesting-nbz', 'id': 101, 'archived': False, 'created_by': '3f1009e8-9726-4c1e-8e12-ee16cf375679', 'created_at': '2023-03-13T23:13:46.247093+00:00', 'models': [{'name': 'housing-control', 'versions': 4, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 3, 14, 0, 32, 44, 92612, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 3, 13, 23, 19, 59, 151078, tzinfo=tzutc())}, {'name': 'housing-challenger', 'versions': 4, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 3, 14, 0, 32, 46, 475364, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 3, 13, 23, 20, 2, 633197, tzinfo=tzutc())}], 'pipelines': [{'name': 'randomsplitpipeline-demo', 'create_time': datetime.datetime(2023, 3, 13, 23, 20, 24, 61852, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up the Champion and Challenger Models\n",
    "\n",
    "Now we upload the Champion and Challenger models to our workspace.  We will use two models:\n",
    "\n",
    "1. a random forest model `rf_model.onnx` for the champion\n",
    "2. an xgboost model `xgb_model.onnx` for the challenger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Champion Model\n",
    "\n",
    "We upload our champion model, labeled as `control`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "control =  wl.upload_model(\"housing-control\",   'models/rf_model.onnx').configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Challenger Model\n",
    "\n",
    "Now we upload the Challenger model, labeled as `challenger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger = wl.upload_model(\"housing-challenger\",   'models/xgb_model.onnx').configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Pipeline\n",
    "\n",
    "Here we will configure a pipeline with two models and set the control model with a random split chance of receiving 2/3 of the data.  Because this is a random split, it is possible for one model or the other to receive more inferences than a strict 2:1 ratio, but the more inferences are run, the more likely it is for the proper ratio split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (wl.build_pipeline(\"randomsplitpipeline-demo\")\n",
    "            .add_random_split([(2, control), (1, challenger)], \"session_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the pipeline\n",
    "\n",
    "Now we deploy the pipeline so we can run our inference through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ............. ok\n"
     ]
    }
   ],
   "source": [
    "experiment_pipeline = pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.64.2.197',\n",
       "   'name': 'engine-5779ddc65c-jxxqg',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'randomsplitpipeline-demo',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'housing-control',\n",
       "      'version': '33301a85-9982-4ecc-9602-ee9773ccae38',\n",
       "      'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'housing-challenger',\n",
       "      'version': 'c54abb74-3764-4540-b940-ff139e8845ac',\n",
       "      'sha': '31e92d6ccb27b041a324a7ac22cf95d9d6cc3aa7e8263a229f7c4aec4938657c',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.64.2.198',\n",
       "   'name': 'engine-lb-74b4969486-2wr8h',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a single inference\n",
    "Now we have our deployment set up let's run a single inference. In the results we will be able to see the inference results as well as which model the inference went to under model_id.  We'll run the inference request 5 times, with the odds are that the challenger model being run at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('housing-challenger', 'c54abb74-3764-4540-b940-ff139e8845ac')\n",
      "[array([[659806.]]), array([[7.2147857e-313]])]\n",
      "('housing-challenger', 'c54abb74-3764-4540-b940-ff139e8845ac')\n",
      "[array([[659806.]]), array([[7.2147857e-313]])]\n",
      "('housing-control', '33301a85-9982-4ecc-9602-ee9773ccae38')\n",
      "[array([[718013.6875]]), array([[7.2147857e-313]])]\n",
      "('housing-control', '33301a85-9982-4ecc-9602-ee9773ccae38')\n",
      "[array([[718013.6875]]), array([[7.2147857e-313]])]\n",
      "('housing-control', '33301a85-9982-4ecc-9602-ee9773ccae38')\n",
      "[array([[718013.6875]]), array([[7.2147857e-313]])]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "if arrowEnabled is True:\n",
    "    # use dataframe JSON files\n",
    "    for x in range(1):\n",
    "        result = experiment_pipeline.infer_from_file(\"data/xtest-1.df.json\")\n",
    "        display(result.loc[:,[\"out.split\", \"out.main\"]])        \n",
    "else:\n",
    "    # use Wallaroo JSON files\n",
    "    results.append(experiment_pipeline.infer_from_file(\"data/xtest-1.json\"))\n",
    "    results.append(experiment_pipeline.infer_from_file(\"data/xtest-1.json\"))\n",
    "    results.append(experiment_pipeline.infer_from_file(\"data/xtest-1.json\"))\n",
    "    results.append(experiment_pipeline.infer_from_file(\"data/xtest-1.json\"))\n",
    "    results.append(experiment_pipeline.infer_from_file(\"data/xtest-1.json\"))\n",
    "    for result in results:\n",
    "        print(result[0].model())\n",
    "        print(result[0].data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference Batch\n",
    "\n",
    "We will submit 1000 rows of test data through the pipeline, then loop through the responses and display which model each inference was performed in.  The results between the control and challenger should be approximately 2:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "housing-control       658\n",
       "housing-challenger    342\n",
       "Name: model, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = []\n",
    "responses =[]\n",
    "\n",
    "if arrowEnabled is True:\n",
    "    #Read in the test data as one dataframe\n",
    "    test_data = pd.read_json('data/xtest-1k.df.json')\n",
    "    # For each row, submit that row as a separate dataframe\n",
    "    # Add the results to the responses array\n",
    "    for index, row in test_data.head(1000).iterrows():\n",
    "        responses.append(experiment_pipeline.infer(row.to_frame('tensor').reset_index(drop=True)))\n",
    "    #now get our responses for each row\n",
    "    # each r is a dataframe, then get the result from out.split into json and get the model name\n",
    "    l = [json.loads(r.loc[0][\"out.split\"][0])[\"name\"] for r in responses]\n",
    "    df = pd.DataFrame({'model': l})\n",
    "    display(df.model.value_counts())\n",
    "else:\n",
    "    from data import test_data\n",
    "    for nth in range(1000):\n",
    "        responses.extend(experiment_pipeline.infer(test_data.data[nth]))\n",
    "    l = [r.raw['model_name'] for r in responses]\n",
    "    df = pd.DataFrame({'model': l})\n",
    "    display(df.model.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Challenger\n",
    "\n",
    "Now we have run a large amount of data we can compare the results.\n",
    "\n",
    "For this experiment we are looking for a significant change average predicted price between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control mean price prediction: 536026.0709773937\n",
      "challenger mean price prediction: 549229.8949195907\n"
     ]
    }
   ],
   "source": [
    "control_count = 0\n",
    "challenger_count = 0\n",
    "\n",
    "control_sum = 0\n",
    "challenger_sum = 0\n",
    "\n",
    "if arrowEnabled is True:\n",
    "    # do nothing\n",
    "    for r in responses:\n",
    "        if json.loads(r.loc[0][\"out.split\"][0])[\"name\"] == \"housing-control\":\n",
    "            control_count += 1\n",
    "            control_sum += r.loc[0][\"out.main\"][0]\n",
    "        else:\n",
    "            challenger_count += 1\n",
    "            challenger_sum += r.loc[0][\"out.main\"][0]\n",
    "else:\n",
    "    for r in responses:\n",
    "        if r.raw['model_name'] == \"housing-control\":\n",
    "            control_count += 1\n",
    "            control_sum += r.raw['outputs'][0]['Float']['data'][0]\n",
    "        else:\n",
    "            challenger_count +=1\n",
    "            challenger_sum += r.raw['outputs'][0]['Float']['data'][0]\n",
    "           \n",
    "            \n",
    "print(\"control mean price prediction: \" + str(control_sum/control_count))\n",
    "print(\"challenger mean price prediction: \" + str(challenger_sum/challenger_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Undeploy Pipeline\n",
    "\n",
    "With the testing complete, we undeploy the pipeline to return the resources back to the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s ............................................"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Undeployment did not finish within 45s.\nStatus: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaitForError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36mwait_for_undeployed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_for_undeployed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"undeployment\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mWaitForError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_wait_for\u001b[0;34m(self, poll_fn, task_name, on_iter, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWaitForError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWaitForError\u001b[0m: Undeployment did not finish within 45s.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3091/1200383124.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36mundeploy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mdeployment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deployment_for_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mdeployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36mundeploy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rehydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_undeployed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36mwait_for_undeployed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mWaitForError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{str(ex)}\\nStatus: {str(ex.status)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Undeployment did not finish within 45s.\nStatus: None"
     ]
    }
   ],
   "source": [
    "experiment_pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>randomsplitpipeline-demo</td></tr><tr><th>created</th> <td>2023-03-13 23:20:24.061852+00:00</td></tr><tr><th>last_updated</th> <td>2023-03-14 00:45:12.882103+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>9d30ef2e-9bbf-46fb-b0c6-a3b9bd7fda52, 6a902bd2-12fc-4990-8659-1409cc5dd2ef, 988a557f-7295-45f2-9b85-32eb78b20e32, 318a3608-e80f-4a0c-a394-bdf668d8a28b, 30566928-1088-4cae-a02f-19b910c15690, 6021caad-646d-4357-b0a4-f0cdaaf19ce3, 485e6a27-fb20-488d-9d7a-a8a374c0bd96, 4c6423ff-a5d2-4e02-b45e-718d02f1049c, 15158f58-a345-4342-b381-c8378a829837, e760b639-2d05-4c06-821f-3ab944f0040a, 89d9c6bf-b110-4712-a902-88d5b2bb2a9e, 1863e003-8999-40d2-a23f-31be6c39c40d</td></tr><tr><th>steps</th> <td>housing-control</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'randomsplitpipeline-demo', 'create_time': datetime.datetime(2023, 3, 13, 23, 20, 24, 61852, tzinfo=tzutc()), 'definition': \"[{'RandomSplit': {'hash_key': 'session_id', 'weights': [{'model': {'name': 'housing-control', 'version': '33301a85-9982-4ecc-9602-ee9773ccae38', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}, 'weight': 2}, {'model': {'name': 'housing-challenger', 'version': 'c54abb74-3764-4540-b940-ff139e8845ac', 'sha': '31e92d6ccb27b041a324a7ac22cf95d9d6cc3aa7e8263a229f7c4aec4938657c'}, 'weight': 1}]}}]\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
