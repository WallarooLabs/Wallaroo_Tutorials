{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-features/wallaroo-model-endpoints).\n",
    "\n",
    "## Internal Pipeline Inference URL Tutorial\n",
    "\n",
    "Wallaroo provides the ability to perform inferences through deployed pipelines via both internal and external inference URLs.  These inference URLs allow inferences to be performed by submitting data to the internal or external URL with the inference results returned in the same format as the [InferenceResult Object](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/#run-inference-through-a-pipeline).\n",
    "\n",
    "**Internal URLs** are available only through the internal Kubernetes environment hosting the Wallaroo instance as demonstrated in this tutorial.\n",
    "**External URLs** are available outside of the Kubernetes environment, such as the public internet.  These are demonstrated in the External Pipeline Deployment URL Tutorial.\n",
    "\n",
    "The following tutorial shows how to set up an environment and demonstrates how to use the Internal Deployment URL.  This example provides the following:\n",
    "\n",
    "* `alohacnnlstm.zip`:  Aloha model used as part of the [Aloha Quick Tutorial](https://docs.wallaroo.ai/wallaroo-tutorials/wallaroo-quick-start-aloha/).\n",
    "* For Arrow enabled instances:\n",
    "  * `data_1.df.json`, `data_1k.df.json` and `data_25k.df.json`:  Sample data used for testing inferences with the sample model.\n",
    "* For Arrow distabled instances:\n",
    "  * `data_1.json`, `data_1k.json` and `data_25k.json`:  Sample data used for testing inferences with the sample model.\n",
    "\n",
    "For our example, we will perform the following:\n",
    "\n",
    "* Create a workspace for our work.\n",
    "* Upload the Aloha model.\n",
    "* Create a pipeline that can ingest our submitted data, submit it to the model, and export the results.\n",
    "* Run a sample inference through our pipeline via the SDK to demonstrate the inference is accurate.\n",
    "* Run a sample inference through our pipeline's Internal URL and store the results in a file.\n",
    "\n",
    "All sample data and models are available through the [Wallaroo Quick Start Guide Samples repository](https://github.com/WallarooLabs/quickstartguide_samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a Connection to Wallaroo\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "import pandas as pd\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client connection from local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "# SSO login through keycloak\n",
    "\n",
    "# wallarooPrefix = \"YOUR PREFIX\"\n",
    "# wallarooSuffix = \"YOUR SUFFIX\"\n",
    "\n",
    "# wallarooPrefix = \"doc-test\"\n",
    "# wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "# wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "#                     auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "#                     auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrow Support\n",
    "\n",
    "As of the 2023.1 release, Wallaroo provides support for dataframe and Arrow for inference inputs.  This tutorial allows users to adjust their experience based on whether they have enabled Arrow support in their Wallaroo instance or not.\n",
    "\n",
    "If Arrow support has been enabled, `arrowEnabled=True`. If disabled or you're not sure, set it to `arrowEnabled=False`\n",
    "\n",
    "The examples below will be shown in an arrow enabled environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Only set the below to make the OS environment ARROW_ENABLED to TRUE.  Otherwise, leave as is.\n",
    "# os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "if \"ARROW_ENABLED\" not in os.environ or os.environ[\"ARROW_ENABLED\"] == \"False\":\n",
    "    arrowEnabled = False\n",
    "else:\n",
    "    arrowEnabled = True\n",
    "print(arrowEnabled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Workspace\n",
    "\n",
    "We will create a workspace to work in and call it the `urldemoworkspace`, then set it as current workspace environment.  We'll also create our pipeline in advance as `urldemopipeline`.\n",
    "\n",
    "The model to be uploaded and used for inference will be labeled as `urldemomodel`.  Modify these to your organizations requirements.\n",
    "\n",
    "Once complete, the workspace will be created or, if already existing, set to the current workspace to host the pipelines and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'urldemoworkspace'\n",
    "pipeline_name = 'urldemopipeline'\n",
    "model_name = 'urldemomodel'\n",
    "model_file_name = './alohacnnlstm.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>urldemopipeline</td></tr><tr><th>created</th> <td>2023-02-27 17:55:12.813456+00:00</td></tr><tr><th>last_updated</th> <td>2023-02-27 17:55:12.813456+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>54158104-c71d-4980-a6a3-25564c909b44</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'urldemopipeline', 'create_time': datetime.datetime(2023, 2, 27, 17, 55, 12, 813456, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the workspace is created the current default workspace with the `get_current_workspace()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'urldemoworkspace', 'id': 14, 'archived': False, 'created_by': '435da905-31e2-4e74-b423-45c38edb5889', 'created_at': '2023-02-27T17:55:11.802586+00:00', 'models': [], 'pipelines': [{'name': 'urldemopipeline', 'create_time': datetime.datetime(2023, 2, 27, 17, 55, 12, 813456, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the Models\n",
    "\n",
    "Now we will upload our models.  Note that for this example we are applying the model from a .ZIP file.  The Aloha model is a [protobuf](https://developers.google.com/protocol-buffers) file that has been defined for evaluating web pages, and we will configure it to use data in the `tensorflow` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wl.upload_model(model_name, model_file_name).configure(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy The Pipeline\n",
    "Now that we have a model that we want to use we will create a deployment for it. \n",
    "\n",
    "We will tell the deployment we are using a tensorflow model and give the deployment name and the configuration we want for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>urldemopipeline</td></tr><tr><th>created</th> <td>2023-02-27 17:55:12.813456+00:00</td></tr><tr><th>last_updated</th> <td>2023-02-27 17:56:25.368424+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>930fe54d-9503-4768-8bf9-499f72272098, 54158104-c71d-4980-a6a3-25564c909b44</td></tr><tr><th>steps</th> <td>urldemomodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'urldemopipeline', 'create_time': datetime.datetime(2023, 2, 27, 17, 55, 12, 813456, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'urldemomodel', 'version': 'a4a80d9f-dcfe-419d-becd-dbab31b65904', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_model_step(model)\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the pipeline is running and list what models are associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.0.37',\n",
       "   'name': 'engine-85c895dbbf-tfq4r',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'urldemopipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'urldemomodel',\n",
       "      'version': 'a4a80d9f-dcfe-419d-becd-dbab31b65904',\n",
       "      'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.1.12',\n",
       "   'name': 'engine-lb-ddd995646-p4nb2',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interferences\n",
    "\n",
    "### Infer 1 row\n",
    "\n",
    "Now that the pipeline is deployed and our Aloha model is in place, we'll perform a smoke test to verify the pipeline is up and running properly.  We'll use the `infer_from_file` command to load a single encoded URL into the inference engine and print the results back out.\n",
    "\n",
    "The result should tell us that the tokenized URL is legitimate (0) or fraud (1).  This sample data should return close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.text_input</th>\n",
       "      <th>out.qakbot</th>\n",
       "      <th>out.gozi</th>\n",
       "      <th>out.cryptolocker</th>\n",
       "      <th>out.pykspa</th>\n",
       "      <th>out.kraken</th>\n",
       "      <th>out.locky</th>\n",
       "      <th>out.corebot</th>\n",
       "      <th>out.ramdo</th>\n",
       "      <th>out.suppobox</th>\n",
       "      <th>out.simda</th>\n",
       "      <th>out.matsnu</th>\n",
       "      <th>out.banjori</th>\n",
       "      <th>out.main</th>\n",
       "      <th>out.ramnit</th>\n",
       "      <th>out.dircrypt</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-27 17:57:33.165</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 16, 32, 23, 29, 32, 30, 19, 26, 17]</td>\n",
       "      <td>[0.016155062]</td>\n",
       "      <td>[2.0289372e-05]</td>\n",
       "      <td>[0.012099565]</td>\n",
       "      <td>[0.008038961]</td>\n",
       "      <td>[0.0003197726]</td>\n",
       "      <td>[0.011029283]</td>\n",
       "      <td>[0.9829148]</td>\n",
       "      <td>[0.006236233]</td>\n",
       "      <td>[1.3889951e-27]</td>\n",
       "      <td>[1.793378e-26]</td>\n",
       "      <td>[0.010341615]</td>\n",
       "      <td>[0.0015195857]</td>\n",
       "      <td>[0.997564]</td>\n",
       "      <td>[0.0009985751]</td>\n",
       "      <td>[4.7591297e-05]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-02-27 17:57:33.165   \n",
       "\n",
       "                                                                                                                                                      in.text_input  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 16, 32, 23, 29, 32, 30, 19, 26, 17]   \n",
       "\n",
       "      out.qakbot         out.gozi out.cryptolocker     out.pykspa  \\\n",
       "0  [0.016155062]  [2.0289372e-05]    [0.012099565]  [0.008038961]   \n",
       "\n",
       "       out.kraken      out.locky  out.corebot      out.ramdo     out.suppobox  \\\n",
       "0  [0.0003197726]  [0.011029283]  [0.9829148]  [0.006236233]  [1.3889951e-27]   \n",
       "\n",
       "        out.simda     out.matsnu     out.banjori    out.main      out.ramnit  \\\n",
       "0  [1.793378e-26]  [0.010341615]  [0.0015195857]  [0.997564]  [0.0009985751]   \n",
       "\n",
       "      out.dircrypt  check_failures  \n",
       "0  [4.7591297e-05]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if arrowEnabled is True:\n",
    "    result = pipeline.infer_from_file('./data/data_1.df.json')\n",
    "else:\n",
    "    result = pipeline.infer_from_file(\"./data/data_1.json\")\n",
    "display(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Inference\n",
    "\n",
    "Now that our smoke test is successful, we will retrieve the Internal Deployment URL and perform an inference by submitting our data through a `curl` command as detailed below.\n",
    "\n",
    "* **IMPORTANT NOTE**:  The `_deployment._url()` method will return an **internal** URL when using Python commands from within the Wallaroo instance - for example, the Wallaroo JupyterHub service.  When connecting via an external connection, `_deployment._url()` returns an **external** URL.  External URL connections requires [the authentication be included in the HTTP request](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/), and that [Model Endpoints Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-model-endpoints-guide/) external endpoints are enabled in the Wallaroo configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doc-test.api.wallaroocommunity.ninja/v1/api/pipelines/infer/urldemopipeline-11\n",
      "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJrTzQ2VjhoQWZDZTBjWU1ETkZobEZWS25HSC1HZy1xc1JkSlhwTTNQYjBJIn0.eyJleHAiOjE2Nzc1MjA3MDIsImlhdCI6MTY3NzUyMDY0MiwiYXV0aF90aW1lIjoxNjc3NTE4MzEyLCJqdGkiOiI1NTdkZDAxYi1jNTVkLTQ0MDQtYTI5ZC01MmRlOWU0MTc2NTciLCJpc3MiOiJodHRwczovL2RvYy10ZXN0LmtleWNsb2FrLndhbGxhcm9vY29tbXVuaXR5Lm5pbmphL2F1dGgvcmVhbG1zL21hc3RlciIsImF1ZCI6WyJtYXN0ZXItcmVhbG0iLCJhY2NvdW50Il0sInN1YiI6IjQzNWRhOTA1LTMxZTItNGU3NC1iNDIzLTQ1YzM4ZWRiNTg4OSIsInR5cCI6IkJlYXJlciIsImF6cCI6InNkay1jbGllbnQiLCJzZXNzaW9uX3N0YXRlIjoiYWNlMWEzMGQtNjZiYy00NGQ5LWJkMGEtYzYyMzc0NzhmZGFhIiwiYWNyIjoiMCIsInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJkZWZhdWx0LXJvbGVzLW1hc3RlciIsIm9mZmxpbmVfYWNjZXNzIiwidW1hX2F1dGhvcml6YXRpb24iXX0sInJlc291cmNlX2FjY2VzcyI6eyJtYXN0ZXItcmVhbG0iOnsicm9sZXMiOlsibWFuYWdlLXVzZXJzIiwidmlldy11c2VycyIsInF1ZXJ5LWdyb3VwcyIsInF1ZXJ5LXVzZXJzIl19LCJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiJhY2UxYTMwZC02NmJjLTQ0ZDktYmQwYS1jNjIzNzQ3OGZkYWEiLCJlbWFpbF92ZXJpZmllZCI6ZmFsc2UsImh0dHBzOi8vaGFzdXJhLmlvL2p3dC9jbGFpbXMiOnsieC1oYXN1cmEtdXNlci1pZCI6IjQzNWRhOTA1LTMxZTItNGU3NC1iNDIzLTQ1YzM4ZWRiNTg4OSIsIngtaGFzdXJhLWRlZmF1bHQtcm9sZSI6InVzZXIiLCJ4LWhhc3VyYS1hbGxvd2VkLXJvbGVzIjpbInVzZXIiXSwieC1oYXN1cmEtdXNlci1ncm91cHMiOiJ7fSJ9LCJuYW1lIjoiSm9obiBIYW5zYXJpY2siLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJqb2huLmh1bW1lbEB3YWxsYXJvby5haSIsImdpdmVuX25hbWUiOiJKb2huIiwiZmFtaWx5X25hbWUiOiJIYW5zYXJpY2siLCJlbWFpbCI6ImpvaG4uaHVtbWVsQHdhbGxhcm9vLmFpIn0.QTTxK6rE-SZIBR7z7hN1aIsGSsPYmBmuI-KxsmwzATjrCtOLO3ObE5YtBye3ITXkG4NAVN3c2llTSzrYLDeBMcsz17_T8UdSpwOVsDeTko-muhzQkcMnUrXGLsJDiOofS3ZT-_S66-IrCfGUD2D1Gj7ufbAnMipyTuE69L1QBEdoszcRfTR-epCqniayB3s6SkhBSgjmgvJcmMSIHxj3zg0siZAjQoxM6_E5GO_o__91p7FiADa0FH3xCmT9iOMM1NcF7FheBNX7xCXBBWekiy9bpB0BQISvMi1IcVCGeMZnTyO1o9ZgFbV5MG-SoKFyZrYUmhBf-JoRjecv1FYgIg\n"
     ]
    }
   ],
   "source": [
    "inference_url = pipeline._deployment._url()\n",
    "print(inference_url)\n",
    "connection =wl.mlops().__dict__\n",
    "token = connection['token']\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arrowEnabled is True:\n",
    "    dataFile=\"./data/data_25k.df.json\"\n",
    "    contentType=\"application/json; format=pandas-records\"\n",
    "else:\n",
    "    dataFile=\"./data/data_25k.json\"\n",
    "    contentType=\"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 34.3M  100 16.3M  100 18.0M   895k   988k  0:00:18  0:00:18 --:--:--  538k\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST {inference_url} -H \"Authorization: Bearer {token}\" -H \"Content-Type:{contentType}\" --data @{dataFile} > curl_response.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy Pipeline\n",
    "\n",
    "When finished with our tests, we will undeploy the pipeline so we have the Kubernetes resources back for other tasks.\n",
    "\n",
    "**IMPORTANT NOTE**:  For the External Pipeline Deployment URL Tutorial, this pipeline will have to be deployed to make the External Deployment URL available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>urldemopipeline</td></tr><tr><th>created</th> <td>2023-02-27 17:55:12.813456+00:00</td></tr><tr><th>last_updated</th> <td>2023-02-27 17:56:25.368424+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>930fe54d-9503-4768-8bf9-499f72272098, 54158104-c71d-4980-a6a3-25564c909b44</td></tr><tr><th>steps</th> <td>urldemomodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'urldemopipeline', 'create_time': datetime.datetime(2023, 2, 27, 17, 55, 12, 813456, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'urldemomodel', 'version': 'a4a80d9f-dcfe-419d-becd-dbab31b65904', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrowtests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
