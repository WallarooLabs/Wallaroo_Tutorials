{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b00150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import datetime, timedelta, timezone, tzinfo\n",
    "import joblib\n",
    "import pytz\n",
    "import json\n",
    "import wallaroo\n",
    "import wallaroo.assay_config\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "import wallaroo.assay\n",
    "from wallaroo.assay_config import BinMode, Aggregation, Metric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "from upload_arrow_data import upload_arrow_data\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1abb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_color(status):\n",
    "    if status == \"Ok\":\n",
    "        return \"green\"\n",
    "    elif status == \"Warning\":\n",
    "        return \"orange\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "    \n",
    "def create_legend():\n",
    "    ok_patch = mpatches.Patch(color='green', label='Status Ok')\n",
    "    warning_patch = mpatches.Patch(color='orange', label='Warning')\n",
    "    alert_patch = mpatches.Patch(color='red', label='Alert')\n",
    "    plt.legend(handles=[ok_patch, warning_patch, alert_patch])\n",
    "    \n",
    "def pick_colors(s):\n",
    "    return [status_color(status) for status in s]\n",
    "\n",
    "def extract_arrow_prediction(t):\n",
    "    return t['out']['dense_2'][0]\n",
    "\n",
    "def extract_arrow_prediction_nested(t):\n",
    "    return t['out.dense_2'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d735ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DEPLOYMENT_CONFIG'] = json.dumps({\"cpus\": 0.1, \"replica_count\": 1, \"memory\": \"100Mi\"})\n",
    "if os.environ.get(\"WALLAROO_SDK_CREDENTIALS\"):\n",
    "    auth_type=\"user_password\"\n",
    "else:\n",
    "    auth_type=\"none\"\n",
    "auth_type = \"sso\"\n",
    "client = wallaroo.Client(auth_type=auth_type, request_timeout=90, interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c5ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy a model/pipeline\n",
    "\n",
    "rand_id = f\"{np.random.randint(10000):05d}\"\n",
    "pipeline_name = 'modelinsightse2e' + rand_id\n",
    "model_name = 'baseline' + rand_id\n",
    "\n",
    "onnx_file_model_name = \"house_price_keras.onnx\"\n",
    "\n",
    "fraud = client.upload_model(model_name, onnx_file_model_name).configure('onnx')\n",
    "pipeline = client.build_pipeline(pipeline_name)\n",
    "pipeline = pipeline.add_model_step(fraud)\n",
    "deployment = pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3179043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = client.pipelines_by_name(pipeline_name)\n",
    "assert(len(pipelines) == 1)\n",
    "pipeline = pipelines[0]\n",
    "pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = client.get_topic_name(pipeline.id())\n",
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load canned data into notebook\n",
    "X_val = joblib.load(\"X_val.pkl\")\n",
    "canned_inference_records = joblib.load('inference_records.pkl')\n",
    "len(canned_inference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out some of the data\n",
    "\n",
    "canned_inference_records = [r for i,r in enumerate(canned_inference_records) if i % 10 == 0]\n",
    "len(canned_inference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_logs = upload_arrow_data(canned_inference_records, pipeline_name, model_name, topic=topic)\n",
    "num_uploaded_logs = len(uploaded_logs)\n",
    "print(f\"\\n Uploaded {num_uploaded_logs} canned logs\")\n",
    "uploaded_logs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e93c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we can query that data\n",
    "day1 = dt.datetime(2022, 1,1, 0, 0, 0, 0, pytz.UTC)\n",
    "day2 = dt.datetime(2022, 1,2, 0, 0, 0, 0, pytz.UTC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some test inferences\n",
    "num_test_inferences = 10\n",
    "inference_start = dt.datetime.now()\n",
    "for i in range(num_test_inferences):\n",
    "    data = pd.DataFrame.from_dict({\"tensor\": [X_val[i].tolist()]})\n",
    "    res = deployment.infer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fe0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual\n",
    "canned_inference_records[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure they extract correctly.ie are numbers. Don't think they should be the same\n",
    "# need to check on that.\n",
    "assert isinstance(extract_arrow_prediction_nested(res), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1df3c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JAMIESKIP\n",
    "# This can be fleshed out to check the structure of the two records better.\n",
    "# def inferences_match(i1, i2):\n",
    "#     return i1.keys() == i2.keys()\n",
    "\n",
    "\n",
    "# sample = res.loc[0,:]\n",
    "# canned_sample =  canned_inference_records[0]\n",
    "\n",
    "# assert inferences_match(sample, canned_sample)\n",
    "\n",
    "# for key in sample.keys():\n",
    "#     assert type(sample[key]) == type(canned_sample[key]), f\"{key} is not the same {type(sample[key])} {type(canned_sample[key])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inference logs we just created through the api-lb using just the topic\n",
    "# Logs can take a bit to get to plateau\n",
    "import time\n",
    "\n",
    "logs = client.get_raw_logs(topic, start=inference_start, end=dt.datetime.now(), parse=True)\n",
    "counter = 0\n",
    "while len(logs) < num_test_inferences and counter < 10:\n",
    "    time.sleep(5)\n",
    "    counter += 1\n",
    "    print(len(logs))\n",
    "    logs = client.get_raw_logs(topic, start=inference_start, end=dt.datetime.now(), parse=True)\n",
    "assert len(logs) == num_test_inferences\n",
    "# assert inferences_match(res[0].raw, logs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(client.get_raw_pipeline_inference_logs(topic, inference_start, dt.datetime.now(), model_name)) == num_test_inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(client.get_raw_pipeline_inference_logs(topic, inference_start, dt.datetime.now(), \"FOOBAR\")) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = client.get_pipeline_inference_dataframe(topic, inference_start, dt.datetime.now(), model_name)\n",
    "assert df.shape[0] == num_test_inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_start = datetime.fromisoformat('2022-01-01T00:00:00+00:00')\n",
    "baseline_end = datetime.fromisoformat('2022-01-02T00:00:00+00:00')\n",
    "last_day = datetime.fromisoformat('2022-02-01T00:00:00+00:00')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b5f70-adb3-4c72-85ad-0bdb97806b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inferences = client.get_raw_pipeline_inference_logs(topic, baseline_start, last_day, model_name, limit=1_000_000)\n",
    "baseline_inferences = client.get_raw_pipeline_inference_logs(topic, baseline_start, baseline_end, model_name, limit=1_000_000)\n",
    "\n",
    "assert len(all_inferences) == num_uploaded_logs\n",
    "assert len(baseline_inferences) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes from the inferences\n",
    "\n",
    "all_preds = pd.DataFrame({\"all_preds\" : [extract_arrow_prediction(t) for _, t in all_inferences.iterrows()]})\n",
    "baseline_preds = pd.DataFrame({\"baseline_preds\" : [extract_arrow_prediction(t)for _, t in baseline_inferences.iterrows()]})\n",
    "\n",
    "min_pred = all_preds.min()[0]\n",
    "max_pred = all_preds.max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_name = f\"Test Assay {rand_id}\"\n",
    "assay_builder = client.build_assay(assay_name, pipeline, model_name, day1, day2)\n",
    "print(assay_builder.build().to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31795144-8d63-45f7-ba94-36b68ee2e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_pipeline_inference_dataframe(client.get_topic_name(assay_builder.pipeline_id), assay_builder.baseline_builder.start, assay_builder.baseline_builder.end, assay_builder.baseline_builder.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_builder.baseline_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa288da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_builder.baseline_kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_builder.baseline_ecdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_id = assay_builder.upload()\n",
    "assay_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1db59-fea7-4842-bc39-9f980d334681",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = client.get_assay_results(assay_id, day1, datetime.now(timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b2d4e-8624-4000-b6d9-36f00e428678",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd30c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sleep = 90\n",
    "elapsed_sleep = 0\n",
    "sleep_interval = 3\n",
    "\n",
    "assay_start = day1\n",
    "while elapsed_sleep <= max_sleep:\n",
    "    assay_results = client.get_assay_results(assay_id, day1, datetime.now(timezone.utc))\n",
    "    if len(assay_results) == 30:\n",
    "        break\n",
    "    time.sleep(sleep_interval)\n",
    "    elapsed_sleep += sleep_interval\n",
    "    \n",
    "print(f\"results available in <{elapsed_sleep} seconds, length {len(assay_results)}\")\n",
    "assert len(assay_results) == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_results[0].raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assay_results.to_dataframe()\n",
    "assert len(df) == len(assay_results)\n",
    "df\n",
    "\n",
    " # Test that df conversion worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34731abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_results[0].raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36cd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_results[0].chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_results[1].chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_results[1].compare_basic_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = assay_results[1].compare_bins()\n",
    "print(f\"Sum of absolute value of differences as percentage per bin {comparison.diff_in_pcts.abs().sum():5.3f}\")\n",
    "\n",
    "assert type(comparison) == pd.DataFrame\n",
    "assert len(comparison) > 0\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff884445",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_config = client.build_assay(\"Input Assay\", pipeline, model_name, day1, day2).add_run_until(last_day).build()\n",
    "ardf = assay_config.interactive_run().to_dataframe()\n",
    "assert ardf.shape[0] > 0\n",
    "assert ardf.shape[1] > 0\n",
    "ardf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_builder = client.build_assay(assay_name, pipeline, model_name, baseline_start, baseline_end)\n",
    "assay_builder = assay_builder.add_run_until(last_day)\n",
    "\n",
    "assay_builder.window_builder().add_width(hours=24).add_interval(hours=12)\n",
    "\n",
    "assay_config = assay_builder.build()\n",
    "\n",
    "assay_results = assay_config.interactive_run()\n",
    "assay_results.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915ca2e-010f-469f-b95a-dfdbf20c2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(assay_results) == 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fad81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_start = datetime.fromisoformat('2022-01-03T00:00:00+00:00')\n",
    "\n",
    "assay_builder = client.build_assay(assay_name, pipeline, model_name, baseline_start, baseline_end)\n",
    "assay_builder = assay_builder.add_run_until(last_day)\n",
    "\n",
    "assay_builder.window_builder().add_width(weeks=1).add_interval(weeks=1).add_start(report_start)\n",
    "\n",
    "assay_config = assay_builder.build()\n",
    "\n",
    "assay_results = assay_config.interactive_run()\n",
    "assert len(assay_results) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb1f5f-9eb5-4334-9701-657a8e968a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['bedrooms', 'bathrooms', 'lat', 'long', 'waterfront', 'sqft_living', 'sqft_lot', 'floors', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "assay_builder = client.build_assay(\"Input Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.window_builder().add_width(hours=4)\n",
    "assay_config = assay_builder.build()\n",
    "assay_results = assay_config.interactive_input_run(all_inferences, labels)\n",
    "iadf = assay_results.to_dataframe()\n",
    "assert len(iadf) > 0\n",
    "iadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d44f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_ok = iadf[iadf.status != \"Ok\"]\n",
    "assert len(not_ok) > 0\n",
    "not_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal bins vs quantiles\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_bin_mode(BinMode.EQUAL)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (7, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User provided edges\n",
    "edges = [11.0, 12.0, 13.0, 14.0, 15.0, 16.0]\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_bin_mode(BinMode.PROVIDED, edges)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (7, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01342b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of bins\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_bin_mode(BinMode.QUANTILE).add_num_bins(10)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (12, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin weights\n",
    "weights = [0] * 6\n",
    "weights.extend([1] * 6)\n",
    "\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_bin_mode(BinMode.QUANTILE).add_num_bins(10).add_bin_weights(weights)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (12, 9)\n",
    "assert ar.score > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  metrics\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_metric(Metric.SUMDIFF)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (7, 9)\n",
    "assert ar.score > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270de238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  metrics\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_metric(Metric.MAXDIFF)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (7, 9)\n",
    "assert ar.score > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d329b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_aggregation(Aggregation.DENSITY)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (7, 9)\n",
    "assert ar.score > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation\n",
    "assay_builder = client.build_assay(\"Test Assay\", pipeline, model_name, day1, day2).add_run_until(last_day)\n",
    "assay_builder.summarizer_builder.add_aggregation(Aggregation.CUMULATIVE)\n",
    "assay_results = assay_builder.build().interactive_run()\n",
    "ar = assay_results[0]\n",
    "df = ar.compare_bins()\n",
    "assert df.shape == (7, 9)\n",
    "assert ar.score > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38575c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c804e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipeline in client.list_pipelines():\n",
    "    pipeline.undeploy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeec1e5-f5e1-4cbf-aa25-1f39dcb8a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fc45f-4bbb-4360-9765-4464585d8a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
