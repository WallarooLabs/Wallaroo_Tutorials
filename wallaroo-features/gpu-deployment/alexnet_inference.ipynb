{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Pipeline Deployment Tutorial\n",
    "\n",
    "The following tutorial demonstrates how to allocate GPU resources in a cluster to a Wallaroo pipeline for models that require GPUs.  This tutorial is based on the Wallaroo SDK 2023.2.1 [Wallaroo SDK Essentials Guide: Pipeline Deployment Configuration](https://staging.docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/).\n",
    "\n",
    "The sample model used is the [AlexNet PyTorch model](https://pytorch.org/hub/pytorch_vision_alexnet/) that performs large scale image recognition.  The data used in this sample is \"toy\" data and is only used to demonstrate a sample inference using this model.\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "This tutorial will demonstrate:\n",
    "\n",
    "1. Allocating GPU resources for a containerized model in a Wallaroo pipeline.  The AlexNet model used in this demonstration requires a GPU for execution.\n",
    "1. Deploying the pipeline and running a sample inference.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "The following is required for this tutorial:\n",
    "\n",
    "* A Wallaroo Enterprise version 2023.2.1 or greater instance installed into a  GPU enabled Kubernetes cluster as described in the [Wallaroo Create GPU Nodepools Kubernetes Clusters guide](https://staging.docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-install-guides/wallaroo-install-configurations/wallaroo-gpu-nodepools/).\n",
    "* The Wallaroo SDK version 2023.2.1 or greater.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Deployment Configuration](https://staging.docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/)\n",
    "* [Wallaroo SDK Reference wallaroo.deployment_config](https://staging.docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-reference-guide/deployment_config/)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import Library\n",
    "\n",
    "The first step will be to import the various libraries used for this tutorial.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.pipeline import Pipeline\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "import pyarrow as pa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance through the User Interface\n",
    "\n",
    "The next step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Tutorial Variables\n",
    "\n",
    "The following variables are used through the tutorial to create the workspace and pipeline.  The helper methods below will either create the workspace and pipeline, or use existing ones if they have already been created.\n",
    "\n",
    "Workspace names must be unique across a Wallaroo instance.  The following code will create a random 4 character suffix to the workspace name to allow this workspace to be run by multiple users across a Wallaroo instance without attempting to create a workspace with the same name.  Users are encouraged to set their own workspace names if they desire to reuse the same workspaces for other needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "# make a random 4 character suffix to prevent overwriting other user's workspaces\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "workspace_name = f'gpudemonstrationworkspace{suffix}'\n",
    "pipeline_name = f'gpudemonstrationpipeline'\n",
    "model_name = f'alexnetmodel'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name, workspace):\n",
    "    pipelines = workspace.pipelines()\n",
    "    pipe_filter = filter(lambda x: x.name() == name, pipelines)\n",
    "    pipes = list(pipe_filter)\n",
    "    # we can't have a pipe in the workspace with the same name, so it's always the first\n",
    "    if pipes:\n",
    "        pipeline = pipes[0]\n",
    "    else:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Retrieve the Workspace\n",
    "\n",
    "We will create the workspace for this tutorial and set it in the current workspace.  All pipelines and models added in the code below will be set with this workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Import and Output Schemas\n",
    "\n",
    "The AlexNet ML Model used in this example is containerized in [MLFlow 1.3.0 format](https://mlflow.org/docs/1.3.0/python_api/mlflow.html).  Wallaroo requires MLFlow models registered in a Wallaroo instance to include the input schema from the Apache Arrow `pyarrow.lib.Schema` format.\n",
    "\n",
    "Reference:  [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: MLFlow](https://staging.docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-registration-mlflow/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('inputs', pa.list_(\n",
    "        pa.list_(\n",
    "            pa.list_(\n",
    "                pa.int64(),\n",
    "                list_size=224\n",
    "            ),\n",
    "            list_size=224\n",
    "        ),\n",
    "        list_size=3\n",
    "    )),\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('prediction', pa.list_(pa.float64(), list_size=1000)),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Model\n",
    "\n",
    "The sample AlexNet model is stored in a containerized model registry.  It is made publicly available through the Wallaroo Tutorials GitHub Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = wl.register_model_image(\n",
    "    name=\"alexnet-cuda\",\n",
    "    image=f\"ghcr.io/wallaroolabs/wallaroo_tutorials/alexnet-gpu:1.30\"\n",
    ").configure(\"mlflow\", input_schema=input_schema, output_schema=output_schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pipeline and Allocate GPU Resources\n",
    "\n",
    "The pipeline will now be created with the registered model added as a model step.\n",
    "\n",
    "A pipeline deployment configuration is created with the following attributes:\n",
    "\n",
    "* Native Runtimes:  These are models that run directly in the Wallaroo engine.  The following resource are allocated to this pipeline for native runtimes:\n",
    "  * CPU:  `0.25`\n",
    "  * RAM:  `1Gi`\n",
    "  * GPUs: 0 .  As there are no native runtimes added to this pipeline that require a GPU, we do not have to allocate a GPU.\n",
    "* Containerized Runtimes:  These are models that are containerized, such as MLFlow as Docker containers.\n",
    "  * AlexNet Model:\n",
    "    * GPUs: 1\n",
    "\n",
    "GPUs can only be allocated a entire integer units from the GPU enabled nodepools.  Organizations should be aware of how many GPUs are allocated to the cluster.  If all GPUs are already allocated to other pipelines, or if there are not enough GPUs to fulfill the request, the pipeline deployment will fail and return an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = wl.build_pipeline(pipeline_name)\n",
    "pipeline.add_model_step(model)\n",
    "\n",
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(0.25).memory('1Gi').gpus(0) \\\n",
    "    .sidekick_gpus(model, 1) \\\n",
    "    .sidekick_env(model, {\"GUNICORN_CMD_ARGS\": \"--timeout=180 --workers=1\"}) \\\n",
    "    .build()\n",
    "\n",
    "deployment_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "With the configuration set, we will deploy the pipeline and allocate resources from the cluster to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Inference\n",
    "\n",
    "A sample inference will be run.  This is toy data, and is only used to verify that the inference is performed through the deployed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = {\n",
    "#         \"inputs\": [np.random.randint(0, 256, (3, 224, 224), dtype=np.uint8)] * 2, # required\n",
    "# }\n",
    "# dataframe = pd.DataFrame(input_data)\n",
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.infer_from_file('./data/test_alexnet_gpu.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy Pipeline\n",
    "\n",
    "With the tutorial complete, the pipeline is undeployed to return the resources back to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce3158ddcd7010e2c9cd39648949ee492f260c114962bfb591dc4ee145ba89f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
