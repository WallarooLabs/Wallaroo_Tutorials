{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/2023.2.1_prerelease/wallaroo-features/pipeline_multiple_replicas_forecast_tutorial).\n",
    "\n",
    "## Statsmodel Forecast with Wallaroo Features: ML Workload Orchestration\n",
    "\n",
    "This tutorial series demonstrates how to use Wallaroo to create a Statsmodel forecasting model based on bike rentals.  This tutorial series is broken down into the following:\n",
    "\n",
    "* Create and Train the Model:  This first notebook shows how the model is trained from existing data.\n",
    "* Deploy and Sample Inference:  With the model developed, we will deploy it into Wallaroo and perform a sample inference.\n",
    "* Parallel Infer:  A sample of multiple weeks of data will be retrieved and submitted as an asynchronous parallel inference.  The results will be collected and uploaded to a sample database.\n",
    "* External Connection:  A sample data connection to Google BigQuery to retrieve input data and store the results in a table.\n",
    "* ML Workload Orchestration:  Take all of the previous steps and automate the request into a single Wallaroo ML Workload Orchestration.\n",
    "\n",
    "This step will expand upon using the Connection and create a ML Workload Orchestration that automates requesting the inference data, submitting it in parallel, and storing the results into a database table.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A Wallaroo instance version 2023.2.1 or greater.\n",
    "* Install the libraries from `./resources/requirements.txt` that include the following:\n",
    "  * google-cloud-bigquery==3.10.0\n",
    "  * google-auth==2.17.3\n",
    "  * db-dtypes==1.1.1\n",
    "\n",
    "## References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Wallaroo SDK Essentials: Inference Guide: Parallel Inferences](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/#parallel-inferences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrations, Taks, and Tasks Runs\n",
    "\n",
    "We've details how Wallaroo Connections work.  Now we'll use Orchestrations, Tasks, and Task Runs.\n",
    "\n",
    "| Item | Description |\n",
    "|---|---|\n",
    "| Orchestration | ML Workload orchestration allows data scientists and ML Engineers to automate and scale production ML workflows in Wallaroo to ensure a tight feedback loop and continuous tuning of models from training to production. Wallaroo platform users (data scientists or ML Engineers) have the ability to deploy, automate and scale recurring batch production ML workloads that can ingest data from predefined data sources to run inferences in Wallaroo, chain pipelines, and send inference results to predefined destinations to analyze model insights and assess business outcomes. |\n",
    "| Task | An implementation of an Orchestration.  Tasks can be either `Run Once`:  They run once and upon completion, stop. `Run Scheduled`: The task runs whenever a specific `cron` like schedule is reached.  Scheduled tasks will run until the `kill` command is issued. |\n",
    "| Task Run | The execusion of a task.  For `Run Once` tasks, there will be only one `Run Task`.  A `Run Scheduled` tasks will have multiple tasks, one for every time the schedule parameter is met.  Task Runs have their own log files that can be examined to track progress and results. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel Forecast Connection Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from resources import simdb\n",
    "from resources import util\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# for Big Query connections\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import db_dtypes\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.3.0+785595cda'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wallaroo.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize connection\n",
    "\n",
    "Start a connect to the Wallaroo instance and save the connection into the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below.\n",
    "\n",
    "Workspace names must be unique.  To allow this tutorial to run in the same Wallaroo instance for multiple users, the `suffix` variable is generated from a random set of 4 ASCII characters.  To use the same workspace across the tutorial notebooks, hard code `suffix` and verify the workspace name created is is unique across the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for unique connection names\n",
    "\n",
    "import string\n",
    "import random\n",
    "\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "\n",
    "workspace_name = f'multiple-replica-forecast-tutorial-{suffix}'\n",
    "pipeline_name = 'bikedaypipe'\n",
    "connection_name = f'statsmodel-bike-rentals-{suffix}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "The workspace will be either used or created if it does not exist, along with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "The pipeline is already set witht the model.  For our demo we'll verify that it's deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s .................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bikedaypipe</td></tr><tr><th>created</th> <td>2023-06-30 15:42:56.781150+00:00</td></tr><tr><th>last_updated</th> <td>2023-06-30 15:45:23.267621+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>6552b04e-d074-4773-982b-a2885ce6f9bf, b884c20c-c491-46ec-b438-74384a963acc, 4e8d2a88-1a41-482c-831d-f057a48e18c1</td></tr><tr><th>steps</th> <td>bikedaymodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bikedaypipe', 'create_time': datetime.datetime(2023, 6, 30, 15, 42, 56, 781150, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bikedaymodel', 'version': 'd60ceac2-6fed-4bef-afd1-f3880ad85d0c', 'sha': '525ea2be4402725878382631c2c32b2e3f105bf78eedf41f3ac6d71c0dfa986b'}]}}]\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the deployment to allow for additional engines to run\n",
    "deploy_config = (wallaroo.DeploymentConfigBuilder()\n",
    "                        .replica_count(4)\n",
    "                        .cpus(0.25)\n",
    "                        .memory(\"512Mi\")\n",
    "                        .build()\n",
    "                    )\n",
    "\n",
    "pipeline.deploy(deployment_config = deploy_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery Sample Orchestration\n",
    "\n",
    "The orchestration that will automate this process is `./resources/forecast-bigquer-orchestration.zip`.  The files used are stored in the directory `forecast-bigquery-orchestration`, created with the command:\n",
    "\n",
    "`zip -r forecast-bigquery-connection.zip main.py requirements.txt`.\n",
    "\n",
    "This contains the following:\n",
    "\n",
    "* `requirements.txt`:  The Python requirements file to specify the following libraries used:\n",
    "\n",
    "```python\n",
    "google-cloud-bigquery==3.10.0\n",
    "google-auth==2.17.3\n",
    "db-dtypes==1.1.1\n",
    "```\n",
    "\n",
    "* `main.py`: The entry file that takes the previous statsmodel BigQuery connection and statsmodel Forecast model and uses it to predict the next month's sales based on the previous month's performance.  The details are listed below.  Since we are using the async `parallel_infer`, we'll use the `asyncio` library to run our sample `main` method.\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import asyncio\n",
    "\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# for Big Query connections\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import db_dtypes\n",
    "\n",
    "import time\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    wl = wallaroo.Client()\n",
    "\n",
    "    # get the arguments\n",
    "    arguments = wl.task_args()\n",
    "\n",
    "    if \"workspace_name\" in arguments:\n",
    "        workspace_name = arguments['workspace_name']\n",
    "    else:\n",
    "        workspace_name=\"multiple-replica-forecast-tutorial\"\n",
    "\n",
    "    if \"pipeline_name\" in arguments:\n",
    "        pipeline_name = arguments['pipeline_name']\n",
    "    else:\n",
    "        pipeline_name=\"bikedaypipe\"\n",
    "\n",
    "    if \"bigquery_connection_input_name\" in arguments:\n",
    "        bigquery_connection_name = arguments['bigquery_connection_input_name']\n",
    "    else:\n",
    "        bigquery_connection_name = \"statsmodel-bike-rentals\"\n",
    "\n",
    "    print(bigquery_connection_name)\n",
    "    def get_workspace(name):\n",
    "        workspace = None\n",
    "        for ws in wl.list_workspaces():\n",
    "            if ws.name() == name:\n",
    "                workspace= ws\n",
    "        return workspace\n",
    "\n",
    "    def get_pipeline(name):\n",
    "        try:\n",
    "            pipeline = wl.pipelines_by_name(name)[0]\n",
    "        except EntityNotFoundError:\n",
    "            print(f\"Pipeline not found:{name}\")\n",
    "        return pipeline\n",
    "\n",
    "    print(f\"BigQuery Connection: {bigquery_connection_name}\")\n",
    "    forecast_connection = wl.get_connection(bigquery_connection_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Workspace: {workspace_name}\")\n",
    "    workspace = get_workspace(workspace_name)\n",
    "\n",
    "    wl.set_current_workspace(workspace)\n",
    "    print(workspace)\n",
    "\n",
    "    # the pipeline is assumed to be deployed\n",
    "    print(f\"Pipeline: {pipeline_name}\")\n",
    "    pipeline = get_pipeline(pipeline_name)\n",
    "    print(pipeline)\n",
    "\n",
    "    print(\"Getting date and input query.\")\n",
    "\n",
    "    bigquery_statsmodel_credentials = service_account.Credentials.from_service_account_info(\n",
    "        forecast_connection.details())\n",
    "\n",
    "    bigquery_statsmodel_client = bigquery.Client(\n",
    "        credentials=bigquery_statsmodel_credentials, \n",
    "        project=forecast_connection.details()['project_id']\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Get the current month and retrieve next month's forecasts\")\n",
    "    month = datetime.datetime.now().month\n",
    "    start_date = f\"{month+1}-1-2011\"\n",
    "    print(f\"Start date: {start_date}\")\n",
    "\n",
    "    def get_forecast_days(firstdate) :\n",
    "        days = [i*7 for i in [-1,0,1,2,3,4]]\n",
    "        deltadays = pd.to_timedelta(pd.Series(days), unit='D') \n",
    "\n",
    "        analysis_days = (pd.to_datetime(firstdate) + deltadays).dt.date\n",
    "        analysis_days = [str(day) for day in analysis_days]\n",
    "        analysis_days\n",
    "        seed_day = analysis_days.pop(0)\n",
    "\n",
    "        return analysis_days\n",
    "\n",
    "    forecast_dates = get_forecast_days(start_date)\n",
    "    print(f\"Forecast dates: {forecast_dates}\")\n",
    "\n",
    "    # get our list of items to run through\n",
    "\n",
    "    inference_data = []\n",
    "    days = []\n",
    "\n",
    "    # get the days from the start date to the end date\n",
    "    def get_forecast_dates(forecast_day: str, nforecast=7):\n",
    "        days = [i for i in range(nforecast)]\n",
    "        deltadays = pd.to_timedelta(pd.Series(days), unit='D')\n",
    "\n",
    "        last_day = pd.to_datetime(forecast_day)\n",
    "        dates = last_day + deltadays\n",
    "        datestr = dates.dt.date.astype(str)\n",
    "        return datestr \n",
    "\n",
    "    # used to generate our queries\n",
    "    def mk_dt_range_query(*, tablename: str, forecast_day: str) -> str:\n",
    "        assert isinstance(tablename, str)\n",
    "        assert isinstance(forecast_day, str)\n",
    "        query = f\"\"\"\n",
    "                select cnt from {tablename} where \n",
    "                dteday >= DATE_SUB(DATE('{forecast_day}'), INTERVAL 1 month) \n",
    "                AND dteday < DATE('{forecast_day}') \n",
    "                ORDER BY dteday\n",
    "                \"\"\"\n",
    "        return query\n",
    "\n",
    "    for day in forecast_dates:\n",
    "        print(f\"Current date: {day}\")\n",
    "        day_range=get_forecast_dates(day)\n",
    "        days.append({\"date\": day_range})\n",
    "        query = mk_dt_range_query(tablename=f\"{forecast_connection.details()['dataset']}.{forecast_connection.details()['input_table']}\", forecast_day=day)\n",
    "        print(query)\n",
    "        data = bigquery_statsmodel_client.query(query).to_dataframe().apply({\"cnt\":int}).to_dict(orient='list')\n",
    "        # add the date into the list\n",
    "        inference_data.append(data)\n",
    "\n",
    "    print(inference_data)\n",
    "\n",
    "    parallel_results = await pipeline.parallel_infer(tensor_list=inference_data, timeout=20, num_parallel=16, retries=2)\n",
    "\n",
    "    days_results = list(zip(days, parallel_results))\n",
    "    print(days_results)\n",
    "\n",
    "    # merge our parallel results into the predicted date sales\n",
    "    results_table = pd.DataFrame(columns=[\"date\", \"forecast\"])\n",
    "\n",
    "    # match the dates to predictions\n",
    "    # display(days_results)\n",
    "    for date in days_results:\n",
    "        # display(date)\n",
    "        new_days = date[0]['date'].tolist()\n",
    "        new_forecast = date[1][0]['forecast']\n",
    "        new_results = list(zip(new_days, new_forecast))\n",
    "        results_table = results_table.append(pd.DataFrame(list(zip(new_days, new_forecast)), columns=['date','forecast']))\n",
    "\n",
    "    print(\"Uploading results to results table.\")\n",
    "    output_table = bigquery_statsmodel_client.get_table(f\"{forecast_connection.details()['dataset']}.{forecast_connection.details()['results_table']}\")\n",
    "\n",
    "    bigquery_statsmodel_client.insert_rows_from_dataframe(\n",
    "        output_table, \n",
    "        dataframe=results_table\n",
    "    )\n",
    "    \n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "This orchestration allows a user to specify the workspace, pipeline, and data connection.  As long as they all match the previous conditions, then the orchestration will run successfully."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Orchestration\n",
    "\n",
    "Orchestrations are uploaded with the Wallaroo client `upload_orchestration(path)` method with the following parameters.\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "| --- | --- | ---|\n",
    "| **path** | string (Required) | The path to the ZIP file to be uploaded. |\n",
    "\n",
    "Once uploaded, the deployment will be prepared and any requirements will be downloaded and installed.\n",
    "\n",
    "\n",
    "For this example, the orchestration `./bigquery_remote_inference/bigquery_remote_inference.zip` will be uploaded and saved to the variable `orchestration`.  Then we will loop until the uploaded orchestration's `status` displays `ready`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pending_packaging\n",
      "pending_packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n",
      "packaging\n"
     ]
    }
   ],
   "source": [
    "orchestration = wl.upload_orchestration(name=\"statsmodel-orchestration\", path=\"./resources/forecast-bigquery-orchestration.zip\")\n",
    "\n",
    "while orchestration.status() != 'ready':\n",
    "    print(orchestration.status())\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>id</th><th>name</th><th>status</th><th>filename</th><th>sha</th><th>created at</th><th>updated at</th></tr><tr><td>8211497d-292a-4145-b28b-f6364e12544e</td><td>statsmodel-orchestration</td><td>packaging</td><td>forecast-bigquery-orchestration.zip</td><td>44f591...1fa8d6</td><td>2023-30-Jun 15:45:48</td><td>2023-30-Jun 15:45:58</td></tr><tr><td>f8f31494-41c4-4336-bfd6-5b3b1607dedc</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>27ad14...306ad1</td><td>2023-30-Jun 15:51:08</td><td>2023-30-Jun 15:51:57</td></tr><tr><td>fd776f89-ea63-45e9-b8d6-a749074fd579</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>bd6a0e...3a6a09</td><td>2023-30-Jun 16:45:50</td><td>2023-30-Jun 16:46:39</td></tr><tr><td>8200995b-3e33-49f4-ac4f-98ea2b1330db</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>8d0c2f...a3c89f</td><td>2023-30-Jun 15:54:14</td><td>2023-30-Jun 15:55:07</td></tr><tr><td>5449a104-abc5-423d-a973-31a3cfdf8b55</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>e00646...45d2a7</td><td>2023-30-Jun 16:12:39</td><td>2023-30-Jun 16:13:29</td></tr><tr><td>9fd1e58c-942d-495b-b3bd-d51f5c03b5ed</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>bd6a0e...3a6a09</td><td>2023-30-Jun 16:48:53</td><td>2023-30-Jun 16:49:44</td></tr><tr><td>73f2e90a-13ab-4182-bde1-0fe55c4446cf</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>f78c26...f494d9</td><td>2023-30-Jun 16:27:37</td><td>2023-30-Jun 16:28:31</td></tr><tr><td>64b085c7-5317-4152-81c3-c0c77b4f683b</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>37257f...4b4547</td><td>2023-30-Jun 16:39:49</td><td>2023-30-Jun 16:40:38</td></tr><tr><td>4a3a73ab-014c-4aa4-9896-44c313d80daa</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>23bf29...17b780</td><td>2023-30-Jun 16:52:45</td><td>2023-30-Jun 16:53:38</td></tr><tr><td>b4ef4449-9afe-4fba-aaa0-b7fd49687443</td><td>statsmodel-orchestration</td><td>ready</td><td>forecast-bigquery-orchestration.zip</td><td>d4f02b...0e6c5d</td><td>2023-30-Jun 16:42:29</td><td>2023-30-Jun 16:43:26</td></tr></table>"
      ],
      "text/plain": [
       "[<wallaroo.orchestration.Orchestration at 0x7fda72ec9910>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda72e3c2e0>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda73114bb0>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda73114af0>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda73114d90>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fdabddb0e20>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fdabddb0eb0>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda72e76d60>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda72e764c0>,\n",
       " <wallaroo.orchestration.Orchestration at 0x7fda72e76370>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.list_orchestrations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Task\n",
    "\n",
    "The orchestration is now ready to be implemented as a Wallaroo Task.  We'll just run it once as an example.  This specific Orchestration that creates the Task assumes that the pipeline is deployed, and accepts the arguments:\n",
    "\n",
    "* workspace_name\n",
    "* pipeline_name\n",
    "* bigquery_connection_name\n",
    "\n",
    "We'll supply the workspaces, pipeline and connection created in previous steps and stored in the initial variables above.  Verify these exist and match the existing workspace, pipeline and connection used in the previous notebooks in this series.\n",
    "\n",
    "Tasks are generated and run once with the Orchestration `run_once(name, json_args, timeout)` method.  Any arguments for the orchestration are passed in as a `Dict`.  If there are no arguments, then an empty set `{}` is passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = orchestration.run_once(name=\"statsmodel single run\", json_args={\"workspace_name\":workspace_name, \"pipeline_name\": pipeline_name, \"bigquery_connection_input_name\":connection_name})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Run with Task Status\n",
    "\n",
    "We'll monitor the run first with it's status.\n",
    "\n",
    "For this example, the status of the previously created task will be generated, then looped until it has reached status `started`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pending'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pending'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while task.status() != \"started\":\n",
    "    display(task.status())\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statsmodel-bike-rentals-jch'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(connection_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Tasks\n",
    "\n",
    "We'll use the Wallaroo client `list_tasks` method to view the tasks currently running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>id</th><th>name</th><th>last run status</th><th>type</th><th>active</th><th>schedule</th><th>created at</th><th>updated at</th></tr><tr><td>c7279e5e-e162-42f8-90ce-b7c0c0bb30f8</td><td>statsmodel single run</td><td>running</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:53:41</td><td>2023-30-Jun 16:53:47</td></tr><tr><td>a47dbca0-e568-44d3-9715-1fed0f17b9a7</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:49:44</td><td>2023-30-Jun 16:49:54</td></tr><tr><td>15c80ad0-537f-4e6a-84c6-6c2f35b5f441</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:46:41</td><td>2023-30-Jun 16:46:51</td></tr><tr><td>d0935da6-480a-420d-a70c-570160b0b6b3</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:44:50</td><td>2023-30-Jun 16:44:56</td></tr><tr><td>e510e8c5-048b-43b1-9524-974934a9e4f5</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:43:30</td><td>2023-30-Jun 16:43:35</td></tr><tr><td>0f62befb-c788-4779-bcfb-0595e3ca6f24</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:40:39</td><td>2023-30-Jun 16:40:50</td></tr><tr><td>f00c6a97-32f9-4124-bf86-34a0068c1314</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:28:32</td><td>2023-30-Jun 16:28:38</td></tr><tr><td>10c8af33-8ff4-4aae-b08d-89665bcb0481</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:13:30</td><td>2023-30-Jun 16:13:35</td></tr><tr><td>9ae4e6e6-3849-4039-acfe-6810699edef8</td><td>statsmodel single run</td><td>failure</td><td>Temporary Run</td><td>True</td><td>-</td><td>2023-30-Jun 16:00:05</td><td>2023-30-Jun 16:00:15</td></tr></table>"
      ],
      "text/plain": [
       "[<wallaroo.task.Task at 0x7fda72ff0280>,\n",
       " <wallaroo.task.Task at 0x7fda72e9c580>,\n",
       " <wallaroo.task.Task at 0x7fda72e6a1c0>,\n",
       " <wallaroo.task.Task at 0x7fda73137100>,\n",
       " <wallaroo.task.Task at 0x7fda73071c70>,\n",
       " <wallaroo.task.Task at 0x7fda73071760>,\n",
       " <wallaroo.task.Task at 0x7fda73071430>,\n",
       " <wallaroo.task.Task at 0x7fda730716d0>,\n",
       " <wallaroo.task.Task at 0x7fda7306f9d0>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.list_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Task Run Results\n",
    "\n",
    "The Task Run is the implementation of the task - the actual running of the script and it's results.  Tasks that are Run Once will only have one Task Run, while a Task set to Run Scheduled will have a Task Run for each time the task is executed.  Each Task Run has its own set of logs and results that are monitoried through the Task Run `logs()` method.\n",
    "\n",
    "We'll wait 30 seconds, then retrieve the task run for our generated task, then start checking the logs for our task run.  It may take longer than 30 seconds to launch the task, so be prepared to run the `.logs()` method again to view the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait 30 seconds for the task to finish\n",
    "time.sleep(30)\n",
    "statsmodel_task_run = task.last_runs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><code>2023-30-Jun 16:53:57 statsmodel-bike-rentals-jch\n",
       "2023-30-Jun 16:53:57 BigQuery Connection: statsmodel-bike-rentals-jch\n",
       "2023-30-Jun 16:53:57 Workspace: multiple-replica-forecast-tutorial-jch\n",
       "2023-30-Jun 16:53:57 {'name': 'multiple-replica-forecast-tutorial-jch', 'id': 7, 'archived': False, 'created_by': '34b86cac-021e-4cf0-aa30-40da7db5a77f', 'created_at': '2023-06-30T15:42:56.551195+00:00', 'models': [{'name': 'bikedaymodel', 'versions': 1, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 6, 30, 15, 42, 56, 979723, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 6, 30, 15, 42, 56, 979723, tzinfo=tzutc())}], 'pipelines': [{'name': 'bikedaypipe', 'create_time': datetime.datetime(2023, 6, 30, 15, 42, 56, 781150, tzinfo=tzutc()), 'definition': '[]'}]}\n",
       "2023-30-Jun 16:53:57 Pipeline: bikedaypipe\n",
       "2023-30-Jun 16:53:57 {'name': 'bikedaypipe', 'create_time': datetime.datetime(2023, 6, 30, 15, 42, 56, 781150, tzinfo=tzutc()), 'definition': '[]'}\n",
       "2023-30-Jun 16:53:57 Getting date and input query.\n",
       "2023-30-Jun 16:53:57 Get the current month and retrieve next month's forecasts\n",
       "2023-30-Jun 16:53:57 Start date: 7-1-2011\n",
       "2023-30-Jun 16:53:57 Forecast dates: ['2011-07-01', '2011-07-08', '2011-07-15', '2011-07-22', '2011-07-29']\n",
       "2023-30-Jun 16:53:57 Current date: 2011-07-01\n",
       "2023-30-Jun 16:53:57 \n",
       "2023-30-Jun 16:53:57                 select cnt from release_testing_2023_2.bike_rentals where \n",
       "2023-30-Jun 16:53:57                 dteday >= DATE_SUB(DATE('2011-07-01'), INTERVAL 1 month) \n",
       "2023-30-Jun 16:53:57                 AND dteday < DATE('2011-07-01') \n",
       "2023-30-Jun 16:53:57                 ORDER BY dteday\n",
       "2023-30-Jun 16:53:57 Current date: 2011-07-08\n",
       "2023-30-Jun 16:53:57                 \n",
       "2023-30-Jun 16:53:57 \n",
       "2023-30-Jun 16:53:57                 select cnt from release_testing_2023_2.bike_rentals where \n",
       "2023-30-Jun 16:53:57                 dteday >= DATE_SUB(DATE('2011-07-08'), INTERVAL 1 month) \n",
       "2023-30-Jun 16:53:57                 ORDER BY dteday\n",
       "2023-30-Jun 16:53:57                 AND dteday < DATE('2011-07-08') \n",
       "2023-30-Jun 16:53:57                 \n",
       "2023-30-Jun 16:53:57 Current date: 2011-07-15\n",
       "2023-30-Jun 16:53:57 \n",
       "2023-30-Jun 16:53:57                 select cnt from release_testing_2023_2.bike_rentals where \n",
       "2023-30-Jun 16:53:57                 dteday >= DATE_SUB(DATE('2011-07-15'), INTERVAL 1 month) \n",
       "2023-30-Jun 16:53:57                 ORDER BY dteday\n",
       "2023-30-Jun 16:53:57                 AND dteday < DATE('2011-07-15') \n",
       "2023-30-Jun 16:53:57                 \n",
       "2023-30-Jun 16:53:57 Current date: 2011-07-22\n",
       "2023-30-Jun 16:53:57 \n",
       "2023-30-Jun 16:53:57                 select cnt from release_testing_2023_2.bike_rentals where \n",
       "2023-30-Jun 16:53:57                 dteday >= DATE_SUB(DATE('2011-07-22'), INTERVAL 1 month) \n",
       "2023-30-Jun 16:53:57                 AND dteday < DATE('2011-07-22') \n",
       "2023-30-Jun 16:53:57                 ORDER BY dteday\n",
       "2023-30-Jun 16:53:57                 \n",
       "2023-30-Jun 16:53:57 Current date: 2011-07-29\n",
       "2023-30-Jun 16:53:57                 select cnt from release_testing_2023_2.bike_rentals where \n",
       "2023-30-Jun 16:53:57 \n",
       "2023-30-Jun 16:53:57                 dteday >= DATE_SUB(DATE('2011-07-29'), INTERVAL 1 month) \n",
       "2023-30-Jun 16:53:57                 ORDER BY dteday\n",
       "2023-30-Jun 16:53:57                 AND dteday < DATE('2011-07-29') \n",
       "2023-30-Jun 16:53:57                 \n",
       "2023-30-Jun 16:53:57 [({'date': 0    2011-07-01\n",
       "2023-30-Jun 16:53:57 [{'cnt': [3974, 4968, 5312, 5342, 4906, 4548, 4833, 4401, 3915, 4586, 4966, 4460, 5020, 4891, 5180, 3767, 4844, 5119, 4744, 4010, 4835, 4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515]}, {'cnt': [4401, 3915, 4586, 4966, 4460, 5020, 4891, 5180, 3767, 4844, 5119, 4744, 4010, 4835, 4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592]}, {'cnt': [5180, 3767, 4844, 5119, 4744, 4010, 4835, 4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592, 4040, 5336, 4881, 4086, 4258, 4342, 5084]}, {'cnt': [4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592, 4040, 5336, 4881, 4086, 4258, 4342, 5084, 5538, 5923, 5302, 4458, 4541, 4332, 3784]}, {'cnt': [5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592, 4040, 5336, 4881, 4086, 4258, 4342, 5084, 5538, 5923, 5302, 4458, 4541, 4332, 3784, 3387, 3285, 3606, 3840, 4590, 4656, 4390]}]\n",
       "2023-30-Jun 16:53:57 1    2011-07-02\n",
       "2023-30-Jun 16:53:57 2    2011-07-03\n",
       "2023-30-Jun 16:53:57 3    2011-07-04\n",
       "2023-30-Jun 16:53:57 4    2011-07-05\n",
       "2023-30-Jun 16:53:57 5    2011-07-06\n",
       "2023-30-Jun 16:53:57 6    2011-07-07\n",
       "2023-30-Jun 16:53:57 dtype: object}, [{'forecast': [4894, 4767, 4786, 4783, 4783, 4783, 4783]}]), ({'date': 0    2011-07-08\n",
       "2023-30-Jun 16:53:57 2    2011-07-10\n",
       "2023-30-Jun 16:53:57 1    2011-07-09\n",
       "2023-30-Jun 16:53:57 4    2011-07-12\n",
       "2023-30-Jun 16:53:57 3    2011-07-11\n",
       "2023-30-Jun 16:53:57 5    2011-07-13\n",
       "2023-30-Jun 16:53:57 6    2011-07-14\n",
       "2023-30-Jun 16:53:57 dtype: object}, [{'forecast': [4842, 4839, 4836, 4833, 4831, 4830, 4828]}]), ({'date': 0    2011-07-15\n",
       "2023-30-Jun 16:53:57 1    2011-07-16\n",
       "2023-30-Jun 16:53:57 2    2011-07-17\n",
       "2023-30-Jun 16:53:57 3    2011-07-18\n",
       "2023-30-Jun 16:53:57 4    2011-07-19\n",
       "2023-30-Jun 16:53:57 5    2011-07-20\n",
       "2023-30-Jun 16:53:57 6    2011-07-21\n",
       "2023-30-Jun 16:53:57 dtype: object}, [{'forecast': [4895, 4759, 4873, 4777, 4858, 4789, 4848]}]), ({'date': 0    2011-07-22\n",
       "2023-30-Jun 16:53:57 1    2011-07-23\n",
       "2023-30-Jun 16:53:57 2    2011-07-24\n",
       "2023-30-Jun 16:53:57 3    2011-07-25\n",
       "2023-30-Jun 16:53:57 5    2011-07-27\n",
       "2023-30-Jun 16:53:57 4    2011-07-26\n",
       "2023-30-Jun 16:53:57 6    2011-07-28\n",
       "2023-30-Jun 16:53:57 dtype: object}, [{'forecast': [4559, 4953, 4829, 4868, 4856, 4860, 4858]}]), ({'date': 0    2011-07-29\n",
       "2023-30-Jun 16:53:57 1    2011-07-30\n",
       "2023-30-Jun 16:53:57 3    2011-08-01\n",
       "2023-30-Jun 16:53:57 2    2011-07-31\n",
       "2023-30-Jun 16:53:57 5    2011-08-03\n",
       "2023-30-Jun 16:53:57 4    2011-08-02\n",
       "2023-30-Jun 16:53:57 6    2011-08-04\n",
       "2023-30-Jun 16:53:57 dtype: object}, [{'forecast': [4490, 4549, 4586, 4610, 4624, 4634, 4640]}])]\n",
       "2023-30-Jun 16:53:57 Uploading results to results table.</code></pre>"
      ],
      "text/plain": [
       "['2023-06-30T16:53:57.629360908Z stdout F statsmodel-bike-rentals-jch',\n",
       " '2023-06-30T16:53:57.629426109Z stdout F BigQuery Connection: statsmodel-bike-rentals-jch',\n",
       " '2023-06-30T16:53:57.629432309Z stdout F Workspace: multiple-replica-forecast-tutorial-jch',\n",
       " '2023-06-30T16:53:57.629438909Z stdout F {\\'name\\': \\'multiple-replica-forecast-tutorial-jch\\', \\'id\\': 7, \\'archived\\': False, \\'created_by\\': \\'34b86cac-021e-4cf0-aa30-40da7db5a77f\\', \\'created_at\\': \\'2023-06-30T15:42:56.551195+00:00\\', \\'models\\': [{\\'name\\': \\'bikedaymodel\\', \\'versions\\': 1, \\'owner_id\\': \\'\"\"\\', \\'last_update_time\\': datetime.datetime(2023, 6, 30, 15, 42, 56, 979723, tzinfo=tzutc()), \\'created_at\\': datetime.datetime(2023, 6, 30, 15, 42, 56, 979723, tzinfo=tzutc())}], \\'pipelines\\': [{\\'name\\': \\'bikedaypipe\\', \\'create_time\\': datetime.datetime(2023, 6, 30, 15, 42, 56, 781150, tzinfo=tzutc()), \\'definition\\': \\'[]\\'}]}',\n",
       " '2023-06-30T16:53:57.629445909Z stdout F Pipeline: bikedaypipe',\n",
       " \"2023-06-30T16:53:57.629450609Z stdout F {'name': 'bikedaypipe', 'create_time': datetime.datetime(2023, 6, 30, 15, 42, 56, 781150, tzinfo=tzutc()), 'definition': '[]'}\",\n",
       " '2023-06-30T16:53:57.629455109Z stdout F Getting date and input query.',\n",
       " \"2023-06-30T16:53:57.629459809Z stdout F Get the current month and retrieve next month's forecasts\",\n",
       " '2023-06-30T16:53:57.629464109Z stdout F Start date: 7-1-2011',\n",
       " \"2023-06-30T16:53:57.629469609Z stdout F Forecast dates: ['2011-07-01', '2011-07-08', '2011-07-15', '2011-07-22', '2011-07-29']\",\n",
       " '2023-06-30T16:53:57.629474009Z stdout F Current date: 2011-07-01',\n",
       " '2023-06-30T16:53:57.629478009Z stdout F ',\n",
       " '2023-06-30T16:53:57.629483509Z stdout F                 select cnt from release_testing_2023_2.bike_rentals where ',\n",
       " \"2023-06-30T16:53:57.629487909Z stdout F                 dteday >= DATE_SUB(DATE('2011-07-01'), INTERVAL 1 month) \",\n",
       " \"2023-06-30T16:53:57.629492209Z stdout F                 AND dteday < DATE('2011-07-01') \",\n",
       " '2023-06-30T16:53:57.629496409Z stdout F                 ORDER BY dteday',\n",
       " '2023-06-30T16:53:57.629504909Z stdout F Current date: 2011-07-08',\n",
       " '2023-06-30T16:53:57.629500609Z stdout F                 ',\n",
       " '2023-06-30T16:53:57.629508909Z stdout F ',\n",
       " '2023-06-30T16:53:57.629513209Z stdout F                 select cnt from release_testing_2023_2.bike_rentals where ',\n",
       " \"2023-06-30T16:53:57.629517909Z stdout F                 dteday >= DATE_SUB(DATE('2011-07-08'), INTERVAL 1 month) \",\n",
       " '2023-06-30T16:53:57.629527309Z stdout F                 ORDER BY dteday',\n",
       " \"2023-06-30T16:53:57.629522709Z stdout F                 AND dteday < DATE('2011-07-08') \",\n",
       " '2023-06-30T16:53:57.629532009Z stdout F                 ',\n",
       " '2023-06-30T16:53:57.629536709Z stdout F Current date: 2011-07-15',\n",
       " '2023-06-30T16:53:57.629540709Z stdout F ',\n",
       " '2023-06-30T16:53:57.629545309Z stdout F                 select cnt from release_testing_2023_2.bike_rentals where ',\n",
       " \"2023-06-30T16:53:57.629549809Z stdout F                 dteday >= DATE_SUB(DATE('2011-07-15'), INTERVAL 1 month) \",\n",
       " '2023-06-30T16:53:57.629558309Z stdout F                 ORDER BY dteday',\n",
       " \"2023-06-30T16:53:57.629554009Z stdout F                 AND dteday < DATE('2011-07-15') \",\n",
       " '2023-06-30T16:53:57.629562809Z stdout F                 ',\n",
       " '2023-06-30T16:53:57.629567509Z stdout F Current date: 2011-07-22',\n",
       " '2023-06-30T16:53:57.629571809Z stdout F ',\n",
       " '2023-06-30T16:53:57.629576709Z stdout F                 select cnt from release_testing_2023_2.bike_rentals where ',\n",
       " \"2023-06-30T16:53:57.629581309Z stdout F                 dteday >= DATE_SUB(DATE('2011-07-22'), INTERVAL 1 month) \",\n",
       " \"2023-06-30T16:53:57.62958591Z stdout F                 AND dteday < DATE('2011-07-22') \",\n",
       " '2023-06-30T16:53:57.62959071Z stdout F                 ORDER BY dteday',\n",
       " '2023-06-30T16:53:57.62959521Z stdout F                 ',\n",
       " '2023-06-30T16:53:57.62959971Z stdout F Current date: 2011-07-29',\n",
       " '2023-06-30T16:53:57.62960921Z stdout F                 select cnt from release_testing_2023_2.bike_rentals where ',\n",
       " '2023-06-30T16:53:57.62960431Z stdout F ',\n",
       " \"2023-06-30T16:53:57.62961431Z stdout F                 dteday >= DATE_SUB(DATE('2011-07-29'), INTERVAL 1 month) \",\n",
       " '2023-06-30T16:53:57.62962351Z stdout F                 ORDER BY dteday',\n",
       " \"2023-06-30T16:53:57.62961891Z stdout F                 AND dteday < DATE('2011-07-29') \",\n",
       " '2023-06-30T16:53:57.62963891Z stdout F                 ',\n",
       " \"2023-06-30T16:53:57.62965501Z stdout F [({'date': 0    2011-07-01\",\n",
       " \"2023-06-30T16:53:57.62964801Z stdout F [{'cnt': [3974, 4968, 5312, 5342, 4906, 4548, 4833, 4401, 3915, 4586, 4966, 4460, 5020, 4891, 5180, 3767, 4844, 5119, 4744, 4010, 4835, 4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515]}, {'cnt': [4401, 3915, 4586, 4966, 4460, 5020, 4891, 5180, 3767, 4844, 5119, 4744, 4010, 4835, 4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592]}, {'cnt': [5180, 3767, 4844, 5119, 4744, 4010, 4835, 4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592, 4040, 5336, 4881, 4086, 4258, 4342, 5084]}, {'cnt': [4507, 4790, 4991, 5202, 5305, 4708, 4648, 5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592, 4040, 5336, 4881, 4086, 4258, 4342, 5084, 5538, 5923, 5302, 4458, 4541, 4332, 3784]}, {'cnt': [5225, 5515, 5362, 5119, 4649, 6043, 4665, 4629, 4592, 4040, 5336, 4881, 4086, 4258, 4342, 5084, 5538, 5923, 5302, 4458, 4541, 4332, 3784, 3387, 3285, 3606, 3840, 4590, 4656, 4390]}]\",\n",
       " '2023-06-30T16:53:57.62965971Z stdout F 1    2011-07-02',\n",
       " '2023-06-30T16:53:57.62966451Z stdout F 2    2011-07-03',\n",
       " '2023-06-30T16:53:57.62966891Z stdout F 3    2011-07-04',\n",
       " '2023-06-30T16:53:57.62967321Z stdout F 4    2011-07-05',\n",
       " '2023-06-30T16:53:57.62967761Z stdout F 5    2011-07-06',\n",
       " '2023-06-30T16:53:57.62968231Z stdout F 6    2011-07-07',\n",
       " \"2023-06-30T16:53:57.62968741Z stdout F dtype: object}, [{'forecast': [4894, 4767, 4786, 4783, 4783, 4783, 4783]}]), ({'date': 0    2011-07-08\",\n",
       " '2023-06-30T16:53:57.62969921Z stdout F 2    2011-07-10',\n",
       " '2023-06-30T16:53:57.62969191Z stdout F 1    2011-07-09',\n",
       " '2023-06-30T16:53:57.62970881Z stdout F 4    2011-07-12',\n",
       " '2023-06-30T16:53:57.62970391Z stdout F 3    2011-07-11',\n",
       " '2023-06-30T16:53:57.62971361Z stdout F 5    2011-07-13',\n",
       " '2023-06-30T16:53:57.62971811Z stdout F 6    2011-07-14',\n",
       " \"2023-06-30T16:53:57.62972261Z stdout F dtype: object}, [{'forecast': [4842, 4839, 4836, 4833, 4831, 4830, 4828]}]), ({'date': 0    2011-07-15\",\n",
       " '2023-06-30T16:53:57.62972731Z stdout F 1    2011-07-16',\n",
       " '2023-06-30T16:53:57.62973191Z stdout F 2    2011-07-17',\n",
       " '2023-06-30T16:53:57.62973641Z stdout F 3    2011-07-18',\n",
       " '2023-06-30T16:53:57.62974111Z stdout F 4    2011-07-19',\n",
       " '2023-06-30T16:53:57.62974571Z stdout F 5    2011-07-20',\n",
       " '2023-06-30T16:53:57.62975041Z stdout F 6    2011-07-21',\n",
       " \"2023-06-30T16:53:57.62975511Z stdout F dtype: object}, [{'forecast': [4895, 4759, 4873, 4777, 4858, 4789, 4848]}]), ({'date': 0    2011-07-22\",\n",
       " '2023-06-30T16:53:57.62975941Z stdout F 1    2011-07-23',\n",
       " '2023-06-30T16:53:57.629764511Z stdout F 2    2011-07-24',\n",
       " '2023-06-30T16:53:57.629769311Z stdout F 3    2011-07-25',\n",
       " '2023-06-30T16:53:57.629778611Z stdout F 5    2011-07-27',\n",
       " '2023-06-30T16:53:57.629773911Z stdout F 4    2011-07-26',\n",
       " '2023-06-30T16:53:57.629783211Z stdout F 6    2011-07-28',\n",
       " \"2023-06-30T16:53:57.629808711Z stdout F dtype: object}, [{'forecast': [4559, 4953, 4829, 4868, 4856, 4860, 4858]}]), ({'date': 0    2011-07-29\",\n",
       " '2023-06-30T16:53:57.629814411Z stdout F 1    2011-07-30',\n",
       " '2023-06-30T16:53:57.629824011Z stdout F 3    2011-08-01',\n",
       " '2023-06-30T16:53:57.629819411Z stdout F 2    2011-07-31',\n",
       " '2023-06-30T16:53:57.629833011Z stdout F 5    2011-08-03',\n",
       " '2023-06-30T16:53:57.629828511Z stdout F 4    2011-08-02',\n",
       " '2023-06-30T16:53:57.629838011Z stdout F 6    2011-08-04',\n",
       " \"2023-06-30T16:53:57.629842711Z stdout F dtype: object}, [{'forecast': [4490, 4549, 4586, 4610, 4624, 4634, 4640]}])]\",\n",
       " '2023-06-30T16:53:57.629847511Z stdout F Uploading results to results table.']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsmodel_task_run.logs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s ..................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bikedaypipe</td></tr><tr><th>created</th> <td>2023-06-30 15:42:56.781150+00:00</td></tr><tr><th>last_updated</th> <td>2023-06-30 15:45:23.267621+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>6552b04e-d074-4773-982b-a2885ce6f9bf, b884c20c-c491-46ec-b438-74384a963acc, 4e8d2a88-1a41-482c-831d-f057a48e18c1</td></tr><tr><th>steps</th> <td>bikedaymodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bikedaypipe', 'create_time': datetime.datetime(2023, 6, 30, 15, 42, 56, 781150, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bikedaymodel', 'version': 'd60ceac2-6fed-4bef-afd1-f3880ad85d0c', 'sha': '525ea2be4402725878382631c2c32b2e3f105bf78eedf41f3ac6d71c0dfa986b'}]}}]\"}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
