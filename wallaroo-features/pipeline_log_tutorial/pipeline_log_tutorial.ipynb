{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-features/pipeline_log_tutorial/).\n",
    "\n",
    "## Pipeline Log Tutorial\n",
    "\n",
    "This tutorial demonstrates Wallaroo Pipeline logs and \n",
    "\n",
    "This tutorial will demonstrate how to:\n",
    "\n",
    "1. Select or create a workspace, pipeline and upload the control model, then additional models for A/B Testing and Shadow Deploy.\n",
    "1. Add a pipeline step with the champion model, then deploy the pipeline and perform sample inferences.\n",
    "1. Display the various log types for a standard deployed pipeline.\n",
    "1. Swap out the pipeline step with the champion model with a shadow deploy step that compares the champion model against two competitors.\n",
    "1. Perform sample inferences with a shadow deployed step, then display the log files for a shadow deployed pipeline.\n",
    "1. Swap out the shadow deployed pipeline step with an A/B pipeline step.\n",
    "1. Perform sample inferences with a A/B pipeline step, then display the log files for an A/B pipeline step.\n",
    "1. Undeploy the pipeline.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* Models:\n",
    "  * `models/rf_model.onnx`: The champion model that has been used in this environment for some time.\n",
    "  * `models/xgb_model.onnx` and `models/gbr_model.onnx`: Rival models that will be tested against the champion.\n",
    "* Data:\n",
    "  * `data/xtest-1.df.json` and `data/xtest-1k.df.json`:  DataFrame JSON inference inputs with 1 input and 1,000 inputs.\n",
    "  * `data/xtest-1k.arrow`:  Apache Arrow inference inputs with 1 input and 1,000 inputs.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* A deployed Wallaroo instance\n",
    "* The following Python libraries installed:\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * [`pyarrow`](https://pypi.org/project/pyarrow/): Pyarrow for Apache Arrow support\n",
    "  * [`polars`](https://pypi.org/project/polars/): Polars for DataFrame with native Apache Arrow support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import os\n",
    "# For Wallaroo SDK 2023.1\n",
    "os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo Instance\n",
    "\n",
    "The following command will create a connection to the Wallaroo instance and store it in the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "# wl = wallaroo.Client()\n",
    "\n",
    "# SSO login through keycloak\n",
    "\n",
    "# wallarooPrefix = \"YOUR PREFIX\"\n",
    "# wallarooSuffix = \"YOUR PREFIX\"\n",
    "\n",
    "wallarooPrefix = \"docreleasetest\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workspace\n",
    "\n",
    "We will create a workspace to manage our pipeline and models.  The following variables will set the name of our sample workspace then set it as the current workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'pipelinelogworkspace'\n",
    "main_pipeline_name = 'pipelinelogpipeline'\n",
    "model_name_control = 'logcontrol'\n",
    "model_file_name_control = './models/rf_model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'pipelinelogworkspace', 'id': 33, 'archived': False, 'created_by': '8b9ea462-081b-423e-bbda-35a32f538d82', 'created_at': '2023-04-21T19:29:11.449809+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload The Champion Model\n",
    "\n",
    "For our example, we will upload the champion model that has been trained to derive house prices from a variety of inputs.  The model file is `rf_model.onnx`, and is uploaded with the name `housingcontrol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_model_control = wl.upload_model(model_name_control, model_file_name_control).configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Pipeline\n",
    "\n",
    "This pipeline is made to be an example of an existing situation where a model is deployed and being used for inferences in a production environment.  We'll call it `housepricepipeline`, set `housingcontrol` as a pipeline step, then run a few sample inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ............... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>pipelinelogpipeline</td></tr><tr><th>created</th> <td>2023-04-21 19:29:16.145012+00:00</td></tr><tr><th>last_updated</th> <td>2023-04-21 19:31:45.629466+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>64152fa1-a331-4204-afd5-f5722945b983, 19498358-db46-4a5e-a6dc-a30e8cbc26eb, 45b7b496-38b1-4ec3-8e9b-38700c52fa0e, 2fb4ba8d-c584-4010-a5fd-6d4fe93a7d8d</td></tr><tr><th>steps</th> <td>logcontrol</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'pipelinelogpipeline', 'create_time': datetime.datetime(2023, 4, 21, 19, 29, 16, 145012, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'logcontrol', 'version': 'd04156bd-2117-46ef-bf92-59df38b98e87', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}]}}]\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainpipeline = wl.build_pipeline(main_pipeline_name)\n",
    "# in case this was run before\n",
    "mainpipeline.clear()\n",
    "mainpipeline.add_model_step(housing_model_control).deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We'll use two inferences as a quick sample test - one that has a house that should be determined around $700k, the other with a house determined to be around $1.5 million.  We'll also save the start and end periods for these events to for later log functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21 19:32:01.905</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-04-21 19:32:01.905   \n",
       "\n",
       "                                                                                                            in.tensor  \\\n",
       "0  [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0   [718013.7]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe_start = datetime.datetime.now()\n",
    "\n",
    "normal_input = pd.DataFrame.from_records({\"tensor\": [[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]]})\n",
    "result = mainpipeline.infer(normal_input)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21 19:32:01.968</td>\n",
       "      <td>[4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]</td>\n",
       "      <td>[1514079.4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-04-21 19:32:01.968   \n",
       "\n",
       "                                                                                                                  in.tensor  \\\n",
       "0  [4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0  [1514079.4]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "large_house_input = pd.DataFrame.from_records({'tensor': [[4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]]})\n",
    "large_house_result = mainpipeline.infer(large_house_input)\n",
    "display(large_house_result)\n",
    "dataframe_end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one last sample, we'll run through roughly 1,000 inferences at once and show a few of the results.  For this example we'll use an Apache Arrow table, which has a smaller file size compared to uploading a pandas DataFrame JSON file.  The inference result is returned as an arrow table, which we'll convert into a pandas DataFrame to display the first 20 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.75]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[2.0, 2.5, 2170.0, 6361.0, 1.0, 0.0, 2.0, 3.0, 8.0, 2170.0, 0.0, 47.7109, -122.017, 2310.0, 7419.0, 6.0, 0.0, 0.0]</td>\n",
       "      <td>[615094.56]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.5, 1300.0, 812.0, 2.0, 0.0, 0.0, 3.0, 8.0, 880.0, 420.0, 47.5893, -122.317, 1300.0, 824.0, 6.0, 0.0, 0.0]</td>\n",
       "      <td>[448627.72]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.5, 2500.0, 8540.0, 2.0, 0.0, 0.0, 3.0, 9.0, 2500.0, 0.0, 47.5759, -121.994, 2560.0, 8475.0, 24.0, 0.0, 0.0]</td>\n",
       "      <td>[758714.2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 1.75, 2200.0, 11520.0, 1.0, 0.0, 0.0, 4.0, 7.0, 2200.0, 0.0, 47.7659, -122.341, 1690.0, 8038.0, 62.0, 0.0, 0.0]</td>\n",
       "      <td>[513264.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.0, 2140.0, 4923.0, 1.0, 0.0, 0.0, 4.0, 8.0, 1070.0, 1070.0, 47.6902, -122.339, 1470.0, 4923.0, 86.0, 0.0, 0.0]</td>\n",
       "      <td>[668288.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 3.5, 3590.0, 5334.0, 2.0, 0.0, 2.0, 3.0, 9.0, 3140.0, 450.0, 47.6763, -122.267, 2100.0, 6250.0, 9.0, 0.0, 0.0]</td>\n",
       "      <td>[1004846.5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.0, 1280.0, 960.0, 2.0, 0.0, 0.0, 3.0, 9.0, 1040.0, 240.0, 47.602, -122.311, 1280.0, 1173.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[684577.2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.5, 2820.0, 15000.0, 2.0, 0.0, 0.0, 4.0, 9.0, 2820.0, 0.0, 47.7255, -122.101, 2440.0, 15000.0, 29.0, 0.0, 0.0]</td>\n",
       "      <td>[727898.1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.25, 1790.0, 11393.0, 1.0, 0.0, 0.0, 3.0, 8.0, 1790.0, 0.0, 47.6297, -122.099, 2290.0, 11894.0, 36.0, 0.0, 0.0]</td>\n",
       "      <td>[559631.1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 1.5, 1010.0, 7683.0, 1.5, 0.0, 0.0, 5.0, 7.0, 1010.0, 0.0, 47.72, -122.318, 1550.0, 7271.0, 61.0, 0.0, 0.0]</td>\n",
       "      <td>[340764.53]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.0, 1270.0, 1323.0, 3.0, 0.0, 0.0, 3.0, 8.0, 1270.0, 0.0, 47.6934, -122.342, 1330.0, 1323.0, 8.0, 0.0, 0.0]</td>\n",
       "      <td>[442168.06]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 1.75, 2070.0, 9120.0, 1.0, 0.0, 0.0, 4.0, 7.0, 1250.0, 820.0, 47.6045, -122.123, 1650.0, 8400.0, 57.0, 0.0, 0.0]</td>\n",
       "      <td>[630865.6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 1.0, 1620.0, 4080.0, 1.5, 0.0, 0.0, 3.0, 7.0, 1620.0, 0.0, 47.6696, -122.324, 1760.0, 4080.0, 91.0, 0.0, 0.0]</td>\n",
       "      <td>[559631.1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 3.25, 3990.0, 9786.0, 2.0, 0.0, 0.0, 3.0, 9.0, 3990.0, 0.0, 47.6784, -122.026, 3920.0, 8200.0, 10.0, 0.0, 0.0]</td>\n",
       "      <td>[909441.1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.0, 1780.0, 19843.0, 1.0, 0.0, 0.0, 3.0, 7.0, 1780.0, 0.0, 47.4414, -122.154, 2210.0, 13500.0, 52.0, 0.0, 0.0]</td>\n",
       "      <td>[313096.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.5, 2130.0, 6003.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2130.0, 0.0, 47.4518, -122.12, 1940.0, 4529.0, 11.0, 0.0, 0.0]</td>\n",
       "      <td>[404040.8]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 1.75, 1660.0, 10440.0, 1.0, 0.0, 0.0, 3.0, 7.0, 1040.0, 620.0, 47.4448, -121.77, 1240.0, 10380.0, 36.0, 0.0, 0.0]</td>\n",
       "      <td>[292859.5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.5, 2110.0, 4118.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2110.0, 0.0, 47.3878, -122.153, 2110.0, 4044.0, 25.0, 0.0, 0.0]</td>\n",
       "      <td>[338357.88]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.25, 2200.0, 11250.0, 1.5, 0.0, 0.0, 5.0, 7.0, 1300.0, 900.0, 47.6845, -122.201, 2320.0, 10814.0, 94.0, 0.0, 0.0]</td>\n",
       "      <td>[682284.6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time  \\\n",
       "0  2023-04-21 19:32:02.033   \n",
       "1  2023-04-21 19:32:02.033   \n",
       "2  2023-04-21 19:32:02.033   \n",
       "3  2023-04-21 19:32:02.033   \n",
       "4  2023-04-21 19:32:02.033   \n",
       "5  2023-04-21 19:32:02.033   \n",
       "6  2023-04-21 19:32:02.033   \n",
       "7  2023-04-21 19:32:02.033   \n",
       "8  2023-04-21 19:32:02.033   \n",
       "9  2023-04-21 19:32:02.033   \n",
       "10 2023-04-21 19:32:02.033   \n",
       "11 2023-04-21 19:32:02.033   \n",
       "12 2023-04-21 19:32:02.033   \n",
       "13 2023-04-21 19:32:02.033   \n",
       "14 2023-04-21 19:32:02.033   \n",
       "15 2023-04-21 19:32:02.033   \n",
       "16 2023-04-21 19:32:02.033   \n",
       "17 2023-04-21 19:32:02.033   \n",
       "18 2023-04-21 19:32:02.033   \n",
       "19 2023-04-21 19:32:02.033   \n",
       "\n",
       "                                                                                                                   in.tensor  \\\n",
       "0         [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "1         [2.0, 2.5, 2170.0, 6361.0, 1.0, 0.0, 2.0, 3.0, 8.0, 2170.0, 0.0, 47.7109, -122.017, 2310.0, 7419.0, 6.0, 0.0, 0.0]   \n",
       "2          [3.0, 2.5, 1300.0, 812.0, 2.0, 0.0, 0.0, 3.0, 8.0, 880.0, 420.0, 47.5893, -122.317, 1300.0, 824.0, 6.0, 0.0, 0.0]   \n",
       "3        [4.0, 2.5, 2500.0, 8540.0, 2.0, 0.0, 0.0, 3.0, 9.0, 2500.0, 0.0, 47.5759, -121.994, 2560.0, 8475.0, 24.0, 0.0, 0.0]   \n",
       "4      [3.0, 1.75, 2200.0, 11520.0, 1.0, 0.0, 0.0, 4.0, 7.0, 2200.0, 0.0, 47.7659, -122.341, 1690.0, 8038.0, 62.0, 0.0, 0.0]   \n",
       "5     [3.0, 2.0, 2140.0, 4923.0, 1.0, 0.0, 0.0, 4.0, 8.0, 1070.0, 1070.0, 47.6902, -122.339, 1470.0, 4923.0, 86.0, 0.0, 0.0]   \n",
       "6       [4.0, 3.5, 3590.0, 5334.0, 2.0, 0.0, 2.0, 3.0, 9.0, 3140.0, 450.0, 47.6763, -122.267, 2100.0, 6250.0, 9.0, 0.0, 0.0]   \n",
       "7         [3.0, 2.0, 1280.0, 960.0, 2.0, 0.0, 0.0, 3.0, 9.0, 1040.0, 240.0, 47.602, -122.311, 1280.0, 1173.0, 0.0, 0.0, 0.0]   \n",
       "8      [4.0, 2.5, 2820.0, 15000.0, 2.0, 0.0, 0.0, 4.0, 9.0, 2820.0, 0.0, 47.7255, -122.101, 2440.0, 15000.0, 29.0, 0.0, 0.0]   \n",
       "9     [3.0, 2.25, 1790.0, 11393.0, 1.0, 0.0, 0.0, 3.0, 8.0, 1790.0, 0.0, 47.6297, -122.099, 2290.0, 11894.0, 36.0, 0.0, 0.0]   \n",
       "10         [3.0, 1.5, 1010.0, 7683.0, 1.5, 0.0, 0.0, 5.0, 7.0, 1010.0, 0.0, 47.72, -122.318, 1550.0, 7271.0, 61.0, 0.0, 0.0]   \n",
       "11        [3.0, 2.0, 1270.0, 1323.0, 3.0, 0.0, 0.0, 3.0, 8.0, 1270.0, 0.0, 47.6934, -122.342, 1330.0, 1323.0, 8.0, 0.0, 0.0]   \n",
       "12    [4.0, 1.75, 2070.0, 9120.0, 1.0, 0.0, 0.0, 4.0, 7.0, 1250.0, 820.0, 47.6045, -122.123, 1650.0, 8400.0, 57.0, 0.0, 0.0]   \n",
       "13       [4.0, 1.0, 1620.0, 4080.0, 1.5, 0.0, 0.0, 3.0, 7.0, 1620.0, 0.0, 47.6696, -122.324, 1760.0, 4080.0, 91.0, 0.0, 0.0]   \n",
       "14      [4.0, 3.25, 3990.0, 9786.0, 2.0, 0.0, 0.0, 3.0, 9.0, 3990.0, 0.0, 47.6784, -122.026, 3920.0, 8200.0, 10.0, 0.0, 0.0]   \n",
       "15     [4.0, 2.0, 1780.0, 19843.0, 1.0, 0.0, 0.0, 3.0, 7.0, 1780.0, 0.0, 47.4414, -122.154, 2210.0, 13500.0, 52.0, 0.0, 0.0]   \n",
       "16        [4.0, 2.5, 2130.0, 6003.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2130.0, 0.0, 47.4518, -122.12, 1940.0, 4529.0, 11.0, 0.0, 0.0]   \n",
       "17   [3.0, 1.75, 1660.0, 10440.0, 1.0, 0.0, 0.0, 3.0, 7.0, 1040.0, 620.0, 47.4448, -121.77, 1240.0, 10380.0, 36.0, 0.0, 0.0]   \n",
       "18       [3.0, 2.5, 2110.0, 4118.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2110.0, 0.0, 47.3878, -122.153, 2110.0, 4044.0, 25.0, 0.0, 0.0]   \n",
       "19  [4.0, 2.25, 2200.0, 11250.0, 1.5, 0.0, 0.0, 5.0, 7.0, 1300.0, 900.0, 47.6845, -122.201, 2320.0, 10814.0, 94.0, 0.0, 0.0]   \n",
       "\n",
       "   out.variable  check_failures  \n",
       "0   [718013.75]               0  \n",
       "1   [615094.56]               0  \n",
       "2   [448627.72]               0  \n",
       "3    [758714.2]               0  \n",
       "4    [513264.7]               0  \n",
       "5    [668288.0]               0  \n",
       "6   [1004846.5]               0  \n",
       "7    [684577.2]               0  \n",
       "8    [727898.1]               0  \n",
       "9    [559631.1]               0  \n",
       "10  [340764.53]               0  \n",
       "11  [442168.06]               0  \n",
       "12   [630865.6]               0  \n",
       "13   [559631.1]               0  \n",
       "14   [909441.1]               0  \n",
       "15   [313096.0]               0  \n",
       "16   [404040.8]               0  \n",
       "17   [292859.5]               0  \n",
       "18  [338357.88]               0  \n",
       "19   [682284.6]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arrow_start = datetime.datetime.now()\n",
    "\n",
    "batch_inferences = mainpipeline.infer_from_file('./data/xtest-1k.arrow')\n",
    "\n",
    "arrow_end = datetime.datetime.now()\n",
    "large_inference_result =  batch_inferences.to_pandas()\n",
    "display(large_inference_result.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Pipeline Logs\n",
    "\n",
    "Pipeline logs with standard pipeline steps are retrieved either with:\n",
    "\n",
    "* Pipeline `logs` which returns either a pandas DataFrame or Apache Arrow table.\n",
    "* Pipeline `export_logs` which saves the logs either a pandas DataFrame JSON file or Apache Arrow table.\n",
    "\n",
    "For full details, see the Wallaroo Documentation Pipeline Log Management guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Log Method\n",
    "\n",
    "The Pipeline `logs` method accepts the following parameters.\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| `limit` | **Int** (*Optional*) | Limits how many log records to display.  Defaults to `100`.  If there are more pipeline logs than are being displayed, the **Warning** message `Pipeline log record limit exceeded` will be displayed.  For example, if 100 log files were requested and there are a total of 1,000, the warning message will be displayed. |\n",
    "| `start_datetime` and `end_datetime` | **DateTime** (*Optional*) | Limits logs to all logs between the `start` and `end` DateTime parameters.  **Both parameters must be provided**. Submitting a `logs()` request with only `start_datetime` or `end_datetime` will generate an exception.<br />If `start_datetime` and `end_datetime` are provided as parameters, then the records are returned in **chronological** order, with the oldest record displayed first. |\n",
    "| `arrow` | **Boolean** (*Optional*) | Defaults to **False**.  If `arrow` is set to `True`, then the logs are returned as an [Apache Arrow table](https://arrow.apache.org/).  If `arrow=False`, then the logs are returned as a pandas DataFrame. |\n",
    "\n",
    "##### Pipeling Log Warnings\n",
    "\n",
    "If the total number of logs the either the set limit or 10 MB in file size, the following warning is returned:\n",
    "\n",
    "`Warning: There are more logs available. Please set a larger limit or request a file using export_logs.`\n",
    "\n",
    "If the total number of logs **requested** either through the limit or through the `start_datetime` and `end_datetime` request is greater than 10 MB in size, the following error is displayed:\n",
    "\n",
    "`Warning: Pipeline log size limit exceeded. Only displaying 509 log messages. Please request a file using export_logs.`\n",
    "\n",
    "The following examples demonstrate displaying the logs, then displaying the logs between the `control_model_start` and `control_model_end` periods, then again retrieved as an Arrow table with the logs limited to only 5 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-04-21T19:32:01.835984'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2023-04-21T19:32:01.981833'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21 19:32:01.905</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-21 19:32:01.968</td>\n",
       "      <td>[4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]</td>\n",
       "      <td>[1514079.4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-04-21 19:32:01.905   \n",
       "1 2023-04-21 19:32:01.968   \n",
       "\n",
       "                                                                                                                  in.tensor  \\\n",
       "0        [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "1  [4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0   [718013.7]               0  \n",
       "1  [1514079.4]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2023-04-21T19:32:01.991521'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2023-04-21T19:32:02.044550'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Pipeline log size limit exceeded. Only displaying 538 log messages. Please request a file using export_logs."
     ]
    },
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.75]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[2.0, 2.5, 2170.0, 6361.0, 1.0, 0.0, 2.0, 3.0, 8.0, 2170.0, 0.0, 47.7109, -122.017, 2310.0, 7419.0, 6.0, 0.0, 0.0]</td>\n",
       "      <td>[615094.56]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.5, 1300.0, 812.0, 2.0, 0.0, 0.0, 3.0, 8.0, 880.0, 420.0, 47.5893, -122.317, 1300.0, 824.0, 6.0, 0.0, 0.0]</td>\n",
       "      <td>[448627.72]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 2.5, 2500.0, 8540.0, 2.0, 0.0, 0.0, 3.0, 9.0, 2500.0, 0.0, 47.5759, -121.994, 2560.0, 8475.0, 24.0, 0.0, 0.0]</td>\n",
       "      <td>[758714.2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 1.75, 2200.0, 11520.0, 1.0, 0.0, 0.0, 4.0, 7.0, 2200.0, 0.0, 47.7659, -122.341, 1690.0, 8038.0, 62.0, 0.0, 0.0]</td>\n",
       "      <td>[513264.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.5, 1750.0, 7208.0, 2.0, 0.0, 0.0, 3.0, 8.0, 1750.0, 0.0, 47.4315, -122.192, 2050.0, 7524.0, 20.0, 0.0, 0.0]</td>\n",
       "      <td>[311909.6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[5.0, 1.75, 2330.0, 6450.0, 1.0, 0.0, 1.0, 3.0, 8.0, 1330.0, 1000.0, 47.4959, -122.367, 2330.0, 8258.0, 57.0, 0.0, 0.0]</td>\n",
       "      <td>[448720.28]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[4.0, 3.5, 4460.0, 16271.0, 2.0, 0.0, 2.0, 3.0, 11.0, 4460.0, 0.0, 47.5862, -121.97, 4540.0, 17122.0, 13.0, 0.0, 0.0]</td>\n",
       "      <td>[1208638.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[3.0, 2.75, 3010.0, 1842.0, 2.0, 0.0, 0.0, 3.0, 9.0, 3010.0, 0.0, 47.5836, -121.994, 2950.0, 4200.0, 3.0, 0.0, 0.0]</td>\n",
       "      <td>[795841.06]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2023-04-21 19:32:02.033</td>\n",
       "      <td>[2.0, 1.5, 1780.0, 4750.0, 1.0, 0.0, 0.0, 4.0, 7.0, 1080.0, 700.0, 47.6859, -122.395, 1690.0, 5962.0, 67.0, 0.0, 0.0]</td>\n",
       "      <td>[558463.3]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  \\\n",
       "0   2023-04-21 19:32:02.033   \n",
       "1   2023-04-21 19:32:02.033   \n",
       "2   2023-04-21 19:32:02.033   \n",
       "3   2023-04-21 19:32:02.033   \n",
       "4   2023-04-21 19:32:02.033   \n",
       "..                      ...   \n",
       "533 2023-04-21 19:32:02.033   \n",
       "534 2023-04-21 19:32:02.033   \n",
       "535 2023-04-21 19:32:02.033   \n",
       "536 2023-04-21 19:32:02.033   \n",
       "537 2023-04-21 19:32:02.033   \n",
       "\n",
       "                                                                                                                   in.tensor  \\\n",
       "0         [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "1         [2.0, 2.5, 2170.0, 6361.0, 1.0, 0.0, 2.0, 3.0, 8.0, 2170.0, 0.0, 47.7109, -122.017, 2310.0, 7419.0, 6.0, 0.0, 0.0]   \n",
       "2          [3.0, 2.5, 1300.0, 812.0, 2.0, 0.0, 0.0, 3.0, 8.0, 880.0, 420.0, 47.5893, -122.317, 1300.0, 824.0, 6.0, 0.0, 0.0]   \n",
       "3        [4.0, 2.5, 2500.0, 8540.0, 2.0, 0.0, 0.0, 3.0, 9.0, 2500.0, 0.0, 47.5759, -121.994, 2560.0, 8475.0, 24.0, 0.0, 0.0]   \n",
       "4      [3.0, 1.75, 2200.0, 11520.0, 1.0, 0.0, 0.0, 4.0, 7.0, 2200.0, 0.0, 47.7659, -122.341, 1690.0, 8038.0, 62.0, 0.0, 0.0]   \n",
       "..                                                                                                                       ...   \n",
       "533      [3.0, 2.5, 1750.0, 7208.0, 2.0, 0.0, 0.0, 3.0, 8.0, 1750.0, 0.0, 47.4315, -122.192, 2050.0, 7524.0, 20.0, 0.0, 0.0]   \n",
       "534  [5.0, 1.75, 2330.0, 6450.0, 1.0, 0.0, 1.0, 3.0, 8.0, 1330.0, 1000.0, 47.4959, -122.367, 2330.0, 8258.0, 57.0, 0.0, 0.0]   \n",
       "535    [4.0, 3.5, 4460.0, 16271.0, 2.0, 0.0, 2.0, 3.0, 11.0, 4460.0, 0.0, 47.5862, -121.97, 4540.0, 17122.0, 13.0, 0.0, 0.0]   \n",
       "536      [3.0, 2.75, 3010.0, 1842.0, 2.0, 0.0, 0.0, 3.0, 9.0, 3010.0, 0.0, 47.5836, -121.994, 2950.0, 4200.0, 3.0, 0.0, 0.0]   \n",
       "537    [2.0, 1.5, 1780.0, 4750.0, 1.0, 0.0, 0.0, 4.0, 7.0, 1080.0, 700.0, 47.6859, -122.395, 1690.0, 5962.0, 67.0, 0.0, 0.0]   \n",
       "\n",
       "    out.variable  check_failures  \n",
       "0    [718013.75]               0  \n",
       "1    [615094.56]               0  \n",
       "2    [448627.72]               0  \n",
       "3     [758714.2]               0  \n",
       "4     [513264.7]               0  \n",
       "..           ...             ...  \n",
       "533   [311909.6]               0  \n",
       "534  [448720.28]               0  \n",
       "535  [1208638.0]               0  \n",
       "536  [795841.06]               0  \n",
       "537   [558463.3]               0  \n",
       "\n",
       "[538 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21 19:32:01.905</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-21 19:32:01.968</td>\n",
       "      <td>[4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]</td>\n",
       "      <td>[1514079.4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-04-21 19:32:01.905   \n",
       "1 2023-04-21 19:32:01.968   \n",
       "\n",
       "                                                                                                                  in.tensor  \\\n",
       "0        [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "1  [4.0, 3.0, 3710.0, 20000.0, 2.0, 0.0, 2.0, 5.0, 10.0, 2760.0, 950.0, 47.6696, -122.261, 3970.0, 20000.0, 79.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0   [718013.7]               0  \n",
       "1  [1514079.4]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pipeline log retrieval - reverse chronological order\n",
    "\n",
    "# regular_logs = mainpipeline.logs()\n",
    "\n",
    "# display(len(regular_logs))\n",
    "# display(regular_logs)\n",
    "\n",
    "# Display dataframe logs\n",
    "\n",
    "display(dataframe_start.isoformat() )\n",
    "display(dataframe_end.isoformat() )\n",
    "\n",
    "dataframe_logs = mainpipeline.logs(start_datetime=dataframe_start, end_datetime=dataframe_end)\n",
    "\n",
    "display(len(dataframe_logs))\n",
    "display(dataframe_logs)\n",
    "\n",
    "# Display arrow logs\n",
    "\n",
    "display(arrow_start.isoformat() )\n",
    "display(arrow_end.isoformat() )\n",
    "\n",
    "arrow_logs = mainpipeline.logs(start_datetime=arrow_start, end_datetime=arrow_end)\n",
    "\n",
    "display(len(arrow_logs))\n",
    "display(arrow_logs)\n",
    "\n",
    "# Display all logs since dataframe start to arrow end - should be all logs between dataframe and arrow\n",
    "\n",
    "total_logs = mainpipeline.logs(start_datetime=dataframe_start, end_datetime=arrow_end)\n",
    "\n",
    "display(len(total_logs))\n",
    "display(total_logs)\n",
    "\n",
    "\n",
    "# # pipeline log retrieval limited to the last 5 an an arrow table\n",
    "\n",
    "# display(mainpipeline.logs(limit=5, arrow=True))\n",
    "\n",
    "# Notice below - I should get around 538 log messages, but only getting 2 since it's segmenting where the dataframe inputs are versus not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Limits\n",
    "\n",
    "In a previous step we performed 10,000 inferences at once.  If we attempt to pull them at once, we'll likely run into the size limit for this pipeline and receive the following warning message indicating that the pipeline size limits were exceeded and we should use `export_logs` instead.\n",
    "\n",
    "`Warning: Pipeline log size limit exceeded. Only displaying 1000 log messages (of 10000 requested). Please request a file using export_logs.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = mainpipeline.logs(limit=10000)\n",
    "display(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline export_logs Method\n",
    "\n",
    "The Pipeline method `export_logs` returns the Pipeline records as either a DataFrame JSON file, or an Apache Arrow table file.  For full details, see the Wallaroo Pipeline Log Management guide.\n",
    "\n",
    "The `export_logs` method takes the following parameters:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| `limit` | **Int** (*Optional*) | Limits how many log records to display.  Defaults to `100`.  If there are more pipeline logs than are being displayed, the **Warning** message `Pipeline log record limit exceeded` will be displayed.  For example, if 100 log files were requested and there are a total of 1,000, the warning message will be displayed. |\n",
    "| `start` and `end` | **DateTime** (*Optional*) | Limits logs to all logs between the `start` and `end` DateTime parameters.  **Both parameters must be provided**. Submitting a `logs()` request with only `start` or `end` will generate an exception.<br />If `start` and `end` are provided as parameters, then the records are returned in **chronological** order, with the oldest record displayed first. |\n",
    "| `filename` | **String** (*Required*) | The file name to save the log file to.  The requesting user must have write access to the file location. |\n",
    "| `arrow` | **Boolean** (*Optional*) | Defaults to **False**.  If `arrow` is set to `True`, then the logs are returned as an [Apache Arrow table](https://arrow.apache.org/).  If `arrow=False`, then the logs are returned as JSON in pandas DataFrame format. |\n",
    "\n",
    "The following examples demonstrate saving a DataFrame version of the `mainpipeline` logs, then an Arrow version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame version of the log file\n",
    "\n",
    "mainpipeline.export_logs(filename=\"mainpipeline_logs.df.json\")\n",
    "data_df = pd.read_json(\"mainpipeline_logs.df.json\", lines=True)\n",
    "display(data_df)\n",
    "\n",
    "# Save the Arrow version of the log file\n",
    "\n",
    "mainpipeline.export_logs(filename=\"mainpipeline_logs.arrow\", arrow=True)\n",
    "\n",
    "with pa.ipc.open_file(\"mainpipeline_logs.arrow\") as reader:\n",
    "    results = reader.read_all()\n",
    "\n",
    "results.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow Deploy\n",
    "\n",
    "Let's assume that after analyzing the assay information we want to test two challenger models to our control.  We do that with the Shadow Deploy pipeline step.\n",
    "\n",
    "In Shadow Deploy, the pipeline step is added with the `add_shadow_deploy` method, with the champion model listed first, then an array of challenger models after.  **All** inference data is fed to **all** models, with the champion results displayed in the `out.variable` column, and the shadow results in the format `out_{model name}.variable`.  For example, since we named our challenger models `housingchallenger01` and `housingchallenger02`, the columns `out_housingchallenger01.variable` and `out_housingchallenger02.variable` have the shadow deployed model results.\n",
    "\n",
    "For this example, we will remove the previous pipeline step, then replace it with a shadow deploy step with `rf_model.onnx` as our champion, and models `xgb_model.onnx` and `gbr_model.onnx` as the challengers.  We'll deploy the pipeline and prepare it for sample inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the challenger models\n",
    "\n",
    "model_name_challenger01 = 'logcontrolchallenger01'\n",
    "model_file_name_challenger01 = './models/xgb_model.onnx'\n",
    "\n",
    "model_name_challenger02 = 'logcontrolchallenger02'\n",
    "model_file_name_challenger02 = './models/gbr_model.onnx'\n",
    "\n",
    "housing_model_challenger01 = wl.upload_model(model_name_challenger01, model_file_name_challenger01).configure()\n",
    "housing_model_challenger02 = wl.upload_model(model_name_challenger02, model_file_name_challenger02).configure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undeploy the pipeline\n",
    "mainpipeline.undeploy()\n",
    "\n",
    "mainpipeline.clear()\n",
    "\n",
    "# Add the new shadow deploy step with our challenger models\n",
    "mainpipeline.add_shadow_deploy(housing_model_control, [housing_model_challenger01, housing_model_challenger02])\n",
    "\n",
    "# Deploy the pipeline with the new shadow step\n",
    "mainpipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Deploy Sample Inference\n",
    "\n",
    "We'll now use our same sample data for an inference to our shadow deployed pipeline, then display the first 20 results with just the comparative outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_result = mainpipeline.infer_from_file('./data/xtest-1k.arrow')\n",
    "\n",
    "shadow_outputs =  shadow_result.to_pandas()\n",
    "display(shadow_outputs.loc[0:20,['out.variable','out_logcontrolchallenger01.variable','out_logcontrolchallenger02.variable']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadow Deploy Logs\n",
    "\n",
    "Pipelines with a shadow deployed step include the shadow inference result in the same format as the inference result:  inference results from shadow deployed models are displayed as `out_{model name}.{output variable}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display logs with shadow deployed steps\n",
    "\n",
    "display(mainpipeline.logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save shadow deployed log files as DataFrame\n",
    "\n",
    "mainpipeline.export_logs(filename=\"shadowdeploylogs_logs.df.json\")\n",
    "\n",
    "data_df = pd.read_json(\"shadowdeploylogs_logs.df.json\", lines=True)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing Pipeline\n",
    "\n",
    "A/B testing allows inference requests to be split between a control model and one or more challenger models.  For full details, see the [Pipeline Management Guide: A/B Testing](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipeline/#ab-testing).\n",
    "\n",
    "When the inference results and log entries are displayed, they include the column `out._model_split` which displays:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `name` | String | The model name used for the inference.  |\n",
    "| `version` | String| The version of the model. |\n",
    "| `sha` | String | The sha hash of the model version. |\n",
    "\n",
    "For this example, the shadow deployed step will be removed and replaced with an A/B Testing step with the ratio 1:1:1, so the control and each of the challenger models will be split randomly between inference requests.  A set of sample inferences will be run, then the pipeline logs displayed.\n",
    "\n",
    "pipeline = (wl.build_pipeline(\"randomsplitpipeline-demo\")\n",
    "            .add_random_split([(2, control), (1, challenger)], \"session_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpipeline.undeploy()\n",
    "\n",
    "# remove the shadow deploy steps\n",
    "mainpipeline.clear()\n",
    "\n",
    "# Add the a/b test step to the pipeline\n",
    "mainpipeline.add_random_split([(1, housing_model_control), (1, housing_model_challenger01), (1, housing_model_challenger02)], \"session_id\")\n",
    "\n",
    "mainpipeline.deploy()\n",
    "\n",
    "# Perform sample inferences of 20 rows and display the results\n",
    "\n",
    "abtesting_inputs = pd.read_json('./data/xtest-1k.df.json')\n",
    "\n",
    "for index, row in abtesting_inputs.sample(20).iterrows():\n",
    "    display(mainpipeline.infer(row.to_frame('tensor').reset_index()).loc[:,[\"out._model_split\", \"out.variable\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the logs with the a/b testing information\n",
    "\n",
    "display(mainpipeline.logs(limit=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a/b testing log files as DataFrame\n",
    "\n",
    "mainpipeline.export_logs(filename=\"abtestinglogs_logs.df.json\")\n",
    "\n",
    "data_df = pd.read_json(\"abtestinglogs_logs.df.json\", lines=True)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy Main Pipeline\n",
    "\n",
    "With the examples and tutorial complete, we will undeploy the main pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s .................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>pipelinelogpipeline</td></tr><tr><th>created</th> <td>2023-04-21 19:29:16.145012+00:00</td></tr><tr><th>last_updated</th> <td>2023-04-21 19:31:45.629466+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>64152fa1-a331-4204-afd5-f5722945b983, 19498358-db46-4a5e-a6dc-a30e8cbc26eb, 45b7b496-38b1-4ec3-8e9b-38700c52fa0e, 2fb4ba8d-c584-4010-a5fd-6d4fe93a7d8d</td></tr><tr><th>steps</th> <td>logcontrol</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'pipelinelogpipeline', 'create_time': datetime.datetime(2023, 4, 21, 19, 29, 16, 145012, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'logcontrol', 'version': 'd04156bd-2117-46ef-bf92-59df38b98e87', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}]}}]\"}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainpipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
