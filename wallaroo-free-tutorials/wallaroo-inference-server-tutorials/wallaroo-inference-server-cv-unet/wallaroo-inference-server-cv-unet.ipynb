{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cc31df",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/main/pipeline-edge-publish/edge-unet-brain-segmentation-demonstration).\n",
    "\n",
    "## Wallaroo Inference Server:  U-Net for Brain Segmentation\n",
    "\n",
    "This notebook is used in conjunction with the [Wallaroo Inference Server Free Edition](https://docs.wallaroo.ai/wallaroo-inferencing-server/) for U-Net for Brain Segmentation.  This provides a free Wallaroo license for performing inferences through the [U-Net for Brain Segmentation](https://github.com/mateuszbuda/brain-segmentation-pytorch/tree/master) model.  The U-Net model is trained to detect lower-grade gliomas.\n",
    "\n",
    "This tutorial demonstrates how to:\n",
    "\n",
    "* Convert sample images of brain scans to tensor values and perform inferences through the [Wallaroo Inference Server Free Edition](https://docs.wallaroo.ai/wallaroo-inferencing-server/) for U-Net for Brain Segmentation\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* A deployed Wallaroo Inference Server Free Edition with one of the following options:\n",
    "  * **Wallaroo.AI U-Net for Brain MRI Segmentation - x64**\n",
    "* Access via port 8080 to the Wallaroo Inference Server Free Edition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620254f",
   "metadata": {},
   "source": [
    "## U-Net for Brain MRI Segmentation Model Schemas\n",
    "\n",
    "### Inputs\n",
    "input_schema = pa.schema([\n",
    "    pa.field('input', pa.list_(\n",
    "        pa.list_(\n",
    "            pa.list_(\n",
    "                pa.float32(),\n",
    "                list_size=256\n",
    "            ),\n",
    "            list_size=256\n",
    "        ),\n",
    "        list_size=3\n",
    "    )),\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('output', pa.list_(\n",
    "        pa.list_(\n",
    "            pa.list_(\n",
    "                pa.float32(),\n",
    "                list_size=256\n",
    "            ),\n",
    "            list_size=256\n",
    "        ),\n",
    "        list_size=1\n",
    "    )),\n",
    "])\n",
    "\n",
    "\n",
    "The U-Net for Brain MRI Segmentation Model takes the following inputs.\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `input` | List(Float) | Tensor in the shape (n, 3, 256, 256) float.  This is the normalized pixel values of the 640x480 color image.\n",
    "\n",
    "### Outputs\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `output` | Variable length *List[Float]* | A flattened numpy array of detected objects.  When reshaped into a `(1, 256, 256)` returns where the bounding for a detected glioma. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6a9c4",
   "metadata": {},
   "source": [
    "## Wallaroo Inference Server API Endpoints\n",
    "\n",
    "The following HTTPS API endpoints are available for Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28891f9",
   "metadata": {},
   "source": [
    "### Pipelines Endpoint\n",
    "\n",
    "* Endpoint: HTTPS GET `/pipelines`\n",
    "* Returns:\n",
    "  * List of `pipelines` with the following fields.\n",
    "    * **id** (*String*): The name of the pipeline.\n",
    "    * **status** (*String*): The pipeline status.  `Running` indicates the pipeline is available for inferences.\n",
    "\n",
    "#### Pipeline Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Pipelines endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl HOSTNAME:8080/pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639b282",
   "metadata": {},
   "source": [
    "### Models Endpoint\n",
    "\n",
    "* Endpoint: GET `/models`\n",
    "* Returns:\n",
    "  * List of `models` with the following fields.\n",
    "    * **name** (*String*):  The name of the model.\n",
    "    * **sha** (*String*):  The `sha` hash of the model.\n",
    "    * **status** (*String*):  The model status.  `Running` indicates the models is available for inferences.\n",
    "    * **version** (*String*): The model version in UUID format.\n",
    "\n",
    "#### Models Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Models endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl HOSTNAME:8080/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f214d",
   "metadata": {},
   "source": [
    "### Inference Endpoint\n",
    "\n",
    "The following endpoints are available from the Wallaroo Server for Computer Vision Yolov8n deployment.\n",
    "\n",
    "* Endpoint: HTTPS POST `/pipelines/hf-summarizer-standard`\n",
    "* Headers:\n",
    "  * `Content-Type: application/vnd.apache.arrow.file`: For Apache Arrow tables.\n",
    "  * `Content-Type: application/json; format=pandas-records`: For pandas DataFrame in record format.\n",
    "* Input Parameters:   The images **must** be in 640x640 format converted to a float tensor.DataFrame in `application/json; format=pandas-records` **OR** Apache Arrow table in `application/vnd.apache.arrow.file` with the shape `(n, 3, 640, 640)` then flattened, with the tensor values in the field `images`.\n",
    "\n",
    "The following code is used to create a DataFrame from a 640x640 image.\n",
    "\n",
    "  ```python\n",
    "  import cv2\n",
    "  import torch\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  \n",
    "  # load the image from disk, convert to BGR, resize to specified width, height, convert the image back to RGB\n",
    "  # convert the image to a float tensor and returns it.  Also return the original resized image for drawing bounding boxes in BGR\n",
    "  def imageResize(image, 640, 640):\n",
    "      #self.print(\"Image Mode:\"+image.mode)\n",
    "      im_pillow = np.array(image)\n",
    "      image = cv2.cvtColor(im_pillow, cv2.COLOR_BGR2RGB) #scott\n",
    "      image = cv2.flip(im_pillow, 1)\n",
    "      image = cv2.flip(image, 1)\n",
    "      #image = cv2.imread(im_pillow)\n",
    "      #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "      #image = cv2.cvtColor(im_pillow, cv2.COLOR_GRAY2BGR)\n",
    "      self.debug(\"Resizing to w:\"+str(width) + \" height:\"+str(height))\n",
    "      image = cv2.resize(image, (width, height))\n",
    "      \n",
    "      # convert the image from BGR to RGB channel ordering and change the\n",
    "      # image from channels last to channels first ordering\n",
    "      #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      image = image.transpose((2, 0, 1))\n",
    "\n",
    "      # add the batch dimension, scale the raw pixel intensities to the\n",
    "      # range [0, 1], and convert the image to a floating point tensor\n",
    "      image = np.expand_dims(image, axis=0)\n",
    "      image = image / 255.0\n",
    "      tensor = torch.FloatTensor(image)\n",
    "      tensor.flatten()\n",
    "\n",
    "      npArray = tensor.cpu().numpy()\n",
    "      dictData = {\"images\":[npArray]}\n",
    "      dataframedata = pd.DataFrame(dictData)\n",
    "  ```\n",
    "\n",
    "* Returns:\n",
    "  * Headers\n",
    "    * `Content-Type: application/json; format=pandas-records`: pandas DataFrame in record format.\n",
    "  * Data\n",
    "    * **time** (*Integer*): The time since UNIX epoch.\n",
    "    * **in**:  The original input.\n",
    "      * **images**:  The flattened tensor values for the original image.\n",
    "    * **out**: The outputs of the inference result separated by data type.\n",
    "      * **output0**: The float outputs for the inference.  This list is flattened, and when reshaped into `(1,84,8400)` with each **row** correlating to a detected object.  The elements break down as follows:\n",
    "        * [0:3]: The bounding box with the positions left, top, width, height.\n",
    "        * [4:]:  The classes and scores of the detected object.\n",
    "\n",
    "        For more details for breaking down the Yolo8n inference results into objects, see the `CVDemoUtils.py` module with the [Computer Vision Yolov8n Deployment in Wallaroo](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-model-cookbooks/computer-vision-yolov8)\n",
    "\n",
    "    * **check_failures** (*List[Integer]*): Whether any validation checks were triggered.  For more information, see [Wallaroo SDK Essentials Guide: Pipeline Management: Anomaly Testing](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/#anomaly-testing).\n",
    "    * **metadata**: Additional data for the inference.\n",
    "      * **last_model**:  The model used for the inference.\n",
    "        * **model_name** (*String*): The name of the model used.\n",
    "        * **model_sha** (*String*): The sha of the model used.\n",
    "      * **pipeline_version** (*String*): The pipeline version in UUID format.\n",
    "      * **elapsed** (*List[Integer]*): A list of time in nanoseconds for:\n",
    "        * [0] The time to serialize the input.\n",
    "        * [1...n] How long each step took.\n",
    "      * **dropped** (*List*): Any dropped input tables.\n",
    "\n",
    "\n",
    "### Inference Endpoint Example\n",
    "\n",
    "The Wallaroo Inference Server accepts pandas DataFrame or Apache Arrow tables as inference inputs.  The sample file `./data/dogbike.df.json` was converted from the file `./data/dogbike.png` as an example using the helper module `CVDemoUtils` and `WallarooUtils` are used to transform a sample image into a pandas DataFrame.  This DataFrame is then submitted to the Yolov8n model deployed in Wallaroo.\n",
    "\n",
    "The following code segment demonstrates converting the image to a DataFrame.\n",
    "\n",
    "```python\n",
    "from CVDemoUtils import CVDemo\n",
    "from WallarooUtils import Util\n",
    "cvDemo = CVDemo()\n",
    "util = Util()\n",
    "\n",
    "width, height = 640, 640\n",
    "tensor1, resizedImage1 = cvDemo.loadImageAndResize('./data/dogbike.png', width, height)\n",
    "tensor1.flatten()\n",
    "\n",
    "# add the tensor to a DataFrame and save the DataFrame in pandas record format\n",
    "df = util.convert_data(tensor1,'images')\n",
    "df.to_json(\"dogbike.df.json\", orient = 'records')\n",
    "```\n",
    "\n",
    "The following code segment demonstrates performing an inference through the Wallaroo Inference Server with the Yolov8n model deployed.  Replace `HOSTNAME`  with the hostname or IP address of your Wallaroo Inference Server instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_image = Image.open(filename)\n",
    "display(input_image)\n",
    "\n",
    "# preprocess\n",
    "m, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=m, std=s),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "nimage = input_batch.detach().numpy()\n",
    "nimage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e747538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.471237e-05, 1.45947615e-05, 1.3948585e-05, 1.3920239e-05, 1.453936e-05]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = {\n",
    "        'Content-Type': 'application/json; format=pandas-records'\n",
    "    }\n",
    "# \n",
    "\n",
    "deploy_url = 'http://HOSTNAME:8080/pipelines/pt-unet'\n",
    "\n",
    "response = requests.post(\n",
    "                    deploy_url, \n",
    "                    headers=headers, \n",
    "                    data=dataframe.to_json(orient=\"records\")\n",
    "                )\n",
    "\n",
    "display(pd.DataFrame(response.json()).loc[0, 'out']['output'][0][0][0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
