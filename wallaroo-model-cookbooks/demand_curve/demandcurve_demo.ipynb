{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-model-cookbooks/demand_curve).\n",
    "\n",
    "## Demand Curve Pipeline Tutorial\n",
    "\n",
    "This worksheet demonstrates a Wallaroo pipeline with data preprocessing, a model, and data postprocessing.\n",
    "\n",
    "The model is a \"demand curve\" that predicts the expected number of units of a product that will be sold to a customer as a function of unit price and facts about the customer. Such models can be used for price optimization or sales volume forecasting.  This is purely a \"toy\" demonstration, but is useful for detailing the process of working with models and pipelines.\n",
    "\n",
    "Data preprocessing is required to create the features used by the model. Simple postprocessing prevents nonsensical estimates (e.g. negative units sold).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* An installed Wallaroo instance.\n",
    "* The following Python libraries installed:\n",
    "  * `os`\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "import pandas\n",
    "import numpy\n",
    "import conversion\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wallarooPrefix = \"doc-test\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Wallaroo client has been initialized, we can create the workspace and call it `demandcurveworkspace`, then set it as our current workspace.  We'll also create our pipeline so it's ready when we add our models to it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set some variables and methods to create our workspace, pipelines and models.  Note that as of the July 2022 release of Wallaroo, workspace names must be unique.  Pipelines with the same name will be created as a new version when built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'demandcurveworkspace'\n",
    "pipeline_name = 'demandcurvepipeline'\n",
    "model_name = 'demandcurvemodel'\n",
    "model_file_name = './demand_curve_v1.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>demandcurvepipeline</td></tr><tr><th>created</th> <td>2023-07-06 16:13:32.024927+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-06 16:38:54.679586+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>137f0f42-9c4c-4427-9e6e-ff78a53e8301, fa1fe10d-94a2-4227-8665-6bf814089b28, 19c008da-6c0e-4307-b652-d43cc2eba0a6</td></tr><tr><th>steps</th> <td>preprocess</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'demandcurvepipeline', 'create_time': datetime.datetime(2023, 7, 6, 16, 13, 32, 24927, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "demandcurve_pipeline = get_pipeline(pipeline_name)\n",
    "demandcurve_pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our workspace established, we'll upload three models:\n",
    "\n",
    "* `demand_curve_v1.onnx`: Our demand_curve model.  We'll store the upload configuration into `demand_curve_model`.\n",
    "* `preprocess`:  Takes the data and prepares it for the demand curve model.  We'll store the upload configuration into `module_pre`.\n",
    "* `postprocess`:  Takes the results from our demand curve model and prepares it for our display.  We'll store the upload configuration into `module_post`.\n",
    "\n",
    "Note that the order we upload our models isn't important - we'll be establishing the actual process of moving data from one model to the next when we set up our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to wallaroo\n",
    "demand_curve_model = wl.upload_model(model_name, model_file_name).configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the preprocess module\n",
    "module_pre = wl.upload_model(\"preprocess\", \"./preprocess.py\").configure('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the postprocess module\n",
    "module_post = wl.upload_model(\"postprocess\", \"./postprocess.py\").configure('python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our models uploaded, we're going to create our own pipeline and give it three steps:\n",
    "\n",
    "* First, start with the preprocess module we called `module_pre` to prepare the data.\n",
    "* Second, we apply the data to our `demand_curve_model`.\n",
    "* And finally, we prepare our data for output with the `module_post`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>demandcurvepipeline</td></tr><tr><th>created</th> <td>2023-07-06 16:13:32.024927+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-06 16:42:43.522606+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>c634d4f7-f350-4321-9360-6ca011e40bd8, 137f0f42-9c4c-4427-9e6e-ff78a53e8301, fa1fe10d-94a2-4227-8665-6bf814089b28, 19c008da-6c0e-4307-b652-d43cc2eba0a6</td></tr><tr><th>steps</th> <td>preprocess</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'demandcurvepipeline', 'create_time': datetime.datetime(2023, 7, 6, 16, 13, 32, 24927, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess', 'version': '4e610a36-79a2-4a88-85fe-85c976e96dd2', 'sha': 'd952371d541b216adbc9e2fb4e7e25e673bac5d0b2a38505c7d4040df82957fc'}]}}, {'ModelInference': {'models': [{'name': 'demandcurvemodel', 'version': '59e0bf0d-3ca6-4af8-b5d4-a6e4136d6f88', 'sha': '2820b42c9e778ae259918315f25afc8685ecab9967bad0a3d241e6191b414a0d'}]}}, {'ModelInference': {'models': [{'name': 'postprocess', 'version': 'da0f20c9-4bf7-481c-ab43-d75a200df8eb', 'sha': '0649e62625b68a96c722d0e05d8e28fb58ddc96c99543f78039d327896325a54'}]}}]\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now make a pipeline\n",
    "demandcurve_pipeline.clear()\n",
    "demandcurve_pipeline.add_model_step(module_pre)\n",
    "demandcurve_pipeline.add_model_step(demand_curve_model)\n",
    "demandcurve_pipeline.add_model_step(module_post)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that - let's deploy our model pipeline.  This usually takes about 45 seconds for the deployment to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>demandcurvepipeline</td></tr><tr><th>created</th> <td>2023-07-06 16:13:32.024927+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-06 16:45:12.652538+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>7c492cdb-d2f1-4cec-8335-95ae82e8c511, c634d4f7-f350-4321-9360-6ca011e40bd8, 137f0f42-9c4c-4427-9e6e-ff78a53e8301, fa1fe10d-94a2-4227-8665-6bf814089b28, 19c008da-6c0e-4307-b652-d43cc2eba0a6</td></tr><tr><th>steps</th> <td>preprocess</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'demandcurvepipeline', 'create_time': datetime.datetime(2023, 7, 6, 16, 13, 32, 24927, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess', 'version': '4e610a36-79a2-4a88-85fe-85c976e96dd2', 'sha': 'd952371d541b216adbc9e2fb4e7e25e673bac5d0b2a38505c7d4040df82957fc'}]}}, {'ModelInference': {'models': [{'name': 'demandcurvemodel', 'version': '59e0bf0d-3ca6-4af8-b5d4-a6e4136d6f88', 'sha': '2820b42c9e778ae259918315f25afc8685ecab9967bad0a3d241e6191b414a0d'}]}}, {'ModelInference': {'models': [{'name': 'postprocess', 'version': 'da0f20c9-4bf7-481c-ab43-d75a200df8eb', 'sha': '0649e62625b68a96c722d0e05d8e28fb58ddc96c99543f78039d327896325a54'}]}}]\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.deploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the status of our pipeline to make sure everything was set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.3.114',\n",
       "   'name': 'engine-6c4bb7f655-tzpr8',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'demandcurvepipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'demandcurvemodel',\n",
       "      'version': '59e0bf0d-3ca6-4af8-b5d4-a6e4136d6f88',\n",
       "      'sha': '2820b42c9e778ae259918315f25afc8685ecab9967bad0a3d241e6191b414a0d',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'preprocess',\n",
       "      'version': '4e610a36-79a2-4a88-85fe-85c976e96dd2',\n",
       "      'sha': 'd952371d541b216adbc9e2fb4e7e25e673bac5d0b2a38505c7d4040df82957fc',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'postprocess',\n",
       "      'version': 'da0f20c9-4bf7-481c-ab43-d75a200df8eb',\n",
       "      'sha': '0649e62625b68a96c722d0e05d8e28fb58ddc96c99543f78039d327896325a54',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.4.159',\n",
       "   'name': 'engine-lb-584f54c899-pjgww',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready.  Let's feed our pipeline some data.  We have some information prepared with the `daily_purchasses.csv` spreadsheet.  We'll start with just one row to make sure that everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in some purchase data\n",
    "purchases = pandas.read_csv('daily_purchases.csv')\n",
    "\n",
    "# start with a one-row data frame for testing\n",
    "subsamp_raw = purchases.iloc[0:1,: ]\n",
    "subsamp_raw\n",
    "\n",
    "# create the input dictionary from the original one-line dataframe\n",
    "input_dict = conversion.pandas_to_dict(subsamp_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/deployment.py:532: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tensor[col] = flatten_np_array_columns(tensor, col)\n"
     ]
    },
    {
     "ename": "InferenceError",
     "evalue": "Inference failed: \n\tInternalError: Error running inference {\"error\": \"Python: Exception: <class 'AttributeError'>, 'str' object has no attribute 'copy'\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_make_infer_request\u001b[0;34m(self, data, headers, params, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m             )\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://doc-test.api.wallaroocommunity.ninja/v1/api/pipelines/infer/demandcurvepipeline-8/demandcurvepipeline?dataset%5B%5D=%2A&dataset.exclude%5B%5D=metadata&dataset.separator=.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInferenceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/_cj0q9d51s365wksymljdz4h0000gn/T/ipykernel_83851/1462739925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# result = demandcurve_pipeline.infer(input_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemandcurve_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamp_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             self._last_infer_time = max(\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mdeployment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deployment_for_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return deployment.infer(\n\u001b[0m\u001b[1;32m    636\u001b[0m                 \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_exclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_separator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             )\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 )\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_with_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_with_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_infer_with_pandas\u001b[0;34m(self, tensor, params, timeout)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPANDAS_RECORDS_HEADER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         }\n\u001b[0;32m--> 537\u001b[0;31m         res = self._make_infer_request(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_records\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk2023.2.1/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_make_infer_request\u001b[0;34m(self, data, headers, params, timeout)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInferenceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         except (\n\u001b[1;32m    639\u001b[0m             \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInferenceError\u001b[0m: Inference failed: \n\tInternalError: Error running inference {\"error\": \"Python: Exception: <class 'AttributeError'>, 'str' object has no attribute 'copy'\"}"
     ]
    }
   ],
   "source": [
    "result = demandcurve_pipeline.infer(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the `prediction` field that the demand curve has a predicted slope of 6.68 from our sample data.  We can isolate that by specifying just the data output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.68025518653071]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result[0]['prediction'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial test went perfectly.  Now let's throw some more data into our pipeline.  We'll draw 10 random rows from our spreadsheet, perform an inference from that, and then display the results and the logs showing the pipeline's actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do 10 rows at once (drawn randomly)\n",
    "ix = numpy.random.choice(purchases.shape[0], size=10, replace=False)\n",
    "output = demandcurve_pipeline.infer(conversion.pandas_to_dict(purchases.iloc[ix,: ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.57067889202563,\n",
       " 6.68025518653071,\n",
       " 40.57067889202563,\n",
       " 9.110871146224234,\n",
       " 33.125323160373426,\n",
       " 33.125323160373426,\n",
       " 33.125323160373426,\n",
       " 40.57067889202563,\n",
       " 6.771545926800889,\n",
       " 40.57067889202563]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output[0]['prediction'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy the Pipeline\n",
    "\n",
    "Once we've finished with our demand curve demo, we'll undeploy the pipeline and give the resources back to our Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>demandcurvepipeline</td></tr><tr><th>created</th> <td>2023-07-06 16:13:32.024927+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-06 16:45:12.652538+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>7c492cdb-d2f1-4cec-8335-95ae82e8c511, c634d4f7-f350-4321-9360-6ca011e40bd8, 137f0f42-9c4c-4427-9e6e-ff78a53e8301, fa1fe10d-94a2-4227-8665-6bf814089b28, 19c008da-6c0e-4307-b652-d43cc2eba0a6</td></tr><tr><th>steps</th> <td>preprocess</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'demandcurvepipeline', 'create_time': datetime.datetime(2023, 7, 6, 16, 13, 32, 24927, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess', 'version': '4e610a36-79a2-4a88-85fe-85c976e96dd2', 'sha': 'd952371d541b216adbc9e2fb4e7e25e673bac5d0b2a38505c7d4040df82957fc'}]}}, {'ModelInference': {'models': [{'name': 'demandcurvemodel', 'version': '59e0bf0d-3ca6-4af8-b5d4-a6e4136d6f88', 'sha': '2820b42c9e778ae259918315f25afc8685ecab9967bad0a3d241e6191b414a0d'}]}}, {'ModelInference': {'models': [{'name': 'postprocess', 'version': 'da0f20c9-4bf7-481c-ab43-d75a200df8eb', 'sha': '0649e62625b68a96c722d0e05d8e28fb58ddc96c99543f78039d327896325a54'}]}}]\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.undeploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for being a part of this demonstration.  If you have additional questions, please feel free to contact us at Wallaroo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
