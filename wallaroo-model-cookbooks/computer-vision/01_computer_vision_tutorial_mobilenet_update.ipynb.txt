{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-model-cookbooks/computer-vision).\n",
    "\n",
    "## Step 01: Detecting Objects Using mobilenet\n",
    "\n",
    "The following tutorial demonstrates how to use a trained mobilenet model deployed in Wallaroo to detect objects.  This process will use the following steps:\n",
    "\n",
    "1. Create a Wallaroo workspace and pipeline.\n",
    "1. Upload a trained mobilenet ML model and add it as a pipeline step.\n",
    "1. Deploy the pipeline.\n",
    "1. Perform an inference on a sample image.\n",
    "1. Draw the detected objects, their bounding boxes, their classifications, and the confidence of the classifications on the provided image.\n",
    "1. Review our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step will be to import our libraries.  Please check with **Step 00: Introduction and Setup** and verify that the necessary libraries and applications are added to your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from CVDemoUtils import CVDemo\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallaroo.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Now we connect to the Wallaroo instance.  If you are connecting from a remote connection, set the `wallarooPrefix` and `wallarooSuffix` and use them to connect.  If the connection is from within the Wallaroo instance cluster, then just `wl = wallaroo.Client()` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local service\n",
    "\n",
    "# wl = wallaroo.Client()\n",
    "\n",
    "# SSO login through keycloak\n",
    "\n",
    "wallarooPrefix = \"YOUR PREFIX\"\n",
    "wallarooSuffix = \"YOUR SUFFIX\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrow Support\n",
    "\n",
    "As of the 2023.1 release, Wallaroo provides support for DataFrame and Arrow for inference inputs.  This tutorial allows users to adjust their experience based on whether they have enabled Arrow support in their Wallaroo instance or not.\n",
    "\n",
    "If Arrow support has been enabled, `arrowEnabled=True`. If disabled or you're not sure, set it to `arrowEnabled=False`\n",
    "\n",
    "The examples below will be shown in an arrow enabled environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables\n",
    "\n",
    "The following variables and methods are used later to create or connect to an existing workspace, pipeline, and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'mobilenetworkspacetest'\n",
    "pipeline_name = 'mobilenetpipeline'\n",
    "model_name = 'mobilenet'\n",
    "model_file_name = 'models/mobilenet.pt.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workspace\n",
    "\n",
    "The workspace will be created or connected to, and set as the default workspace for this session.  Once that is done, then all models and pipelines will be set in that workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "wl.set_current_workspace(workspace)\n",
    "wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline and Upload Model\n",
    "\n",
    "We will now create or connect to an existing pipeline as named in the variables above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(pipeline_name)\n",
    "mobilenet_model = wl.upload_model(model_name, model_file_name, framework=Framework.ONNX).configure(batch_config=\"single\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "With the model uploaded, we can add it is as a step in the pipeline, then deploy it.  Once deployed, resources from the Wallaroo instance will be reserved and the pipeline will be ready to use the model to perform inference requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_model_step(mobilenet_model)\n",
    "deployment_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(1).memory(\"1Gi\").build() \n",
    "pipeline.deploy(deployment_config =deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input image\n",
    "\n",
    "Next we will load a sample image and resize it to the width and height required for the object detector.  Once complete, it the image will be converted to a numpy ndim array and added to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "cvDemo = CVDemo()\n",
    "\n",
    "imagePath = 'data/images/input/example/dairy_bottles.png'\n",
    "\n",
    "# The image width and height needs to be set to what the model was trained for.  In this case 640x480.\n",
    "tensor, resizedImage = cvDemo.loadImageAndResize(imagePath, width, height)\n",
    "\n",
    "# get npArray from the tensorFloat\n",
    "npArray = tensor.cpu().numpy()\n",
    "\n",
    "#creates a dictionary with the wallaroo \"tensor\" key and the numpy ndim array representing image as the value.\n",
    "dictData = {\"tensor\":[npArray]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframedata = pd.DataFrame(dictData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run Inference\n",
    "\n",
    "With that done, we can have the model detect the objects on the image by running an inference through the pipeline, and storing the results for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "infResults = pipeline.infer(dataframedata)\n",
    "endTime = time.time()\n",
    "\n",
    "if arrowEnabled is True:\n",
    "    results = infResults[0]\n",
    "else:\n",
    "    results = infResults[0].raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the Inference Results\n",
    "\n",
    "With our inference results, we can take them and use the Wallaroo CVDemo class and draw them onto the original image.  The bounding boxes and the confidence value will only be drawn on images where the model returned a 90% confidence rate in the object's identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['classification','confidence','x','y','width','height'])\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.float_format = '{:.2%}'.format\n",
    "\n",
    "# Points to where all the inference results are\n",
    "outputs = results['outputs']\n",
    "boxes = outputs[0]\n",
    "\n",
    "# reshape this to an array of bounding box coordinates converted to ints\n",
    "boxList = boxes['Float']['data']\n",
    "boxA = np.array(boxList)\n",
    "boxes = boxA.reshape(-1, 4)\n",
    "boxes = boxes.astype(int)\n",
    "\n",
    "df[['x', 'y','width','height']] = pd.DataFrame(boxes)\n",
    "\n",
    "classes = outputs[1]['Int64']['data']\n",
    "confidences = outputs[2]['Float']['data']\n",
    "\n",
    "infResults = {\n",
    "    'model_name' : model_name,\n",
    "    'pipeline_name' : pipeline_name,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'image' : resizedImage,\n",
    "    'boxes' : boxes,\n",
    "    'classes' : classes,\n",
    "    'confidences' : confidences,\n",
    "    'confidence-target' : 0.90,\n",
    "    'inference-time': (endTime-startTime),\n",
    "    'onnx-time' : int(results['elapsed']) / 1e+9,                \n",
    "    'color':(255,0,0)\n",
    "}\n",
    "\n",
    "image = cvDemo.drawAndDisplayDetectedObjectsWithClassification(infResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Inference Information\n",
    "\n",
    "To show what is going on in the background, we'll extract the inference results create a dataframe with columns representing the classification, confidence, and bounding boxes of the objects identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "for idx in range(0,len(classes)):\n",
    "    df['classification'][idx] = cvDemo.CLASSES[classes[idx]] # Classes contains the 80 different COCO classificaitons\n",
    "    df['confidence'][idx] = confidences[idx]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "With the inference complete, we can undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d.undeploy() for d in wl.list_deployments()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl.list_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb2d5a211cf7fee4614d0b9047a0972c7d6bf7ecea2ecd0ade6beeb12bbc9c8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
