{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Wallaroo Shadow Deployment in Computer Vision - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will explore using Wallaroo's Shadow Deployment Technology to safely improve your Object Detectors inference capabilities in a production environments.\n",
    "\n",
    "We will configure the pipeline to use a shadow deployment where the control is the production mobilenet object detector.  We will configure a challenger resnet50 object detector.\n",
    "\n",
    "Both object detectors will perform inference on each frame in the video and the objects they detect, their bounding boxes, and the classification confidence will be drawn on the frame.\n",
    "\n",
    "Our goal is to study the video and its statistics to learn if the new challenger resnet50 object performs better than  the control mobilenet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /opt/conda/lib/python3.9/site-packages (0.5.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (2022.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "!pip install pytz\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import wallaroo\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import imutils\n",
    "from CVDemoUtils import CVDemo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize some Vars\n",
    "\n",
    "Initialize the COCO Classes, meaning the classificaitons found on the images and the default width and height all images are resized to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wl.list_workspaces()\n",
    "for w in ws:\n",
    "    if w.name() == 'computer-vision':\n",
    "        wl.set_current_workspace(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "control =  wl.upload_model('mobilenet', 'models/mobilenet.pt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_list  = [ \n",
    "    wl.upload_model('resnet50', 'models/frcnn-resnet.pt.onnx')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(1).memory(\"12Gi\").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ..... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>shadow-pp</td></tr><tr><th>created</th> <td>2022-11-08 20:04:56.582490+00:00</td></tr><tr><th>last_updated</th> <td>2022-11-09 18:13:21.103084+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>resnet50</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'shadow-pp', 'create_time': datetime.datetime(2022, 11, 8, 20, 4, 56, 582490, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'mobilenet', 'version': '0082c84c-4446-4884-ae47-1e7d344eb7cb', 'sha': 'f4c7009e53b679f5e44d70d9612e8dc365565cec88c25b5efa11b903b6b7bdc6'}, {'name': 'resnet50', 'version': 'd293ea2e-58a3-4220-88ea-ac1f8ae8ac8f', 'sha': 'ee606dc9776a1029420b3adf59b6d29395c89d1d9460d75045a1f2f152d288e7'}]}}, {'AuditResults': {'from': 1, 'to': None}}, {'MultiOut': {}}]\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = wl.build_pipeline(\"shadow-pp\")\n",
    "pipeline.add_shadow_deploy(control, challenger_list)\n",
    "pipeline.deploy(deployment_config = deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://engine-lb.shadow-pp-895:29502/pipelines/shadow-pp\n"
     ]
    }
   ],
   "source": [
    "time.sleep(5) # needed to allow the pipeline to settle in.\n",
    "url = pipeline._deployment._url()\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from CVDemoUtils import CVDemo\n",
    "\n",
    "# set the device we will be using to run the model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# The set of COCO classifications\n",
    "CLASSES = pickle.loads(open(\"models/coco_classes.pickle\", \"rb\").read())\n",
    "\n",
    "# Unique colors for each identified COCO class\n",
    "COLORS = [CVDemo.BLUE, CVDemo.RED]\n",
    "\n",
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "confidence_target = 0.75\n",
    "\n",
    "cvDemo = CVDemo(CLASSES,COLORS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect and Classify Objects in Video using Wallaroo Shadow Deployment\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-09-2022 18:13:33.977844 Start Time:01:13:33 PM\n",
      "11-09-2022 18:13:33.977934 Skipping [100] frames\n",
      "11-09-2022 18:13:33.977946 Captureing up to [300] frames\n",
      "11-09-2022 18:13:33.983652 Video Properties\n",
      "11-09-2022 18:13:33.983725    format:0.0\n",
      "11-09-2022 18:13:33.983736    fourcc:828601953.0\n",
      "11-09-2022 18:13:33.983744    mode:0.0\n",
      "11-09-2022 18:13:33.983752    buffer:0.0\n",
      "11-09-2022 18:13:33.983760    width:1280.0\n",
      "11-09-2022 18:13:33.983767    height:720.0\n",
      "11-09-2022 18:13:33.983774    fps:25.0\n",
      "11-09-2022 18:13:33.983781    frame count:16054.0\n",
      "11-09-2022 18:13:39.802007 Frame:1 Read: 0.0011 Inf: 5.4701 Onnx: 0.0000 Draw: 0.0057 Total: 5.5512\n",
      "11-09-2022 18:13:44.869342 Frame:2 Read: 0.0012 Inf: 5.0188 Onnx: 0.0000 Draw: 0.0063 Total: 5.0672\n",
      "11-09-2022 18:13:50.218690 Frame:3 Read: 0.0011 Inf: 5.2998 Onnx: 0.0000 Draw: 0.0057 Total: 5.3492\n",
      "11-09-2022 18:13:55.516640 Frame:4 Read: 0.0011 Inf: 5.2498 Onnx: 0.0000 Draw: 0.0056 Total: 5.2978\n",
      "11-09-2022 18:14:00.807651 Frame:5 Read: 0.0011 Inf: 5.2402 Onnx: 0.0000 Draw: 0.0053 Total: 5.2908\n",
      "11-09-2022 18:14:06.025946 Frame:6 Read: 0.0014 Inf: 5.1558 Onnx: 0.0000 Draw: 0.0057 Total: 5.2181\n",
      "11-09-2022 18:14:11.504236 Frame:7 Read: 0.0011 Inf: 5.4282 Onnx: 0.0000 Draw: 0.0056 Total: 5.4781\n",
      "11-09-2022 18:14:16.662195 Frame:8 Read: 0.0014 Inf: 5.1057 Onnx: 0.0000 Draw: 0.0056 Total: 5.1574\n",
      "11-09-2022 18:14:22.186408 Frame:9 Read: 0.0011 Inf: 5.4753 Onnx: 0.0000 Draw: 0.0057 Total: 5.5241\n",
      "11-09-2022 18:14:22.775186 Exiting\n",
      "11-09-2022 18:14:22.795640 End Time:13:14:22\n",
      "We are done.\n"
     ]
    }
   ],
   "source": [
    "cvDemo = CVDemo(CLASSES,COLORS, DEVICE)\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "input_video = \"videos/amazon-fresh-go.mp4\"\n",
    "output_video = \"videos/amazon-fresh-go-shadow-part-1-inferenced.mp4\"\n",
    "cur_ws = wl.get_current_workspace()\n",
    "config = {\n",
    "    'input-video' : input_video, # source video\n",
    "    'output-video' : output_video, # show the input video with the inferenced results drawn on each frame\n",
    "    'fps' : 25, # Frames per second\n",
    "    'pipeline' : pipeline,\n",
    "    'control-model' : control,\n",
    "    'challenger-model-list' : challenger_list,\n",
    "    'endpoint-url' : url, # the pipelines rest api endpoint url\n",
    "    'width' : width, # the width of the url\n",
    "    'height' : height, # the height of the url\n",
    "    'max-frames' : 300, # the # of frames to capture in the output video\n",
    "    'skip-frames' : 100, # the # of frames to capture in the output video\n",
    "    'confidence-target' : 0.90, # only display bounding boxes with confidence > provided #\n",
    "    'inference': 'WALLAROO_SDK',\n",
    "}\n",
    "cvDemo.DEBUG = False\n",
    "cvDemo.detectAndClassifyObjectsInVideoUsingShadowDeployment(config)\n",
    "print(\"We are done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n"
     ]
    }
   ],
   "source": [
    "#pipeline.undeploy()\n",
    "for d in wl.list_deployments():\n",
    "    d.undeploy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Notice the difference in the control confidence and the challenger confidence.  Clearly we can see in this example the Control resnet50 model is performing better than the mobilenet.  This is likely due to the fact that frcnn resnet50 model is a 2 stage object detector vs the mobilenet is a single stage detector.\n",
    "\n",
    "In the next example we will take this to another level and see what happens when we use shadow deployment in a video in order to achieve the best of both worlds.  Highest accuracy with the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
