{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Wallaroo Shadow Deployment in Computer Vision - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have learned a little bit about how both object detectors perform, what if we could have the best of both worlds.\n",
    "\n",
    "In this tutorial we will once again configure the pipeline to use a shadow deployment where the control is the production mobilenet object detector.  We will configure a challenger resnet50 object detector.\n",
    "\n",
    "Both object detectors will once again perform inference on each frame in the video and the objects they detect, <b>but only the object detector with the highest average confidence score will be used.</b>\n",
    "\n",
    "Our goal is to increase our inference success rate from 85% to 95% by choosing the object detector with the highest avareage confidence score in each frame.\n",
    "\n",
    "After you execute this notebook and download the video, you might want to set the playback speed to 0.25 or 0.50 to see the results at a speed we humans can process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /opt/conda/lib/python3.9/site-packages (0.5.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (2022.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.9/site-packages (9.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "!pip install pytz\n",
    "!pip install more-itertools\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import wallaroo\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import imutils\n",
    "from CVDemoUtils import CVDemo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize some Vars\n",
    "\n",
    "Initialize the COCO Classes, meaning the classificaitons found on the images and the default width and height all images are resized to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wl.list_workspaces()\n",
    "for w in ws:\n",
    "    if w.name() == 'computer-vision':\n",
    "        wl.set_current_workspace(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "control =  wl.upload_model('mobilenet', 'models/mobilenet.pt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_list  = [ \n",
    "    wl.upload_model('resnet50', 'models/frcnn-resnet.pt.onnx')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(2).memory(\"8Gi\").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ..... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>shadow-pp</td></tr><tr><th>created</th> <td>2022-11-08 20:04:56.582490+00:00</td></tr><tr><th>last_updated</th> <td>2022-11-09 15:56:10.916084+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>resnet50</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'shadow-pp', 'create_time': datetime.datetime(2022, 11, 8, 20, 4, 56, 582490, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'mobilenet', 'version': '9f1f42b5-e525-4ce8-88ac-bbf7cbba8183', 'sha': 'f4c7009e53b679f5e44d70d9612e8dc365565cec88c25b5efa11b903b6b7bdc6'}, {'name': 'resnet50', 'version': 'b230bacc-038e-4a3e-9f70-4be63f9cb58b', 'sha': 'ee606dc9776a1029420b3adf59b6d29395c89d1d9460d75045a1f2f152d288e7'}]}}, {'AuditResults': {'from': 1, 'to': None}}, {'MultiOut': {}}]\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = wl.build_pipeline(\"shadow-pp\")\n",
    "pipeline.add_shadow_deploy(control, challenger_list)\n",
    "pipeline.deploy(deployment_config = deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://engine-lb.shadow-pp-895:29502/pipelines/shadow-pp\n"
     ]
    }
   ],
   "source": [
    "time.sleep(5) # needed to allow the pipeline to settle in.\n",
    "url = pipeline._deployment._url()\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from CVDemoUtils import CVDemo\n",
    "\n",
    "# set the device we will be using to run the model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# The set of COCO classifications\n",
    "CLASSES = pickle.loads(open(\"models/coco_classes.pickle\", \"rb\").read())\n",
    "\n",
    "# Unique colors for each identified COCO class\n",
    "#COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "COLORS = [CVDemo.BLUE, CVDemo.RED]\n",
    "\n",
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "confidence_target = 0.75\n",
    "\n",
    "cvDemo = CVDemo(CLASSES,COLORS, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect and Classify Objects in Video using Wallaroo Shadow Deployment\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-09-2022 15:56:21.861089 Start Time:10:56:21 AM\n",
      "11-09-2022 15:56:21.861263 Skipping [100] frames\n",
      "11-09-2022 15:56:21.861278 Captureing up to [1000] frames\n",
      "11-09-2022 15:56:21.871960 Video Properties\n",
      "11-09-2022 15:56:21.872033    format:0.0\n",
      "11-09-2022 15:56:21.872044    fourcc:828601953.0\n",
      "11-09-2022 15:56:21.872052    mode:0.0\n",
      "11-09-2022 15:56:21.872060    buffer:0.0\n",
      "11-09-2022 15:56:21.872067    width:1280.0\n",
      "11-09-2022 15:56:21.872075    height:720.0\n",
      "11-09-2022 15:56:21.872082    fps:25.0\n",
      "11-09-2022 15:56:21.872089    frame count:12721.0\n",
      "11-09-2022 15:56:25.388767 best model=mobilenet\n",
      "11-09-2022 15:56:25.393721 Frame:1 Read: 0.0010 Inf: 3.3042 Onnx: 0.0000 Draw: 0.0047 Total: 3.3571\n",
      "11-09-2022 15:56:29.182804 best model=mobilenet\n",
      "11-09-2022 15:56:29.187375 Frame:2 Read: 0.0014 Inf: 3.7453 Onnx: 0.0000 Draw: 0.0044 Total: 3.7936\n",
      "11-09-2022 15:56:32.453588 best model=mobilenet\n",
      "11-09-2022 15:56:32.458737 Frame:3 Read: 0.0011 Inf: 3.2230 Onnx: 0.0000 Draw: 0.0047 Total: 3.2713\n",
      "11-09-2022 15:56:36.357032 best model=mobilenet\n",
      "11-09-2022 15:56:36.360735 Frame:4 Read: 0.0014 Inf: 3.8552 Onnx: 0.0000 Draw: 0.0034 Total: 3.9019\n",
      "11-09-2022 15:56:39.855618 best model=mobilenet\n",
      "11-09-2022 15:56:39.859662 Frame:5 Read: 0.0012 Inf: 3.4519 Onnx: 0.0000 Draw: 0.0038 Total: 3.4989\n",
      "11-09-2022 15:56:43.426119 best model=mobilenet\n",
      "11-09-2022 15:56:43.429741 Frame:6 Read: 0.0011 Inf: 3.5231 Onnx: 0.0000 Draw: 0.0034 Total: 3.5700\n",
      "11-09-2022 15:56:47.063906 best model=mobilenet\n",
      "11-09-2022 15:56:47.067669 Frame:7 Read: 0.0011 Inf: 3.5904 Onnx: 0.0000 Draw: 0.0035 Total: 3.6379\n",
      "11-09-2022 15:56:50.348664 best model=resnet50\n",
      "11-09-2022 15:56:50.352796 Frame:8 Read: 0.0011 Inf: 3.2332 Onnx: 0.0000 Draw: 0.0039 Total: 3.2851\n",
      "11-09-2022 15:56:54.050552 best model=resnet50\n",
      "11-09-2022 15:56:54.054593 Frame:9 Read: 0.0011 Inf: 3.6517 Onnx: 0.0000 Draw: 0.0038 Total: 3.7017\n",
      "11-09-2022 15:56:57.663461 best model=resnet50\n",
      "11-09-2022 15:56:57.667392 Frame:10 Read: 0.0011 Inf: 3.5648 Onnx: 0.0000 Draw: 0.0037 Total: 3.6127\n",
      "11-09-2022 15:57:01.160369 best model=resnet50\n",
      "11-09-2022 15:57:01.164203 Frame:11 Read: 0.0014 Inf: 3.4510 Onnx: 0.0000 Draw: 0.0036 Total: 3.4968\n",
      "11-09-2022 15:57:04.934254 best model=resnet50\n",
      "11-09-2022 15:57:04.938198 Frame:12 Read: 0.0011 Inf: 3.7272 Onnx: 0.0000 Draw: 0.0037 Total: 3.7739\n",
      "11-09-2022 15:57:08.270995 best model=resnet50\n",
      "11-09-2022 15:57:08.275874 Frame:13 Read: 0.0011 Inf: 3.2896 Onnx: 0.0000 Draw: 0.0047 Total: 3.3376\n",
      "11-09-2022 15:57:12.049103 best model=mobilenet\n",
      "11-09-2022 15:57:12.053021 Frame:14 Read: 0.0014 Inf: 3.7304 Onnx: 0.0000 Draw: 0.0035 Total: 3.7771\n",
      "11-09-2022 15:57:15.729552 best model=resnet50\n",
      "11-09-2022 15:57:15.733425 Frame:15 Read: 0.0011 Inf: 3.6329 Onnx: 0.0000 Draw: 0.0037 Total: 3.6803\n",
      "11-09-2022 15:57:16.281436 Exiting\n",
      "11-09-2022 15:57:16.302361 End Time:10:57:16\n",
      "We are done.\n"
     ]
    }
   ],
   "source": [
    "cvDemo = CVDemo(CLASSES,COLORS, DEVICE)\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "input_video = \"videos/amazon-fresh-go.mp4\"\n",
    "input_video = \"videos/ww2-warbirds-in-formation.mp4\"\n",
    "output_video = \"videos/ww2-warbirds-in-formation-inferenced.mp4\"\n",
    "\n",
    "cur_ws = wl.get_current_workspace()\n",
    "config = {\n",
    "    'input-video' : input_video, # source video\n",
    "    'output-video' : output_video, # show the input video with the inferenced results drawn on each frame\n",
    "    'fps' : 25, # Frames per second\n",
    "    'pipeline' : pipeline,\n",
    "    'control-model' : control,\n",
    "    'challenger-model-list' : challenger_list,\n",
    "    'width' : width, # the width of the url\n",
    "    'height' : height, # the height of the url\n",
    "    'max-frames' : 1000, # the # of frames to capture in the output video\n",
    "    'skip-frames' : 100, # the # of frames to capture in the output video\n",
    "    'confidence-target' : 0.90, # only display bounding boxes with confidence > provided #\n",
    "    'model-cnt': 2,\n",
    "    'inference': 'WALLAROO_SDK',\n",
    "    'color': CVDemo.BLUE\n",
    "}\n",
    "cvDemo.DEBUG = False\n",
    "cvDemo.useBestObjectDetectorInVideoUsingShadowDeployment(config)\n",
    "print(\"We are done.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in wl.list_deployments():\n",
    "#    d.undeploy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Notice the difference in the control confidence and the challenger confidence.  Clearly we can see in this example the Control resnet50 model is performing better than the mobilenet.  This is likely due to the fact that frcnn resnet50 model is a 2 stage object detector vs the mobilenet is a single stage detector.\n",
    "\n",
    "In the next example we will take this to another level and see what happens when we use shadow deployment in a video in order to achieve the best of both worlds.  Highest accuracy with the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
