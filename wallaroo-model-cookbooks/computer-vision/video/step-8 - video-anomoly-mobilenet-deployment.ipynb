{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Anomalies using the Wallaroo mobilenet Pipeline in a Video Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will explore using the mobilenet pipeline we created in step 3 to run inference on the frames in a Video and then draw the identified object's bounding boxes, classification and classification confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import wallaroo\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import imutils\n",
    "from CVDemoUtils import CVDemo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wl.list_workspaces()\n",
    "for w in ws:\n",
    "    if w.name() == 'computer-vision':\n",
    "        wl.set_current_workspace(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenet'\n",
    "mobilenet_model = wl.upload_model('mobilenet', \"models/mobilenet.pt.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will add our post processing anomoly detection file called post-process-anomoly-detection.py.  Predictions that are lower than 75% we will consider anomalies that need to be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_anomoly_detection = wl.upload_model(\"post-process-anomoly-detection\", \"./post-process-anomoly-detection.py\").configure('python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy our custom anomoly detection\n",
    "\n",
    "Next we will deploy our pipeline with the custom anomoly detection logic as a post processing step in our pipeline.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(1).memory(\"8Gi\").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'anomoly-pp'\n",
    "pipeline = wl.build_pipeline(pipeline_name) \\\n",
    "            .add_model_step(mobilenet_model) \\\n",
    "            .add_model_step(module_anomoly_detection)\n",
    "\n",
    "pipeline.deploy(deployment_config = deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5) # needed to allow the pipeline to settle in.\n",
    "url = pipeline._deployment._url()\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the pipeline in a video stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize some Vars\n",
    "\n",
    "Initialize the COCO Classes, meaning the classificaitons found on the images and the default width and height all images are resized to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from CVDemoUtils import CVDemo\n",
    "\n",
    "# set the device we will be using to run the model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# The set of COCO classifications\n",
    "CLASSES = pickle.loads(open(\"models/coco_classes.pickle\", \"rb\").read())\n",
    "\n",
    "# Unique colors for each identified COCO class\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "confidence_target = 0.75\n",
    "\n",
    "cvDemo = CVDemo(CLASSES,COLORS, DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Detect and Classify Anomalies in the Video Stream\n",
    "\n",
    "Next we will load each frame in the input-video feed itto the pipeline for inferencing.  The pipeline will perform normal inferencing logic and then before returning the results execute our custom anomoly detection.  The anomalies detected, meaning their bounding boxes, their classification and confidence of classifications are included in the inferencing results.\n",
    "\n",
    "We use these results to draw all the anomalies their bounding boxes, each identified object,  its classification, and the model's confidence that the prediction and then save the frame to an output video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "#input_video = \"videos/amazon-fresh-go.mp4\"\n",
    "#output_video = \"videos/amazon-fresh-go-inferenced.mp4\"\n",
    "\n",
    "input_video = \"videos/ww2-warbirds-in-formation.mp4\"\n",
    "output_video = \"videos/ww2-warbirds-in-formation-anomalies.mp4\"\n",
    "\n",
    "config = {\n",
    "    'input-video' : input_video, # source video\n",
    "    'output-video' : output_video, # show the input video with the inferenced results drawn on each frame\n",
    "    'fps' : 15, # Frames per second\n",
    "    'width' : width, # the width of the url\n",
    "    'height' : height, # the height of the url\n",
    "    #'max-frames' : 400, # the # of frames to capture in the output video\n",
    "    'skip-frames' : 50, # the # of frames to capture in the output video\n",
    "    'color':CVDemo.ORANGE, # color to draw bounding boxes and the text in the statistics\n",
    "     #'inference' : 'WALLAROO_SDK' is only supported for anomalies right now\n",
    "    'model_name' : model_name,\n",
    "    'pipeline' : pipeline, # provide this when using inference WALLAROO_SDK \n",
    "    'pipeline_name' : pipeline_name,\n",
    "    'record-start-frame' : 51, # the # of frames to capture in the output video\n",
    "    'record-end-frame' : 151, # the # of frames to capture in the output video  \n",
    "}\n",
    "cvDemo.DEBUG = False\n",
    "cvDemo.detectAndClassifyAnomaliesInVideo(config)\n",
    "print(\"We are done.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Notice how simple it is to take the mobilenet object detectors rest api endpoint url and use it in a video stream.  Now its your turn.  Upload a video to this notebook and replace the input-video with the path of the uploaded video.  Update the output video accordingly.\n",
    "\n",
    "See how well it works for you.  Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s .................................... ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      " ok\n",
      "Waiting for undeployment - this will take up to 45s ............................."
     ]
    }
   ],
   "source": [
    "#pipeline.undeploy()\n",
    "#for d in wl.list_deployments():\n",
    "#    d.undeploy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
