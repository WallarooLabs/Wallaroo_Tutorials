{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Objects using the Wallaroo mobilenet Pipeline in a Video Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will explore using the mobilenet pipeline we created in step 3 to run inference on the frames in a Video and then draw the identified object's bounding boxes, classification and classification confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import wallaroo\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "from CVDemoUtils import CVDemo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wl.list_workspaces()\n",
    "for w in ws:\n",
    "    if w.name() == 'computer-vision':\n",
    "        wl.set_current_workspace(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = wl.upload_model(model_name, \"models/mobilenet.pt.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wl.upload_model('post-process', \"post-process.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(1).memory(\"8Gi\").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ..........................................."
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>*** An error occurred while deploying your pipeline.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "WaitForDeployError",
     "evalue": "Cannot deploy pipeline due to insufficient resources. Your pipeline needs 8Gi of memory to run but there is not enough memory currently available. Please try again or un-deploy pipelines not in use to adjust the resources that are available for your Wallaroo instance. Contact your Wallaroo platform administrator for additional support.",
     "output_type": "error",
     "traceback": [
      "Cannot deploy pipeline due to insufficient resources. Your pipeline needs 8Gi of memory to run but there is not enough memory currently available. Please try again or un-deploy pipelines not in use to adjust the resources that are available for your Wallaroo instance. Contact your Wallaroo platform administrator for additional support."
     ]
    }
   ],
   "source": [
    "#p = p.add_validation('price too high', housing_model.outputs[0][0] < 100.0)\n",
    "pipeline = wl.build_pipeline('mobilenet-pp') \\\n",
    "            .add_model_step(mobilenet_model) \\\n",
    "            .deploy(deployment_config = deployment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = pipeline._deployment._url()\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building, configuring, and scheduling Assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.assay_config import BinMode, Aggregation, Metric\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = wallaroo.Client()\n",
    "\n",
    "pipeline_name = 'mypipeline'\n",
    "\n",
    "pipeline = client.pipelines_by_name(\"mobilenet-pp\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "baseline_start = datetime.datetime.fromisoformat('2022-10-31T00:00:00+00:00')\n",
    "baseline_end = datetime.datetime.fromisoformat('2022-11-01T00:00:00+00:00')\n",
    "last_day = datetime.datetime.fromisoformat('2022-11-30T00:00:00+00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assay_name = \"mobilenet-assay\"\n",
    "#assay_builder = client.build_assay(assay_name, pipeline, model_name, baseline_start, baseline_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_run = assay_builder.build().interactive_baseline_run()\n",
    "#baseline_run.baseline_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the pipeline in a video stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize some Vars\n",
    "\n",
    "Initialize the COCO Classes, meaning the classificaitons found on the images and the default width and height all images are resized to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from CVDemoUtils import CVDemo\n",
    "\n",
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Only objects that have a confidence > confidence_target will be displayed on the image\n",
    "confidence_target = 0.75\n",
    "\n",
    "cvDemo = CVDemo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect and Classify Objects in Video using Wallaroo Shadow Deployment\n",
    "\n",
    "Next we will load each frame in the input-video feedubg ut to the pipeline for inferencing.  Then using the results we will draw a bounding box around each identified object, print its classification, and the model's confidence that the prediction is accurate on the frame and save the frame to an output video.\n",
    "\n",
    "As we are executing this notice the time it takes to process each frame.  In the next section we will discuss ways to improve this performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5987/1154975401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m'output-video'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0moutput_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# show the input video with the inferenced results drawn on each frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m'fps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Frames per second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;34m'endpoint-url'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the pipelines rest api endpoint url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;34m'width'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the width of the url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m'height'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the height of the url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "input_video = \"videos/amazon-fresh-go.mp4\"\n",
    "output_video = \"videos/amazon-fresh-go-inferenced.mp4\"\n",
    "\n",
    "\n",
    "red = (0, 0, 255)\n",
    "config = {\n",
    "    'input-video' : input_video, # source video\n",
    "    'output-video' : output_video, # show the input video with the inferenced results drawn on each frame\n",
    "    'fps' : 15, # Frames per second\n",
    "    'endpoint-url' : url, # the pipelines rest api endpoint url\n",
    "    'width' : width, # the width of the url\n",
    "    'height' : height, # the height of the url\n",
    "    'max-frames' : 400, # the # of frames to capture in the output video\n",
    "    'skip-frames' : 75, # the # of frames to capture in the output video\n",
    "    'confidence-target' : 0.90, # only display bounding boxes with confidence > provided #\n",
    "    'color':red,\n",
    "    'blur-frame-start':130,\n",
    "    'blur-frame-end':175\n",
    "}\n",
    "cvDemo.DEBUG = True\n",
    "cvDemo.simulateDriftWhileDetectingAndClassifyingObjectsInVideoUsingPipeline(config)\n",
    "print(\"We are done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.undeploy()\n",
    "#for d in wl.list_deployments():\n",
    "#    d.undeploy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Notice how simple it is to take the mobilenet object detectors rest api endpoint url and use it in a video stream.  Now its your turn.  Upload a video to this notebook and replace the input-video with the path of the uploaded video.  Update the output video accordingly.\n",
    "\n",
    "See how well it works for you.  Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2    \n",
    "input_video = \"videos/amazon-fresh-go.mp4\"\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "  \n",
    "output = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*'MPEG'), 25, (1280,720))\n",
    "\n",
    "try:\n",
    "    cnt=0\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if(ret):\n",
    "            # adding rectangle on each frame\n",
    "            #cv2.rectangle(frame, (100, 100), (500, 500), (0, 255, 0), 3)\n",
    "\n",
    "            # writing the new frame in output\n",
    "            print(frame.shape)\n",
    "            print(\"frame \"+str(cnt))\n",
    "\n",
    "            output.write(frame)\n",
    "        cnt += 1\n",
    "        if cnt == 200:\n",
    "            break;\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting\")\n",
    "    \n",
    "output.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"videos/amazon-fresh-go.mp4\"\n",
    "size = images[0].shape[1], images[0].shape[0] ## <<<--- NOTICE THIS\n",
    "video = cv2.VideoWriter(video_path,cv2.VideoWriter_fourcc(*'DIVX'), 60, size)  \n",
    "\n",
    "for img in images:  \n",
    "    video.write(img)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
