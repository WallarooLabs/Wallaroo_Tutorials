{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Objects using the Wallaroo mobilenet Pipeline in a Video Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will explore using the mobilenet pipeline we created in step 3 to run inference on the frames in a Video and then draw the identified object's bounding boxes, classification and classification confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import wallaroo\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import imutils\n",
    "import sys\n",
    " \n",
    "from CVDemoUtils import CVDemo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wl.list_workspaces()\n",
    "for w in ws:\n",
    "    if w.name() == 'computer-vision':\n",
    "        wl.set_current_workspace(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenet'\n",
    "onnx_model_path = 'models/mobilenet.pt.onnx'\n",
    "mobilenet_model = wl.upload_model(model_name, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(1).memory(\"8Gi\").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'camera-1-pp'\n",
    "pipeline = wl.build_pipeline(pipeline_name) \\\n",
    "            .add_model_step(mobilenet_model) \\\n",
    "            .deploy(deployment_config = deployment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5) # needed to allow the pipeline to settle in.\n",
    "url = pipeline._deployment._url()\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the pipeline in a video stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Detect and Classify Objects in Video using Wallaroo Shadow Deployment\n",
    "\n",
    "Next we will load each frame in the input-video feedubg ut to the pipeline for inferencing.  Then using the results we will draw a bounding box around each identified object, print its classification, and the model's confidence that the prediction is accurate on the frame and save the frame to an output video.\n",
    "\n",
    "As we are executing this notice the time it takes to process each frame.  In the next section we will discuss ways to improve this performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDemo = CVDemo()\n",
    "\n",
    "# The size the image will be resized to\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "input_video = \"videos/amazon-fresh-go.mp4\"\n",
    "#input_video = \"videos/camera2.mp4\"\n",
    "output_video = \"videos/amazon-fresh-go-inferenced.mp4\"\n",
    "save_frames_path = \"images/output\"\n",
    "#input_video = \"videos/ww2-warbirds-in-formation.mp4\"\n",
    "#output_video = \"videos/ww2-warbirds-in-formation-inferenced.mp4\"\n",
    "\n",
    "config = {\n",
    "    'input-video' : input_video, # source video\n",
    "    'output-video' : output_video, # show the input video with the inferenced results drawn on each frame\n",
    "    'save-frames-path' : save_frames_path, # show the input video with the inferenced results drawn on each frame\n",
    "    'fps' : 15, # Frames per second\n",
    "    'endpoint-url' : url, # the pipelines rest api endpoint url\n",
    "    'width' : width, # the width of the url\n",
    "    'height' : height, # the height of the url\n",
    "    #'max-frames' : 400, # the # of frames to capture in the output video\n",
    "    'skip-frames' : 225, # the # of frames to capture in the output video\n",
    "    'confidence-target' : 0.10, # only display bounding boxes with confidence > provided #\n",
    "    'color':CVDemo.CYAN, # color to draw bounding boxes and the text in the statistics\n",
    "    'inference' : 'WALLAROO_SDK', # \"ONNX\" or \"WALLAROO_API\" or \"WALLAROO_SDK\"\n",
    "    'onnx_model_path' : onnx_model_path,\n",
    "    'model_name' : model_name,\n",
    "    'pipeline' : pipeline, # provide this when using inference WALLAROO_SDK \n",
    "    'pipeline_name' : pipeline_name,\n",
    "    'skip-frames-list' :[(440,460)]\n",
    "#    'record-start-frame' : 225, # the # of frames to capture in the output video\n",
    "#    'record-end-frame' : 275, # the # of frames to capture in the output video  \n",
    "}\n",
    "cvDemo.DEBUG = False\n",
    "cvDemo.detectAndClassifyObjectsInVideo(config)\n",
    "print(\"We are done.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Notice how simple it is to take the mobilenet object detectors rest api endpoint url and use it in a video stream.  Now its your turn.  Upload a video to this notebook and replace the input-video with the path of the uploaded video.  Update the output video accordingly.\n",
    "\n",
    "See how well it works for you.  Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.undeploy()\n",
    "#for d in wl.list_deployments():\n",
    "#    d.undeploy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
