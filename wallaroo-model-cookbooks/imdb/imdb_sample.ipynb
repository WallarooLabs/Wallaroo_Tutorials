{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-model-cookbooks/imdb).\n",
    "\n",
    "## IMDB Sample\n",
    "\n",
    "The following example demonstrates how to use Wallaroo with chained models.  In this example, we will be using information from the IMDB (Internet Movie DataBase) with a sentiment model to detect whether a given review is positive or negative.  Imagine using this to automatically scan Tweets regarding your product and finding either customers who need help or have nice things to say about your product.\n",
    "\n",
    "Note that this example is considered a \"toy\" model - only the first 100 words in the review were tokenized, and the embedding is very small.\n",
    "\n",
    "The following example is based on the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/), and sample data can be downloaded from the [aclIMDB dataset](http://s3.amazonaws.com/text-datasets/aclImdb.zip ).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* An installed Wallaroo instance.\n",
    "* The following Python libraries installed:\n",
    "  * `os`\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * [`pyarrow`](https://pypi.org/project/pyarrow/): PyArrow for Apache Arrow support\n",
    "  * [`polars`](https://pypi.org/project/polars/): Polars for DataFrame with native Apache Arrow support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023.2.1rc2\n"
     ]
    }
   ],
   "source": [
    "print(wallaroo.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this model, we will perform the following:\n",
    "\n",
    "* Create a workspace for our models.\n",
    "* Upload two models:\n",
    "  * `embedder`: Takes pre-tokenized text documents (model input: 100 integers/datum; output 800 numbers/datum) and creates an embedding from them.\n",
    "  * `sentiment`:  The second model classifies the resulting embeddings from 0 to 1, which 0 being an unfavorable review, 1 being a favorable review.\n",
    "* Create a pipeline that will take incoming data and pass it to the embedder, which will pass the output to the sentiment model, and then export the final result.\n",
    "* To test it, we will use information that has already been tokenized and submit it to our pipeline and gauge the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the sake of this tutorial, we'll use the SDK below to create our workspace , assign as our **current workspace**, then display all of the workspaces we have at the moment.  We'll also set up for our models and pipelines down the road, so we have one spot to change names to whatever fits your organization's standards best.\n",
    "\n",
    "To allow this tutorial to be run multiple times or by multiple users in the same Wallaroo instance, a random 4 character prefix will be added to the workspace, pipeline, and model.\n",
    "\n",
    "When we create our new workspace, we'll save it in the Python variable `workspace` so we can refer to it as needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll create a workspace for our environment, and call it `imdbworkspace`.  We'll also set up our pipeline so it's ready for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "# make a random 4 character prefix\n",
    "prefix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "workspace_name = f'{prefix}imdbworkspace'\n",
    "pipeline_name = f'{prefix}imdbpipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bggqimdbpipeline</td></tr><tr><th>created</th> <td>2023-07-14 15:29:46.732165+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-14 15:29:46.732165+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>844d5e89-1cb8-44a3-b9ff-2dbf1e75db27</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bggqimdbpipeline', 'create_time': datetime.datetime(2023, 7, 14, 15, 29, 46, 732165, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "imdb_pipeline = get_pipeline(pipeline_name)\n",
    "imdb_pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure, let's list our current workspace.  If everything is going right, it will show us we're in the `imdb-workspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'bggqimdbworkspace', 'id': 21, 'archived': False, 'created_by': '4e296632-35b3-460e-85fe-565e311bc566', 'created_at': '2023-07-14T15:29:45.662776+00:00', 'models': [], 'pipelines': [{'name': 'bggqimdbpipeline', 'create_time': datetime.datetime(2023, 7, 14, 15, 29, 46, 732165, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload our two models:\n",
    "\n",
    "* `embedder.onnx`: This will be used to embed the tokenized documents for evaluation.\n",
    "* `sentiment_model.onnx`: This will be used to analyze the review and determine if it is a positive or negative review.  The closer to 0, the more likely it is a negative review, while the closer to 1 the more likely it is to be a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = wl.upload_model(f'{prefix}embedder-o', './embedder.onnx').configure()\n",
    "smodel = wl.upload_model(f'{prefix}smodel-o', './sentiment_model.onnx').configure(runtime=\"onnx\", tensor_fields=[\"flatten_1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our models uploaded, now we'll create our pipeline that will contain two steps:\n",
    "\n",
    "* First, it runs the data through the embedder.\n",
    "* Second, it applies it to our sentiment model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bggqimdbpipeline</td></tr><tr><th>created</th> <td>2023-07-14 15:29:46.732165+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-14 15:29:46.732165+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>844d5e89-1cb8-44a3-b9ff-2dbf1e75db27</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bggqimdbpipeline', 'create_time': datetime.datetime(2023, 7, 14, 15, 29, 46, 732165, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bggqembedder-o', 'version': '2ef7af8b-1ad6-4ae9-b126-f836a05e9e37', 'sha': 'd083fd87fa84451904f71ab8b9adfa88580beb92ca77c046800f79780a20b7e4'}]}}, {'ModelInference': {'models': [{'name': 'bggqsmodel-o', 'version': 'aaca7ea2-b6d6-471f-9c5f-ea194de3112b', 'sha': '3473ea8700fbf1a1a8bfb112554a0dde8aab36758030dcde94a9357a83fd5650'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now make a pipeline\n",
    "imdb_pipeline.add_model_step(embedder)\n",
    "imdb_pipeline.add_model_step(smodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our pipeline set up with the steps, we can deploy the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bggqimdbpipeline</td></tr><tr><th>created</th> <td>2023-07-14 15:29:46.732165+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-14 15:29:52.678281+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>8fd7b44a-f5d3-4291-b741-db398c478537, 844d5e89-1cb8-44a3-b9ff-2dbf1e75db27</td></tr><tr><th>steps</th> <td>bggqembedder-o</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bggqimdbpipeline', 'create_time': datetime.datetime(2023, 7, 14, 15, 29, 46, 732165, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bggqembedder-o', 'version': '2ef7af8b-1ad6-4ae9-b126-f836a05e9e37', 'sha': 'd083fd87fa84451904f71ab8b9adfa88580beb92ca77c046800f79780a20b7e4'}]}}, {'ModelInference': {'models': [{'name': 'bggqsmodel-o', 'version': 'aaca7ea2-b6d6-471f-9c5f-ea194de3112b', 'sha': '3473ea8700fbf1a1a8bfb112554a0dde8aab36758030dcde94a9357a83fd5650'}]}}]\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_pipeline.deploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll check the pipeline status to verify it's deployed and the models are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.3.140',\n",
       "   'name': 'engine-6cb454f6bb-4fz9b',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'bggqimdbpipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'bggqsmodel-o',\n",
       "      'version': 'aaca7ea2-b6d6-471f-9c5f-ea194de3112b',\n",
       "      'sha': '3473ea8700fbf1a1a8bfb112554a0dde8aab36758030dcde94a9357a83fd5650',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'bggqembedder-o',\n",
       "      'version': '2ef7af8b-1ad6-4ae9-b126-f836a05e9e37',\n",
       "      'sha': 'd083fd87fa84451904f71ab8b9adfa88580beb92ca77c046800f79780a20b7e4',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.4.186',\n",
       "   'name': 'engine-lb-584f54c899-5zpkl',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_pipeline.status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this out, we'll start with a single piece of information from our data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.dense_1</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-14 15:30:09.930</td>\n",
       "      <td>[1607.0, 2635.0, 5749.0, 199.0, 49.0, 351.0, 16.0, 2919.0, 159.0, 5092.0, 2457.0, 8.0, 11.0, 1252.0, 507.0, 42.0, 287.0, 316.0, 15.0, 65.0, 136.0, 2.0, 133.0, 16.0, 4311.0, 131.0, 286.0, 153.0, 5.0, 2826.0, 175.0, 54.0, 548.0, 48.0, 1.0, 17.0, 9.0, 183.0, 1.0, 111.0, 15.0, 1.0, 17.0, 284.0, 982.0, 18.0, 28.0, 211.0, 1.0, 1382.0, 8.0, 146.0, 1.0, 19.0, 12.0, 9.0, 13.0, 21.0, 1898.0, 122.0, 14.0, 70.0, 14.0, 9.0, 97.0, 25.0, 74.0, 1.0, 189.0, 12.0, 9.0, 6.0, 31.0, 3.0, 244.0, 2497.0, 3659.0, 2.0, 665.0, 2497.0, 63.0, 180.0, 1.0, 17.0, 6.0, 287.0, 3.0, 646.0, 44.0, 15.0, 161.0, 50.0, 71.0, 438.0, 351.0, 31.0, 5749.0, 2.0, 0.0, 0.0]</td>\n",
       "      <td>[0.37142318]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-07-14 15:30:09.930   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      in.tensor  \\\n",
       "0  [1607.0, 2635.0, 5749.0, 199.0, 49.0, 351.0, 16.0, 2919.0, 159.0, 5092.0, 2457.0, 8.0, 11.0, 1252.0, 507.0, 42.0, 287.0, 316.0, 15.0, 65.0, 136.0, 2.0, 133.0, 16.0, 4311.0, 131.0, 286.0, 153.0, 5.0, 2826.0, 175.0, 54.0, 548.0, 48.0, 1.0, 17.0, 9.0, 183.0, 1.0, 111.0, 15.0, 1.0, 17.0, 284.0, 982.0, 18.0, 28.0, 211.0, 1.0, 1382.0, 8.0, 146.0, 1.0, 19.0, 12.0, 9.0, 13.0, 21.0, 1898.0, 122.0, 14.0, 70.0, 14.0, 9.0, 97.0, 25.0, 74.0, 1.0, 189.0, 12.0, 9.0, 6.0, 31.0, 3.0, 244.0, 2497.0, 3659.0, 2.0, 665.0, 2497.0, 63.0, 180.0, 1.0, 17.0, 6.0, 287.0, 3.0, 646.0, 44.0, 15.0, 161.0, 50.0, 71.0, 438.0, 351.0, 31.0, 5749.0, 2.0, 0.0, 0.0]   \n",
       "\n",
       "    out.dense_1  check_failures  \n",
       "0  [0.37142318]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "singleton = pd.DataFrame.from_records(\n",
    "    [\n",
    "    {\n",
    "        \"tensor\":[\n",
    "            1607.0,\n",
    "            2635.0,\n",
    "            5749.0,\n",
    "            199.0,\n",
    "            49.0,\n",
    "            351.0,\n",
    "            16.0,\n",
    "            2919.0,\n",
    "            159.0,\n",
    "            5092.0,\n",
    "            2457.0,\n",
    "            8.0,\n",
    "            11.0,\n",
    "            1252.0,\n",
    "            507.0,\n",
    "            42.0,\n",
    "            287.0,\n",
    "            316.0,\n",
    "            15.0,\n",
    "            65.0,\n",
    "            136.0,\n",
    "            2.0,\n",
    "            133.0,\n",
    "            16.0,\n",
    "            4311.0,\n",
    "            131.0,\n",
    "            286.0,\n",
    "            153.0,\n",
    "            5.0,\n",
    "            2826.0,\n",
    "            175.0,\n",
    "            54.0,\n",
    "            548.0,\n",
    "            48.0,\n",
    "            1.0,\n",
    "            17.0,\n",
    "            9.0,\n",
    "            183.0,\n",
    "            1.0,\n",
    "            111.0,\n",
    "            15.0,\n",
    "            1.0,\n",
    "            17.0,\n",
    "            284.0,\n",
    "            982.0,\n",
    "            18.0,\n",
    "            28.0,\n",
    "            211.0,\n",
    "            1.0,\n",
    "            1382.0,\n",
    "            8.0,\n",
    "            146.0,\n",
    "            1.0,\n",
    "            19.0,\n",
    "            12.0,\n",
    "            9.0,\n",
    "            13.0,\n",
    "            21.0,\n",
    "            1898.0,\n",
    "            122.0,\n",
    "            14.0,\n",
    "            70.0,\n",
    "            14.0,\n",
    "            9.0,\n",
    "            97.0,\n",
    "            25.0,\n",
    "            74.0,\n",
    "            1.0,\n",
    "            189.0,\n",
    "            12.0,\n",
    "            9.0,\n",
    "            6.0,\n",
    "            31.0,\n",
    "            3.0,\n",
    "            244.0,\n",
    "            2497.0,\n",
    "            3659.0,\n",
    "            2.0,\n",
    "            665.0,\n",
    "            2497.0,\n",
    "            63.0,\n",
    "            180.0,\n",
    "            1.0,\n",
    "            17.0,\n",
    "            6.0,\n",
    "            287.0,\n",
    "            3.0,\n",
    "            646.0,\n",
    "            44.0,\n",
    "            15.0,\n",
    "            161.0,\n",
    "            50.0,\n",
    "            71.0,\n",
    "            438.0,\n",
    "            351.0,\n",
    "            31.0,\n",
    "            5749.0,\n",
    "            2.0,\n",
    "            0.0,\n",
    "            0.0\n",
    "        ]\n",
    "    }\n",
    "]\n",
    ")\n",
    "results = imdb_pipeline.infer(singleton)\n",
    "display(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that works, let's load up all 50,000 rows and do a full inference on each of them via an Apache Arrow file.  Wallaroo pipeline inferences use Apache Arrow as their core data type, making this inference fast.  \n",
    "\n",
    "We'll do a demonstration with a pandas DataFrame and display the first 5 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = imdb_pipeline.infer_from_file('./data/test_data_50K.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.dense_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-14 15:30:17.404</td>\n",
       "      <td>[0.8980188]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-14 15:30:17.404</td>\n",
       "      <td>[0.056596935]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-14 15:30:17.404</td>\n",
       "      <td>[0.9260802]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-14 15:30:17.404</td>\n",
       "      <td>[0.926919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-14 15:30:17.404</td>\n",
       "      <td>[0.6618577]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-14 15:30:17.404</td>\n",
       "      <td>[0.48736304]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time    out.dense_1\n",
       "0 2023-07-14 15:30:17.404    [0.8980188]\n",
       "1 2023-07-14 15:30:17.404  [0.056596935]\n",
       "2 2023-07-14 15:30:17.404    [0.9260802]\n",
       "3 2023-07-14 15:30:17.404     [0.926919]\n",
       "4 2023-07-14 15:30:17.404    [0.6618577]\n",
       "5 2023-07-14 15:30:17.404   [0.48736304]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using pandas DataFrame\n",
    "\n",
    "outputs = results.to_pandas()\n",
    "display(outputs.loc[:5, [\"time\",\"out.dense_1\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy\n",
    "\n",
    "With our pipeline's work done, we'll undeploy it and give our Kubernetes environment back its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bggqimdbpipeline</td></tr><tr><th>created</th> <td>2023-07-14 15:29:46.732165+00:00</td></tr><tr><th>last_updated</th> <td>2023-07-14 15:29:52.678281+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>8fd7b44a-f5d3-4291-b741-db398c478537, 844d5e89-1cb8-44a3-b9ff-2dbf1e75db27</td></tr><tr><th>steps</th> <td>bggqembedder-o</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bggqimdbpipeline', 'create_time': datetime.datetime(2023, 7, 14, 15, 29, 46, 732165, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bggqembedder-o', 'version': '2ef7af8b-1ad6-4ae9-b126-f836a05e9e37', 'sha': 'd083fd87fa84451904f71ab8b9adfa88580beb92ca77c046800f79780a20b7e4'}]}}, {'ModelInference': {'models': [{'name': 'bggqsmodel-o', 'version': 'aaca7ea2-b6d6-471f-9c5f-ea194de3112b', 'sha': '3473ea8700fbf1a1a8bfb112554a0dde8aab36758030dcde94a9357a83fd5650'}]}}]\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_pipeline.undeploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there is our example. Please feel free to contact us at Wallaroo for if you have any questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrowtests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
