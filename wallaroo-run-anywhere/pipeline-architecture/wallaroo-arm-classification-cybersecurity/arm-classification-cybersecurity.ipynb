{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is available on the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.1_tutorials/wallaroo-run-anywhere/pipeline-architecture/wallaroo-arm-classification-cybersecurity).\n",
    "\n",
    "## Classification Cybersecurity with Arm Architecture\n",
    "\n",
    "This tutorial demonstrates how to use the Wallaroo combined with ARM processors to perform inferences with pre-trained classification cybersecurity ML models.  This demonstration assumes that:\n",
    "\n",
    "* Wallaroo Version 2023.3 or above instance is installed.\n",
    "* A nodepools with ARM architecture virtual machines are part of the Kubernetes cluster.  For example, Azure supports Ampere® Altra® Arm-based processor included with the following virtual machines:\n",
    "  * [Dpsv5 and Dpdsv5-series](https://learn.microsoft.com/en-us/azure/virtual-machines/dpsv5-dpdsv5-series)\n",
    "  * [Epsv5 and Epdsv5-series](https://learn.microsoft.com/en-us/azure/virtual-machines/epsv5-epdsv5-series)\n",
    "\n",
    "In this notebook we will walk through a simple pipeline deployment to inference on a model. For this example we will be using an open source model that uses an [Aloha CNN LSTM model](https://www.researchgate.net/publication/348920204_Using_Auxiliary_Inputs_in_Deep_Learning_Models_for_Detecting_DGA-based_Domain_Names) for classifying Domain names as being either legitimate or being used for nefarious purposes such as malware distribution.\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "For our example, we will perform the following:\n",
    "\n",
    "* Create a workspace for our work.\n",
    "* Upload the Aloha model.\n",
    "* Create a pipeline using the default architecture that can ingest our submitted data, submit it to the model, and export the results while tracking how long the inference took.\n",
    "* Redeploy the same pipeline on the ARM architecture, then perform the same inference on the same data and model and track how long the inference took.\n",
    "* Compare the inference timing through the default architecture versus the ARM architecture.\n",
    "\n",
    "All sample data and models are available through the [Wallaroo Quick Start Guide Samples repository](https://github.com/WallarooLabs/quickstartguide_samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  If logging in externally, update the `wallarooPrefix` and `wallarooSuffix` variables with the proper DNS information.  For more information on Wallaroo DNS settings, see the [Wallaroo DNS Integration Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-dns-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import pyarrow as pa\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workspace\n",
    "\n",
    "Now we'll use the SDK below to create our workspace , assign as our **current workspace**, then display all of the workspaces we have at the moment.  We'll also set up for our models and pipelines down the road, so we have one spot to change names to whatever fits your organization's standards best.\n",
    "\n",
    "To allow this tutorial to be run multiple times or by multiple users in the same Wallaroo instance, a random 4 character prefix will be added to the workspace.  Feel free to change this `suffix` variable to `''` if not required.\n",
    "\n",
    "When we create our new workspace, we'll save it in the Python variable `workspace` so we can refer to it as needed.\n",
    "\n",
    "For more information, see the [Wallaroo SDK Essentials Guide: Workspace Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-workspace/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = f'arm-classification-security'\n",
    "pipeline_name = 'alohapipeline'\n",
    "model_name = 'alohamodel'\n",
    "model_file_name = './models/alohacnnlstm.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'arm-classification-securityjohn', 'id': 24, 'archived': False, 'created_by': '0e5060a5-218c-47c1-9678-e83337494184', 'created_at': '2023-09-08T21:32:35.381464+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = wl.get_workspace(name=workspace_name, create_if_not_exist=True)\n",
    "\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the workspace is created the current default workspace with the `get_current_workspace()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'arm-classification-securityjohn', 'id': 24, 'archived': False, 'created_by': '0e5060a5-218c-47c1-9678-e83337494184', 'created_at': '2023-09-08T21:32:35.381464+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the Models\n",
    "\n",
    "Now we will upload our models.  Note that for this example we are applying the model from a .ZIP file.  The Aloha model is a [protobuf](https://developers.google.com/protocol-buffers) file that has been defined for evaluating web pages, and we will configure it to use data in the `tensorflow` format.\n",
    "\n",
    "We will create two versions of the model:  one that defaults to the x86 architecture, the other that will use the ARM architecture.\n",
    "\n",
    "\n",
    "For more information, see the [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wallaroo.engine_config import Architecture\n",
    "\n",
    "x86_model = wl.upload_model(model_name, \n",
    "                            model_file_name, \n",
    "                            framework=Framework.TENSORFLOW).configure(\"tensorflow\")\n",
    "arm_model = wl.upload_model(model_name, \n",
    "                            model_file_name, \n",
    "                            framework=Framework.TENSORFLOW,\n",
    "                            arch=Architecture.ARM).configure(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a model For x86\n",
    "\n",
    "Now that we have a model that we want to use we will create a deployment for it.  We will create a pipeline, then add the model to the pipeline as a pipeline step.\n",
    "\n",
    "For more information, see the [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-09-08 21:32:58.216028+00:00</td></tr><tr><th>last_updated</th> <td>2023-09-08 21:32:58.216028+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>fcde3598-c68d-4310-aea6-b3e98d4a4fb7</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 9, 8, 21, 32, 58, 216028, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '49530373-9ecc-4fab-8d32-918caa240101', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline = wl.build_pipeline(pipeline_name)\n",
    "aloha_pipeline\n",
    "\n",
    "# clear the steps if used before\n",
    "aloha_pipeline.clear()\n",
    "aloha_pipeline.add_model_step(x86_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Pipeline for x86\n",
    "\n",
    "We will now deploy the pipeline.  The x86 version of our model will be auto-applied in this pipeline configuration for x86 based architectures.\n",
    "\n",
    "For more information, see the [Wallaroo SDK Essentials Guide: Pipeline Deployment Configuration](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine': {'cpu': 4,\n",
       "  'resources': {'limits': {'cpu': 4, 'memory': '8Gi'},\n",
       "   'requests': {'cpu': 4, 'memory': '8Gi'}}},\n",
       " 'enginelb': {},\n",
       " 'engineAux': {'images': {}},\n",
       " 'node_selector': {}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ........ ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-09-08 21:32:58.216028+00:00</td></tr><tr><th>last_updated</th> <td>2023-09-08 21:33:00.111664+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>21218bd6-8ce8-4315-9683-b5a7542a0a94, fcde3598-c68d-4310-aea6-b3e98d4a4fb7</td></tr><tr><th>steps</th> <td>alohamodel</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 9, 8, 21, 32, 58, 216028, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '49530373-9ecc-4fab-8d32-918caa240101', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_config = (wallaroo.deployment_config\n",
    "                     .DeploymentConfigBuilder()\n",
    "                     .cpus(4)\n",
    "                     .memory('8Gi')\n",
    "                     .build()\n",
    "                    )\n",
    "display(deployment_config)\n",
    "aloha_pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the pipeline is running and list what models are associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.3.42',\n",
       "   'name': 'engine-5bc7d8697f-6klln',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'alohapipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'alohamodel',\n",
       "      'version': '49530373-9ecc-4fab-8d32-918caa240101',\n",
       "      'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.3.41',\n",
       "   'name': 'engine-lb-584f54c899-k7h8s',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Standard Architecture\n",
    "\n",
    "We will now perform an inference on 25,000 records by specifying an Apache Arrow input file, and track the time it takes to perform the inference and display the first 5 results.\n",
    "\n",
    "For more information, see the [Wallaroo SDK Essentials Guide: Inference Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.99999994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.9999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.9999989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24949</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.9996881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.99981505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24951</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.9999919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24952</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24953</th>\n",
       "      <td>2023-09-08 21:33:08.904</td>\n",
       "      <td>[0.99999803]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time      out.main\n",
       "0     2023-09-08 21:33:08.904    [0.997564]\n",
       "1     2023-09-08 21:33:08.904  [0.99999994]\n",
       "2     2023-09-08 21:33:08.904         [1.0]\n",
       "3     2023-09-08 21:33:08.904   [0.9999997]\n",
       "4     2023-09-08 21:33:08.904   [0.9999989]\n",
       "...                       ...           ...\n",
       "24949 2023-09-08 21:33:08.904   [0.9996881]\n",
       "24950 2023-09-08 21:33:08.904  [0.99981505]\n",
       "24951 2023-09-08 21:33:08.904   [0.9999919]\n",
       "24952 2023-09-08 21:33:08.904         [1.0]\n",
       "24953 2023-09-08 21:33:08.904  [0.99999803]\n",
       "\n",
       "[24954 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "result = aloha_pipeline.infer_from_file('./data/data_25k.arrow')\n",
    "endTime = time.time()\n",
    "x86_time = endTime-startTime\n",
    "display(result.to_pandas().loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy with ARM\n",
    "\n",
    "We have demonstrated performing our sample inference using a standard pipeline deployment.  Now we will redeploy the same pipeline with the ARM architecture version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ok\n",
      "Waiting for deployment - this will take up to 45s .................................. ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-09-08 21:32:58.216028+00:00</td></tr><tr><th>last_updated</th> <td>2023-09-08 21:35:11.663764+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>9c61af33-2934-4552-bf45-42d03441a64b, 9c51cf24-9fcc-40c1-82ab-297972ce488d, 21218bd6-8ce8-4315-9683-b5a7542a0a94, fcde3598-c68d-4310-aea6-b3e98d4a4fb7</td></tr><tr><th>steps</th> <td>alohamodel</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 9, 8, 21, 32, 58, 216028, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '554897eb-6464-45d3-87b3-afa7b765f388', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.undeploy()\n",
    "# clear the steps if used before\n",
    "aloha_pipeline.clear()\n",
    "aloha_pipeline.add_model_step(arm_model)\n",
    "aloha_pipeline.deploy(deployment_config = deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer with ARM\n",
    "\n",
    "We will now perform the same inference request, this time through the pipeline with the ARM architecture.  The same data, the same model - just on ARM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.99999994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.9999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.9999989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24949</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.9996881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.99981505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24951</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.9999919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24952</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24953</th>\n",
       "      <td>2023-09-08 21:36:22.500</td>\n",
       "      <td>[0.99999803]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time      out.main\n",
       "0     2023-09-08 21:36:22.500    [0.997564]\n",
       "1     2023-09-08 21:36:22.500  [0.99999994]\n",
       "2     2023-09-08 21:36:22.500         [1.0]\n",
       "3     2023-09-08 21:36:22.500   [0.9999997]\n",
       "4     2023-09-08 21:36:22.500   [0.9999989]\n",
       "...                       ...           ...\n",
       "24949 2023-09-08 21:36:22.500   [0.9996881]\n",
       "24950 2023-09-08 21:36:22.500  [0.99981505]\n",
       "24951 2023-09-08 21:36:22.500   [0.9999919]\n",
       "24952 2023-09-08 21:36:22.500         [1.0]\n",
       "24953 2023-09-08 21:36:22.500  [0.99999803]\n",
       "\n",
       "[24954 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "result = aloha_pipeline.infer_from_file('./data/data_25k.arrow',timeout=2500)\n",
    "endTime = time.time()\n",
    "arm_time = endTime-startTime\n",
    "display(result.to_pandas().loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Standard against Arm\n",
    "\n",
    "With the two inferences complete, we'll compare the standard deployment architecture time against the ARM architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Standard architecture: 2.8868443965911865'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ARM architecture: 2.5103814601898193'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"Standard architecture: {x86_time}\")\n",
    "display(f\"ARM architecture: {arm_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy Pipeline\n",
    "\n",
    "When finished with our tests, we will undeploy the pipeline so we have the Kubernetes resources back for other tasks.  Note that if the deployment variable is unchanged aloha_pipeline.deploy() will restart the inference engine in the same configuration as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s .................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-09-08 21:32:58.216028+00:00</td></tr><tr><th>last_updated</th> <td>2023-09-08 21:35:11.663764+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>9c61af33-2934-4552-bf45-42d03441a64b, 9c51cf24-9fcc-40c1-82ab-297972ce488d, 21218bd6-8ce8-4315-9683-b5a7542a0a94, fcde3598-c68d-4310-aea6-b3e98d4a4fb7</td></tr><tr><th>steps</th> <td>alohamodel</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 9, 8, 21, 32, 58, 216028, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '554897eb-6464-45d3-87b3-afa7b765f388', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
