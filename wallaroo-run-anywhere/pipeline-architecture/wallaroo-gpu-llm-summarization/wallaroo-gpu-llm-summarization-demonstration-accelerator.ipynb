{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b7ac3",
   "metadata": {},
   "source": [
    "This tutorial is available on the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.1_tutorials/wallaroo-run-anywhere/pipeline-architecture/wallaroo-gpu-llm-summarization).\n",
    "\n",
    "## LLM Summarization GPU Edge Deployment\n",
    "\n",
    "This tutorial demonstrates how to use the Wallaroo combined with GPU processors to perform inferences with pre-trained computer vision ML models.  This demonstration assumes that:\n",
    "\n",
    "* Wallaroo Version 2023.3 or above instance is installed.\n",
    "* A nodepools with GPUs part of the Kubernetes cluster.  See [Create GPU Nodepools for Kubernetes Clusters](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-install-guides/wallaroo-install-configurations/wallaroo-gpu-nodepools/) for more detials.\n",
    "* The model [`hf-summarization-bart-large-samsun.zip` (1.4 G)](https://storage.googleapis.com/wallaroo-public-data/llm-models/model-auto-conversion_hugging-face_complex-pipelines_hf-summarisation-bart-large-samsun.zip) has been downloaded to the `./models` folder.\n",
    "\n",
    "### Tutorial Goals\n",
    "\n",
    "For our example, we will perform the following:\n",
    "\n",
    "* Create a workspace for our work.\n",
    "* Upload the model.\n",
    "* Create a pipeline and specify the gpus in the pipeline deployment.\n",
    "* Perform a sample inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33e888-28a8-48cc-b418-2d95ad206d98",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step will be to import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8228fc-00ce-4770-a863-8985633605b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.pipeline   import Pipeline\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4e7d2",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb6f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6a089-7c58-4525-8af9-69552637d3d7",
   "metadata": {},
   "source": [
    "### Configure PyArrow Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a8480-293f-405b-a58f-b8e852dbe2ad",
   "metadata": {},
   "source": [
    "You can find more info on the available inputs under [TextSummarizationInputs](https://github.com/WallarooLabs/platform/blob/main/conductor/model-auto-conversion/flavors/hugging-face/src/io/pipeline_inputs/text_summarization_inputs.py#L14) or under the [official source code](https://github.com/huggingface/transformers/blob/v4.28.1/src/transformers/pipelines/text2text_generation.py#L241) from `ðŸ¤— Hugging Face`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef115ab9-9c73-4c28-aad8-e915a92a746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('inputs', pa.string()),\n",
    "    pa.field('return_text', pa.bool_()),\n",
    "    pa.field('return_tensors', pa.bool_()),\n",
    "    pa.field('clean_up_tokenization_spaces', pa.bool_()),\n",
    "    # pa.field('generate_kwargs', pa.map_(pa.string(), pa.null())), # dictionaries are not currently supported by the engine\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('summary_text', pa.string()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b396e",
   "metadata": {},
   "source": [
    "### Upload Model\n",
    "\n",
    "We will now create or connect to our pipeline and upload the model.\n",
    "\n",
    "The model's AI Accelerator is set during the model upload process.  For this model, that is set to `CUDA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3173ef82-80e7-4783-ab63-9aa097dd5edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for model loading - this will take up to 10.0min.\n",
      "Model is pending loading to a container runtime..\n",
      "Model is attempting loading to a container runtime.....................................................successful\n",
      "\n",
      "Ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>hf-summarization-yns</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>9297e44f-4c7a-4055-9a90-5284d3bf46a5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>hf-summarisation-bart-large-samsun.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>ee71d066a83708e7ca4a3c07caf33fdc528bb000039b6ca2ef77fa2428dc6268</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2024.1.0-main-4921</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>x86</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Acceleration</td>\n",
       "          <td>cuda</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2024-17-Apr 19:46:06</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'hf-summarization-yns', 'version': '9297e44f-4c7a-4055-9a90-5284d3bf46a5', 'file_name': 'hf-summarisation-bart-large-samsun.zip', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2024.1.0-main-4921', 'arch': 'x86', 'accel': 'cuda', 'last_update_time': datetime.datetime(2024, 4, 17, 19, 46, 6, 668684, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = wl.upload_model('hf-summarization', \n",
    "                        './models/hf-summarisation-bart-large-samsun.zip', \n",
    "                        framework=Framework.HUGGING_FACE_SUMMARIZATION, \n",
    "                        input_schema=input_schema, \n",
    "                        output_schema=output_schema,\n",
    "                        accel=wallaroo.engine_config.Acceleration.CUDA)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb0930-8246-4731-84f9-eb1e0e1d9091",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "With the model uploaded, we can add it is as a step in the pipeline, then deploy it.  \n",
    "\n",
    "For GPU deployment, the pipeline deployment configuration allocated the cpus, ram, gpus, and other settings for the pipeline.  For gpus,  both the number of GPUs and the nodepool containing the gpus must be specified.\n",
    "\n",
    "For Wallaroo Native Runtime models (`onnx`, `tensorflow`), the method is `wallaroo.deployment_config.gpus(int)` to allocate the number of gpus to the pipeline.  This applies to all Wallaroo Native Runtime models in the pipeline.\n",
    "\n",
    "For Wallaroo Containerized models (`hugging-face`, etc), the method is `wallaroo.deployment_config.sidekick_gpus(int)` to allocate the number of gpus to the model.\n",
    "\n",
    "The deployment label is set with the `wallaroo.deployment_config.deployment_label(string)` method.\n",
    "\n",
    "For more information on allocating resources to a Wallaroo pipeline for deployment, see [Wallaroo SDK Essentials Guide: Pipeline Deployment Configuration](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/).\n",
    "\n",
    "For this example, 1 gpu will be allocated to the pipeline from the nodepool with the deployment label `wallaroo.ai/accelerator: a100`.\n",
    "\n",
    "Note that the accelerator setting for the deployment configuration is not specified; this is inherited from the model's `accel` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ac85a4-1978-4fb9-91c4-a4d728ed04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(1).memory('1Gi') \\\n",
    "    .sidekick_gpus(model, 1) \\\n",
    "    .sidekick_cpus(model,4) \\\n",
    "    .sidekick_memory(model, '8Gi') \\\n",
    "    .deployment_label('wallaroo.ai/accelerator: a100') \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2e189f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine': {'cpu': 1,\n",
       "  'resources': {'limits': {'cpu': 1, 'memory': '1Gi'},\n",
       "   'requests': {'cpu': 1, 'memory': '1Gi'}},\n",
       "  'node_selector': 'wallaroo.ai/accelerator: a100',\n",
       "  'arch': 'x86',\n",
       "  'accel': 'cuda'},\n",
       " 'enginelb': {},\n",
       " 'engineAux': {'images': {'hf-summarization-yns-65': {'resources': {'limits': {'nvidia.com/gpu': 1,\n",
       "      'cpu': 4,\n",
       "      'memory': '8Gi'},\n",
       "     'requests': {'nvidia.com/gpu': 1, 'cpu': 4, 'memory': '8Gi'}}}}},\n",
       " 'node_selector': {}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1527954b-1a42-4014-9f02-171d30463b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>hf-summarization-pipeline</td></tr><tr><th>created</th> <td>2024-04-17 19:47:45.965024+00:00</td></tr><tr><th>last_updated</th> <td>2024-04-17 19:48:53.441612+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>arch</th> <td>None</td></tr><tr><th>accel</th> <td>None</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>34289130-76ca-47c1-a672-9e6b027056d5, 8a9b269a-9b0a-4d68-a591-46f97392de0f, 8b79fb5a-2743-4e3a-a2e4-c8ac32884394</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'hf-summarization-pipeline', 'create_time': datetime.datetime(2024, 4, 17, 19, 47, 45, 965024, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'hf-summarization-yns', 'version': '9297e44f-4c7a-4055-9a90-5284d3bf46a5', 'sha': 'ee71d066a83708e7ca4a3c07caf33fdc528bb000039b6ca2ef77fa2428dc6268'}]}}]\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = \"hf-summarization-pipeline\"\n",
    "pipeline = wl.build_pipeline(pipeline_name)\n",
    "pipeline.add_model_step(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e76644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for pipeline publish... It may take up to 600 sec.\n",
      "Pipeline is publishing............................. Published.\n"
     ]
    }
   ],
   "source": [
    "pub = pipeline.publish(deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0eb3a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <table>\n",
       "              <tr><td>ID</td><td>1</td></tr>\n",
       "              <tr><td>Pipeline Name</td><td>hf-summarization-pipeline</td></tr>\n",
       "              <tr><td>Pipeline Version</td><td>6d453276-a4cf-4b01-90d7-78e9da1dd72a</td></tr>\n",
       "              <tr><td>Status</td><td>Published</td></tr>\n",
       "              <tr><td>Engine URL</td><td><a href='https://ghcr.io/wallaroolabs/doc-samples/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-cuda:v2024.1.0-main-4921'>ghcr.io/wallaroolabs/doc-samples/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-cuda:v2024.1.0-main-4921</a></td></tr>\n",
       "              <tr><td>Pipeline URL</td><td><a href='https://ghcr.io/wallaroolabs/doc-samples/pipelines/hf-summarization-pipeline:6d453276-a4cf-4b01-90d7-78e9da1dd72a'>ghcr.io/wallaroolabs/doc-samples/pipelines/hf-summarization-pipeline:6d453276-a4cf-4b01-90d7-78e9da1dd72a</a></td></tr>\n",
       "              <tr><td>Helm Chart URL</td><td>oci://<a href='https://ghcr.io/wallaroolabs/doc-samples/charts/hf-summarization-pipeline'>ghcr.io/wallaroolabs/doc-samples/charts/hf-summarization-pipeline</a></td></tr>\n",
       "              <tr><td>Helm Chart Reference</td><td>ghcr.io/wallaroolabs/doc-samples/charts@sha256:a9406689f7429c16758447780c860ee41c78dc674280754eb2b377da1a9efbf4</td></tr>\n",
       "              <tr><td>Helm Chart Version</td><td>0.0.1-6d453276-a4cf-4b01-90d7-78e9da1dd72a</td></tr>\n",
       "              <tr><td>Engine Config</td><td>{'engine': {'resources': {'limits': {'cpu': 1.0, 'memory': '512Mi'}, 'requests': {'cpu': 1.0, 'memory': '512Mi'}, 'accel': 'cuda', 'arch': 'x86', 'gpu': False}}, 'engineAux': {'autoscale': {'type': 'none'}, 'images': {}}}</td></tr>\n",
       "              <tr><td>User Images</td><td>[]</td></tr>\n",
       "              <tr><td>Created By</td><td>john.hansarick@wallaroo.ai</td></tr>\n",
       "              <tr><td>Created At</td><td>2024-04-17 19:49:32.922418+00:00</td></tr>\n",
       "              <tr><td>Updated At</td><td>2024-04-17 19:49:32.922418+00:00</td></tr>\n",
       "              <tr><td>Replaces</td><td></td></tr>\n",
       "              <tr>\n",
       "                  <td>Docker Run Command</td>\n",
       "                  <td>\n",
       "                      <table><tr><td>\n",
       "<pre style=\"text-align: left\">docker run \\\n",
       "    -p $EDGE_PORT:8080 \\\n",
       "    -e OCI_USERNAME=$OCI_USERNAME \\\n",
       "    -e OCI_PASSWORD=$OCI_PASSWORD \\\n",
       "    -e PIPELINE_URL=ghcr.io/wallaroolabs/doc-samples/pipelines/hf-summarization-pipeline:6d453276-a4cf-4b01-90d7-78e9da1dd72a \\\n",
       "    -e CONFIG_CPUS=1 ghcr.io/wallaroolabs/doc-samples/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-cuda:v2024.1.0-main-4921</pre></td></tr></table>\n",
       "                      <br />\n",
       "                      <i>\n",
       "                          Note: Please set the <code>EDGE_PORT</code>, <code>OCI_USERNAME</code>, and <code>OCI_PASSWORD</code> environment variables.\n",
       "                      </i>\n",
       "                  </td>\n",
       "              </tr>\n",
       "              <tr>\n",
       "                  <td>Helm Install Command</td>\n",
       "                  <td>\n",
       "                      <table><tr><td>\n",
       "<pre style=\"text-align: left\">helm install --atomic $HELM_INSTALL_NAME \\\n",
       "    oci://ghcr.io/wallaroolabs/doc-samples/charts/hf-summarization-pipeline \\\n",
       "    --namespace $HELM_INSTALL_NAMESPACE \\\n",
       "    --version 0.0.1-6d453276-a4cf-4b01-90d7-78e9da1dd72a \\\n",
       "    --set ociRegistry.username=$OCI_USERNAME \\\n",
       "    --set ociRegistry.password=$OCI_PASSWORD</pre></td></tr></table>\n",
       "                      <br />\n",
       "                      <i>\n",
       "                          Note: Please set the <code>HELM_INSTALL_NAME</code>, <code>HELM_INSTALL_NAMESPACE</code>,\n",
       "                          <code>OCI_USERNAME</code>, and <code>OCI_PASSWORD</code> environment variables.\n",
       "                      </i>\n",
       "                  </td>\n",
       "              </tr>\n",
       "              \n",
       "          </table>\n",
       "        "
      ],
      "text/plain": [
       "PipelinePublish(created_at=datetime.datetime(2024, 4, 17, 19, 49, 32, 922418, tzinfo=tzutc()), docker_run_variables={'PIPELINE_URL': 'ghcr.io/wallaroolabs/doc-samples/pipelines/hf-summarization-pipeline:6d453276-a4cf-4b01-90d7-78e9da1dd72a'}, engine_config={'engine': {'resources': {'limits': {'cpu': 1.0, 'memory': '512Mi'}, 'requests': {'cpu': 1.0, 'memory': '512Mi'}, 'accel': 'cuda', 'arch': 'x86', 'gpu': False}}, 'engineAux': {'autoscale': {'type': 'none'}, 'images': {}}}, id=1, pipeline_name='hf-summarization-pipeline', pipeline_version_id=126, replaces=[], status='Published', updated_at=datetime.datetime(2024, 4, 17, 19, 49, 32, 922418, tzinfo=tzutc()), user_images=[], created_by='65124b18-8382-49af-b3c8-ada3b9df3330', created_on_version='2024.1.0', edge_bundles=<wallaroo.wallaroo_ml_ops_api_client.types.Unset object at 0x17f035160>, engine_url='ghcr.io/wallaroolabs/doc-samples/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-cuda:v2024.1.0-main-4921', error=None, helm={'reference': 'ghcr.io/wallaroolabs/doc-samples/charts@sha256:a9406689f7429c16758447780c860ee41c78dc674280754eb2b377da1a9efbf4', 'values': {}, 'chart': 'ghcr.io/wallaroolabs/doc-samples/charts/hf-summarization-pipeline', 'version': '0.0.1-6d453276-a4cf-4b01-90d7-78e9da1dd72a'}, pipeline_url='ghcr.io/wallaroolabs/doc-samples/pipelines/hf-summarization-pipeline:6d453276-a4cf-4b01-90d7-78e9da1dd72a', pipeline_version_name='6d453276-a4cf-4b01-90d7-78e9da1dd72a', additional_properties={})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9123fa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>hf-summarization-pipeline</td></tr><tr><th>created</th> <td>2024-04-17 19:47:45.965024+00:00</td></tr><tr><th>last_updated</th> <td>2024-04-17 19:49:31.864182+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>arch</th> <td>None</td></tr><tr><th>accel</th> <td>None</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>6d453276-a4cf-4b01-90d7-78e9da1dd72a, c2a5693d-a580-45be-8898-5dd7ee36cb00, 34289130-76ca-47c1-a672-9e6b027056d5, 8a9b269a-9b0a-4d68-a591-46f97392de0f, 8b79fb5a-2743-4e3a-a2e4-c8ac32884394</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'hf-summarization-pipeline', 'create_time': datetime.datetime(2024, 4, 17, 19, 47, 45, 965024, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'hf-summarization-yns', 'version': '9297e44f-4c7a-4055-9a90-5284d3bf46a5', 'sha': 'ee71d066a83708e7ca4a3c07caf33fdc528bb000039b6ca2ef77fa2428dc6268'}]}}]\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea455f46-6f8b-4d5f-a195-74634c0c886b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f305561-adc4-4362-9b83-547815a73fa5",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Run inference\n",
    "\n",
    "We can now run a sample inference using the `wallaroo.pipeline.infer` method and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063afee0-c19a-4a20-842e-b462ad3960c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>return_text</th>\n",
       "      <th>return_tensors</th>\n",
       "      <th>clean_up_tokenization_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinkedIn (/lÉªÅ‹ktËˆÉªn/) is a business and employ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  return_text  \\\n",
       "0  LinkedIn (/lÉªÅ‹ktËˆÉªn/) is a business and employ...         True   \n",
       "\n",
       "   return_tensors  clean_up_tokenization_spaces  \n",
       "0           False                         False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "        \"inputs\": [\"LinkedIn (/lÉªÅ‹ktËˆÉªn/) is a business and employment-focused social media platform that works through websites and mobile apps. It launched on May 5, 2003. It is now owned by Microsoft. The platform is primarily used for professional networking and career development, and allows jobseekers to post their CVs and employers to post jobs. From 2015 most of the company's revenue came from selling access to information about its members to recruiters and sales professionals. Since December 2016, it has been a wholly owned subsidiary of Microsoft. As of March 2023, LinkedIn has more than 900 million registered members from over 200 countries and territories. LinkedIn allows members (both workers and employers) to create profiles and connect with each other in an online social network which may represent real-world professional relationships. Members can invite anyone (whether an existing member or not) to become a connection. LinkedIn can also be used to organize offline events, join groups, write articles, publish job postings, post photos and videos, and more\"], # required\n",
    "        \"return_text\": [True], # optional: using the defaults, similar to not passing this parameter\n",
    "        \"return_tensors\": [False], # optional: using the defaults, similar to not passing this parameter\n",
    "        \"clean_up_tokenization_spaces\": [False], # optional: using the defaults, similar to not passing this parameter\n",
    "}\n",
    "dataframe = pd.DataFrame(input_data)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa078ffd-859e-4706-8729-9e7d78f8bf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.clean_up_tokenization_spaces</th>\n",
       "      <th>in.inputs</th>\n",
       "      <th>in.return_tensors</th>\n",
       "      <th>in.return_text</th>\n",
       "      <th>out.summary_text</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08 13:18:58.557</td>\n",
       "      <td>False</td>\n",
       "      <td>LinkedIn (/lÉªÅ‹ktËˆÉªn/) is a business and employ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>LinkedIn is a business and employment-focused ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  in.clean_up_tokenization_spaces  \\\n",
       "0 2023-09-08 13:18:58.557                            False   \n",
       "\n",
       "                                           in.inputs  in.return_tensors  \\\n",
       "0  LinkedIn (/lÉªÅ‹ktËˆÉªn/) is a business and employ...              False   \n",
       "\n",
       "   in.return_text                                   out.summary_text  \\\n",
       "0            True  LinkedIn is a business and employment-focused ...   \n",
       "\n",
       "   check_failures  \n",
       "0               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipeline.infer(dataframe)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af628bea-8a5a-4b7e-8c24-dfed150332d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinkedIn is a business and employment-focused social media platform that works through websites and mobile apps. It launched on May 5, 2003. LinkedIn allows members (both workers and employers) to create profiles and connect with each other in an online social network which may represent real-world professional relationships.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"out.summary_text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f8d2a-9182-4040-a61c-77a643907657",
   "metadata": {},
   "source": [
    "### Model Inferencing with Pipeline Deployment Endpoint\n",
    "\n",
    "The other option is to use the pipeline's inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b3a869-6370-4cb9-abb1-01b9df12d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"time\":1694179270999,\"in\":{\"clean_up_tokenization_spaces\":[false],\"inputs\":[\"LinkedIn (/lÉªÅ‹ktËˆÉªn/) is a business and employment-focused social media platform that works through websites and mobile apps. It launched on May 5, 2003. It is now owned by Microsoft. The platform is primarily used for professional networking and career development, and allows jobseekers to post their CVs and employers to post jobs. From 2015 most of the company's revenue came from selling access to information about its members to recruiters and sales professionals. Since December 2016, it has been a wholly owned subsidiary of Microsoft. As of March 2023, LinkedIn has more than 900 million registered members from over 200 countries and territories. LinkedIn allows members (both workers and employers) to create profiles and connect with each other in an online social network which may represent real-world professional relationships. Members can invite anyone (whether an existing member or not) to become a connection. LinkedIn can also be used to organize offline events, join groups, write articles, publish job postings, post photos and videos, and more\"],\"return_tensors\":[false],\"return_text\":[true]},\"out\":{\"summary_text\":\"LinkedIn is a business and employment-focused social media platform that works through websites and mobile apps. It launched on May 5, 2003. LinkedIn allows members (both workers and employers) to create profiles and connect with each other in an online social network which may represent real-world professional relationships.\"},\"check_failures\":[],\"metadata\":{\"last_model\":\"{\\\"model_name\\\":\\\"hf-summarization-yns\\\",\\\"model_sha\\\":\\\"ee71d066a83708e7ca4a3c07caf33fdc528bb000039b6ca2ef77fa2428dc6268\\\"}\",\"pipeline_version\":\"4aeb608f-166b-4b59-bb10-c06f9e49df23\",\"elapsed\":[41800,4294967295],\"dropped\":[]}}]"
     ]
    }
   ],
   "source": [
    "!curl -X POST {pipeline.url()} \\\n",
    "    -H \"Content-Type: application/json; format=pandas-records\" \\\n",
    "        -d @./data/test_summarization.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd836161",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "With the demonstration complete, we can undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba355e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk.2024.1",
   "language": "python",
   "name": "wallaroosdk.2024.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
