{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.4_tutorials/wallaroo-run-anywhere/run-anywhere-acceleration-aloha).\n",
    "\n",
    "## Run Anywhere With Jetson Acceleration Tutorial: Aloha Model\n",
    "\n",
    "Wallaroo supports deploying models with accelerators that increase the inference speed and performance.  These accelerators are set during model upload, and are carried through to model deployment and model edge deployment.\n",
    "\n",
    "### Supported Accelerators\n",
    "\n",
    "The following accelerators are supported:\n",
    "\n",
    "| Accelerator | Description |\n",
    "|---|---|\n",
    "| `None` | The default acceleration, used for all scenarios and architectures. |\n",
    "| `Aio` | Compatible only with the `ARM` architecture. |\n",
    "| `Jetson` | Compatible only with the `ARM` architecture. |\n",
    "| `CUDA` | [Nvidia Cuda acceleration](https://developer.nvidia.com/about-cuda) supported by both ARM and X64/X86 processors.  This is intended for deployment with GPUs. |\n",
    "\n",
    "## Goal\n",
    "\n",
    "Demonstrate uploading an Aloha model with the `Jetson`, then publishing the same model for edge deployment with the `Jetson` accelerator inherited from the model.\n",
    "\n",
    "### Resources\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* Models:\n",
    "  * `models/alohacnnlstm.zip`:  An open source model based on the [Aloha CNN LSTM model](https://www.researchgate.net/publication/348920204_Using_Auxiliary_Inputs_in_Deep_Learning_Models_for_Detecting_DGA-based_Domain_Names) for classifying Domain names as being either legitimate or being used for nefarious purposes such as malware distribution.  \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* A deployed Wallaroo instance with [Edge Registry Services](https://docs.wallaroo.ai/wallaroo-platform-operations/wallaroo-platform-operations-configure/wallaroo-edge-deployment/#enable-wallaroo-edge-deployment-registry) and [Edge Observability enabled](https://docs.wallaroo.ai/wallaroo-platform-operations/wallaroo-platform-operations-configure/wallaroo-edge-deployment/#set-edge-observability-service).\n",
    "* The following Python libraries installed:\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * `json`: Used for format input data for inference requests.\n",
    "\n",
    "The following deployment prerequisites must be met on the target device where the models are deployed to.\n",
    "\n",
    "* Hardware Requirements:\n",
    "  * Jetson Orin Nano Board\n",
    "* Software Requirements:\n",
    "  * [Jetpack 6.1](https://developer.nvidia.com/embedded/jetpack-sdk-61)\n",
    "  * [Cuda 12.2](https://developer.nvidia.com/cuda-12-2-0-download-archive)\n",
    "\n",
    "Setup the Docker access with the following command before deploying\n",
    "\n",
    "```bash\n",
    "sudo usermod -aG docker $USER\n",
    "newgrp docker\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* Upload the model with the targeted accelerator left as `None` by default.\n",
    "* Create the pipeline add the model as a model step.\n",
    "* Deploy the model with deployment configuration and show the acceleration setting inherits the model's accelerator.\n",
    "* Publish the pipeline an OCI registry and show the publish pipeline deployment configuration inherit's the model's accelerator.\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step will be to import our libraries, and set variables used through this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The next step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workspace\n",
    "\n",
    "We will create a workspace to manage our pipeline and models.  The following variables will set the name of our sample workspace then set it as the current workspace.\n",
    "\n",
    "Workspace, pipeline, and model names should be unique to each user, so we'll add in a randomly generated suffix so multiple people can run this tutorial in a Wallaroo instance without effecting each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'accelerator-aloha-demonstration', 'id': 41, 'archived': False, 'created_by': 'eed2002f-769f-4cbd-a189-8ca1e9bf496c', 'created_at': '2024-04-19T17:03:13.108611+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_name = 'accelerator-aloha-demonstration'\n",
    "\n",
    "workspace = wl.get_workspace(name=workspace_name, create_if_not_exist=True)\n",
    "\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model Accelerator\n",
    "\n",
    "For our example, we will upload the model.  The file name is `./models/alohacnnlstm.zip` and the model will be called `aloha`.\n",
    "\n",
    "Models are uploaded to Wallaroo via the [`wallaroo.client.upload_model`](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-reference-guide/client/#Client.upload_model) method which takes the following arguments:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| **path** | *String* (*Required*) | The file path to the model. |\n",
    "| **framework** | *wallaroo.framework.Framework* (*Required*) | The model's framework.  See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) for supported model frameworks. |\n",
    "| **input_schema** | *pyarrow.lib.Schema* (*Optional*)  | The model's input schema.  **Only required for non-Native Wallaroo frameworks.  See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) for more details. |\n",
    "| **output_schema** | *pyarrow.lib.Schema* (*Optional*)  | The model's output schema.  **Only required for non-Native Wallaroo frameworks.  See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) for more details. |\n",
    "| **convert_wait** | *bool* (*Optional*)  | Whether to wait in the SDK session to complete the auto-packaging process for non-native Wallaroo frameworks. |\n",
    "| **arch** | *wallaroo.engine_config.Architecture* (*Optional*)  | The targeted architecture for the model.  Options are <ul><li>`X86` (*Default*)</li><li>`ARM`</li></ul> |\n",
    "| **accel** |  *wallaroo.engine_config.Acceleration* (*Optional*)  | The targeted optimization for the model.  Options are <ul><li>`None`: The default acceleration, used for all scenarios and architectures.</li><li>`Aio`:Compatible only with the `ARM` architecture.</li><li>`Jetson`: Compatible only with the `ARM` architecture.</li><li>`CUDA`: Compatible with either `ARM` or `X86/X64` architectures.</li></ul> |\n",
    "\n",
    "We upload the model and set set the `accel` to `wallaroo.engine_config.Acceleration.Jetson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'aloha'\n",
    "model_file_name = './models/alohacnnlstm.zip'\n",
    "\n",
    "from wallaroo.framework import Framework\n",
    "from wallaroo.engine_config import Architecture, Acceleration\n",
    "\n",
    "model = wl.upload_model(model_name, \n",
    "                        model_file_name,\n",
    "                        framework=Framework.TENSORFLOW,\n",
    "                        arch=Architecture.ARM,\n",
    "                        accel=Acceleration.Jetson,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Model Details\n",
    "\n",
    "Once the model is uploaded, we view the model details to verify the `accel` setting it set to `Jetson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>aloha</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>4f42d63e-aff1-4eb2-997a-eef23dc5582d</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>alohacnnlstm.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>d71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>arm</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Acceleration</td>\n",
       "          <td>jetson</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2024-19-Apr 17:03:13</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'aloha', 'version': '4f42d63e-aff1-4eb2-997a-eef23dc5582d', 'file_name': 'alohacnnlstm.zip', 'image_path': None, 'arch': 'arm', 'accel': 'jetson', 'last_update_time': datetime.datetime(2024, 4, 19, 17, 3, 13, 811983, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pipeline\n",
    "\n",
    "With the model uploaded, we build our pipeline and add the Aloha model as a pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'aloha-pipeline'\n",
    "\n",
    "aloha_pipeline = wl.build_pipeline(pipeline_name)\n",
    "\n",
    "_ = aloha_pipeline.add_model_step(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Accelerator for Pipeline Publish\n",
    "\n",
    "Publishing the pipeline uses the pipeline `wallaroo.pipeline.Pipeline.publish()` command.  This requires that the Wallaroo Ops instance have [Edge Registry Services](https://docs.wallaroo.ai/wallaroo-platform-operations/wallaroo-platform-operations-configure/wallaroo-edge-deployment/#enable-wallaroo-edge-deployment-registry) enabled.\n",
    "\n",
    "The deployment configuration for the pipeline publish inherits the model's accelerator and architecture.  Options such as the number of cpus, amount of memory, etc can be adjusted without impacting the model's accelerator or architecture settings.\n",
    "\n",
    "Pipelines do **not** need to be deployed in the centralized Wallaroo Ops instance **before** publishing the pipeline.  This is useful in deployments to edge devices with different hardware accelerators than the centralized Wallaroo Ops instance.\n",
    "\n",
    "To change the model architecture or acceleration settings, upload the model as a new model or model version with the new architecture or acceleration settings.\n",
    "\n",
    "For this example, we will publish the pipeline twice:\n",
    "\n",
    "* Publish the pipeline with a default deployment configuration.\n",
    "* Publish the pipeline with the cpu and memory specified.\n",
    "\n",
    "Note that in both examples, the architecture and the acceleration inherits the model's settings.\n",
    "\n",
    "For more information, see [Wallaroo SDK Essentials Guide: Pipeline Edge Publication](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-publication/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for pipeline publish... It may take up to 600 sec.\n",
      "Pipeline is publishing.................... Published.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "          <table>\n",
       "              <tr><td>ID</td><td>2</td></tr>\n",
       "              <tr><td>Pipeline Name</td><td>aloha-pipeline</td></tr>\n",
       "              <tr><td>Pipeline Version</td><td>f4336f6f-808f-4e46-b8bd-c0e2a407cb01</td></tr>\n",
       "              <tr><td>Status</td><td>Published</td></tr>\n",
       "              <tr><td>Engine URL</td><td><a href='https://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849'>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849</a></td></tr>\n",
       "              <tr><td>Pipeline URL</td><td><a href='https://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:f4336f6f-808f-4e46-b8bd-c0e2a407cb01'>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:f4336f6f-808f-4e46-b8bd-c0e2a407cb01</a></td></tr>\n",
       "              <tr><td>Helm Chart URL</td><td>oci://<a href='https://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline'>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline</a></td></tr>\n",
       "              <tr><td>Helm Chart Reference</td><td>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts@sha256:acf1102592e193c7bfc5fa867856d81f8619f9205a52860aad7d1a671af7e853</td></tr>\n",
       "              <tr><td>Helm Chart Version</td><td>0.0.1-f4336f6f-808f-4e46-b8bd-c0e2a407cb01</td></tr>\n",
       "              <tr><td>Engine Config</td><td>{'engine': {'resources': {'limits': {'cpu': 1.0, 'memory': '512Mi'}, 'requests': {'cpu': 1.0, 'memory': '512Mi'}, 'accel': 'jetson', 'arch': 'arm', 'gpu': False}}, 'engineAux': {'autoscale': {'type': 'none'}, 'images': {}}}</td></tr>\n",
       "              <tr><td>User Images</td><td>[]</td></tr>\n",
       "              <tr><td>Created By</td><td>john.hummel@wallaroo.ai</td></tr>\n",
       "              <tr><td>Created At</td><td>2024-04-19 17:03:14.326070+00:00</td></tr>\n",
       "              <tr><td>Updated At</td><td>2024-04-19 17:03:14.326070+00:00</td></tr>\n",
       "              <tr><td>Replaces</td><td></td></tr>\n",
       "              <tr>\n",
       "                  <td>Docker Run Command</td>\n",
       "                  <td>\n",
       "                      <table><tr><td>\n",
       "<pre style=\"text-align: left\">docker run \\\n",
       "    -p $EDGE_PORT:8080 \\\n",
       "    -e OCI_USERNAME=$OCI_USERNAME \\\n",
       "    -e OCI_PASSWORD=$OCI_PASSWORD \\\n",
       "    -e PIPELINE_URL=us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:f4336f6f-808f-4e46-b8bd-c0e2a407cb01 \\\n",
       "    -e CONFIG_CPUS=1 us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849</pre></td></tr></table>\n",
       "                      <br />\n",
       "                      <i>\n",
       "                          Note: Please set the <code>EDGE_PORT</code>, <code>OCI_USERNAME</code>, and <code>OCI_PASSWORD</code> environment variables.\n",
       "                      </i>\n",
       "                  </td>\n",
       "              </tr>\n",
       "              <tr>\n",
       "                  <td>Helm Install Command</td>\n",
       "                  <td>\n",
       "                      <table><tr><td>\n",
       "<pre style=\"text-align: left\">helm install --atomic $HELM_INSTALL_NAME \\\n",
       "    oci://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline \\\n",
       "    --namespace $HELM_INSTALL_NAMESPACE \\\n",
       "    --version 0.0.1-f4336f6f-808f-4e46-b8bd-c0e2a407cb01 \\\n",
       "    --set ociRegistry.username=$OCI_USERNAME \\\n",
       "    --set ociRegistry.password=$OCI_PASSWORD</pre></td></tr></table>\n",
       "                      <br />\n",
       "                      <i>\n",
       "                          Note: Please set the <code>HELM_INSTALL_NAME</code>, <code>HELM_INSTALL_NAMESPACE</code>,\n",
       "                          <code>OCI_USERNAME</code>, and <code>OCI_PASSWORD</code> environment variables.\n",
       "                      </i>\n",
       "                  </td>\n",
       "              </tr>\n",
       "              \n",
       "          </table>\n",
       "        "
      ],
      "text/plain": [
       "PipelinePublish(created_at=datetime.datetime(2024, 4, 19, 17, 3, 14, 326070, tzinfo=tzutc()), docker_run_variables={'PIPELINE_URL': 'us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:f4336f6f-808f-4e46-b8bd-c0e2a407cb01'}, engine_config={'engine': {'resources': {'limits': {'cpu': 1.0, 'memory': '512Mi'}, 'requests': {'cpu': 1.0, 'memory': '512Mi'}, 'accel': 'jetson', 'arch': 'arm', 'gpu': False}}, 'engineAux': {'autoscale': {'type': 'none'}, 'images': {}}}, id=2, pipeline_name='aloha-pipeline', pipeline_version_id=18, replaces=[], status='Published', updated_at=datetime.datetime(2024, 4, 19, 17, 3, 14, 326070, tzinfo=tzutc()), user_images=[], created_by='eed2002f-769f-4cbd-a189-8ca1e9bf496c', created_on_version='2024.4.0', edge_bundles=<wallaroo.wallaroo_ml_ops_api_client.types.Unset object at 0x7a2b79393ee0>, engine_url='us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849', error=None, helm={'reference': 'us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts@sha256:acf1102592e193c7bfc5fa867856d81f8619f9205a52860aad7d1a671af7e853', 'values': {}, 'chart': 'us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline', 'version': '0.0.1-f4336f6f-808f-4e46-b8bd-c0e2a407cb01'}, pipeline_url='us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:f4336f6f-808f-4e46-b8bd-c0e2a407cb01', pipeline_version_name='f4336f6f-808f-4e46-b8bd-c0e2a407cb01', additional_properties={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "\n",
    "deploy_config = wallaroo.DeploymentConfigBuilder().build()\n",
    "\n",
    "aloha_pipeline.publish(deployment_config=deploy_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We publish the pipeline again, this time changing the number of cpus and memory for the deployment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for pipeline publish... It may take up to 600 sec.\n",
      "Pipeline is publishing................ Published.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "          <table>\n",
       "              <tr><td>ID</td><td>3</td></tr>\n",
       "              <tr><td>Pipeline Name</td><td>aloha-pipeline</td></tr>\n",
       "              <tr><td>Pipeline Version</td><td>d261c45e-de85-4997-971c-2bdcaf406014</td></tr>\n",
       "              <tr><td>Status</td><td>Published</td></tr>\n",
       "              <tr><td>Engine URL</td><td><a href='https://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849'>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849</a></td></tr>\n",
       "              <tr><td>Pipeline URL</td><td><a href='https://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:d261c45e-de85-4997-971c-2bdcaf406014'>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:d261c45e-de85-4997-971c-2bdcaf406014</a></td></tr>\n",
       "              <tr><td>Helm Chart URL</td><td>oci://<a href='https://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline'>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline</a></td></tr>\n",
       "              <tr><td>Helm Chart Reference</td><td>us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts@sha256:b9e27a601d69deb4c79bc46d1a1597b2ec1cbd5cbf67cbe5e46f5aa88536d361</td></tr>\n",
       "              <tr><td>Helm Chart Version</td><td>0.0.1-d261c45e-de85-4997-971c-2bdcaf406014</td></tr>\n",
       "              <tr><td>Engine Config</td><td>{'engine': {'resources': {'limits': {'cpu': 1.0, 'memory': '512Mi'}, 'requests': {'cpu': 1.0, 'memory': '512Mi'}, 'accel': 'jetson', 'arch': 'arm', 'gpu': False}}, 'engineAux': {'autoscale': {'type': 'none'}, 'images': {}}}</td></tr>\n",
       "              <tr><td>User Images</td><td>[]</td></tr>\n",
       "              <tr><td>Created By</td><td>john.hummel@wallaroo.ai</td></tr>\n",
       "              <tr><td>Created At</td><td>2024-04-19 17:04:51.595162+00:00</td></tr>\n",
       "              <tr><td>Updated At</td><td>2024-04-19 17:04:51.595162+00:00</td></tr>\n",
       "              <tr><td>Replaces</td><td></td></tr>\n",
       "              <tr>\n",
       "                  <td>Docker Run Command</td>\n",
       "                  <td>\n",
       "                      <table><tr><td>\n",
       "<pre style=\"text-align: left\">docker run \\\n",
       "    -p $EDGE_PORT:8080 \\\n",
       "    -e OCI_USERNAME=$OCI_USERNAME \\\n",
       "    -e OCI_PASSWORD=$OCI_PASSWORD \\\n",
       "    -e PIPELINE_URL=us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:d261c45e-de85-4997-971c-2bdcaf406014 \\\n",
       "    -e CONFIG_CPUS=1 us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849</pre></td></tr></table>\n",
       "                      <br />\n",
       "                      <i>\n",
       "                          Note: Please set the <code>EDGE_PORT</code>, <code>OCI_USERNAME</code>, and <code>OCI_PASSWORD</code> environment variables.\n",
       "                      </i>\n",
       "                  </td>\n",
       "              </tr>\n",
       "              <tr>\n",
       "                  <td>Helm Install Command</td>\n",
       "                  <td>\n",
       "                      <table><tr><td>\n",
       "<pre style=\"text-align: left\">helm install --atomic $HELM_INSTALL_NAME \\\n",
       "    oci://us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline \\\n",
       "    --namespace $HELM_INSTALL_NAMESPACE \\\n",
       "    --version 0.0.1-d261c45e-de85-4997-971c-2bdcaf406014 \\\n",
       "    --set ociRegistry.username=$OCI_USERNAME \\\n",
       "    --set ociRegistry.password=$OCI_PASSWORD</pre></td></tr></table>\n",
       "                      <br />\n",
       "                      <i>\n",
       "                          Note: Please set the <code>HELM_INSTALL_NAME</code>, <code>HELM_INSTALL_NAMESPACE</code>,\n",
       "                          <code>OCI_USERNAME</code>, and <code>OCI_PASSWORD</code> environment variables.\n",
       "                      </i>\n",
       "                  </td>\n",
       "              </tr>\n",
       "              \n",
       "          </table>\n",
       "        "
      ],
      "text/plain": [
       "PipelinePublish(created_at=datetime.datetime(2024, 4, 19, 17, 4, 51, 595162, tzinfo=tzutc()), docker_run_variables={'PIPELINE_URL': 'us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:d261c45e-de85-4997-971c-2bdcaf406014'}, engine_config={'engine': {'resources': {'limits': {'cpu': 1.0, 'memory': '512Mi'}, 'requests': {'cpu': 1.0, 'memory': '512Mi'}, 'accel': 'jetson', 'arch': 'arm', 'gpu': False}}, 'engineAux': {'autoscale': {'type': 'none'}, 'images': {}}}, id=3, pipeline_name='aloha-pipeline', pipeline_version_id=19, replaces=[], status='Published', updated_at=datetime.datetime(2024, 4, 19, 17, 4, 51, 595162, tzinfo=tzutc()), user_images=[], created_by='eed2002f-769f-4cbd-a189-8ca1e9bf496c', created_on_version='2024.4.0', edge_bundles=<wallaroo.wallaroo_ml_ops_api_client.types.Unset object at 0x7a2b79393ee0>, engine_url='us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849', error=None, helm={'reference': 'us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts@sha256:b9e27a601d69deb4c79bc46d1a1597b2ec1cbd5cbf67cbe5e46f5aa88536d361', 'values': {}, 'chart': 'us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/charts/aloha-pipeline', 'version': '0.0.1-d261c45e-de85-4997-971c-2bdcaf406014'}, pipeline_url='us-central1-docker.pkg.dev/wallaroo-dev-253816/uat/pipelines/aloha-pipeline:d261c45e-de85-4997-971c-2bdcaf406014', pipeline_version_name='d261c45e-de85-4997-971c-2bdcaf406014', additional_properties={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "\n",
    "deploy_config_custom = (wallaroo.DeploymentConfigBuilder()\n",
    "                     .replica_count(1)\n",
    "                     .cpus(1)\n",
    "                     .memory(\"1Gi\")\n",
    "                     .build()\n",
    "                    )\n",
    "\n",
    "aloha_pipeline.publish(deployment_config=deploy_config_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML models published to OCI registries via the Wallaroo SDK are provided with the **Docker Run Command**:  a sample `docker` script for deploying the model on edge and multicloud environments.\n",
    "\n",
    "For ML models deployed on Jetson accelerated hardware via Docker, the application `docker` is replace by the `nvidia-docker` application.  For details on installing `nvidia-docker`, see [Installing the NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html).  For example:\n",
    "\n",
    "```python\n",
    "docker run --runtime nvidia --privileged --gpus all \\\n",
    "    -v $PERSISTENT_VOLUME_DIR:/persist \\\n",
    "    -e OCI_USERNAME=$OCI_USERNAME \\\n",
    "    -e OCI_PASSWORD=$OCI_PASSWORD \\\n",
    "    -e PIPELINE_URL=ghcr.io/wallaroolabs/doc-samples/pipelines/sample-edge-deploy:446aeed9-2d52-47ae-9e5c-f2a05ef0d4d6\\\n",
    "    -e EDGE_BUNDLE=abc123 \\\n",
    "    ghcr.io/wallaroolabs/doc-samples/engines/proxy/wallaroo/ghcr.io/wallaroolabs/fitzroy-mini-jetson:v2024.4.0-5849\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
