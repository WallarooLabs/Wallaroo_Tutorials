{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.1_tutorials/wallaroo-run-anywhere/edge-architecture-publish-cv-resnet-model).\n",
    "\n",
    "## Run Anywhere for ARM Architecture Tutorial: Custom Inference Computer Vision with Resnet50\n",
    "\n",
    "Wallaroo Run Anywhere provides model deployment in any device, any cloud, and any architecture.  Models uploaded to Wallaroo are set to their targeted architecture.  By default, this is `X86`.\n",
    "\n",
    "The model's deployment configuration is tied to its architecture settings.  That deployment configuration is carried over to the models publication in Open Container Initiative (OCI) Registries, which allows edge model deployments on X64 and ARM architectures.\n",
    "\n",
    "This tutorial demonstrates deploying a computer vision model trained to detect objects using the Resnet50 methodology, combined with custom inference known as [Wallaroo Bring Your Own Predict or Arbitrary Python](https://staging.docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-upload-register/wallaroo-model-operations-upload-register-arbitrary-python/) to X64 and ARM edge locations through the following steps.\n",
    "\n",
    "* Setting up a workspace, and pipeline.\n",
    "* Upload a model set to the ARM architecture.\n",
    "* Deploy the model to the ARM architecture and demonstrate that the deployment configuration inherits its architecture from the model configuration.\n",
    "* Performing a sample set of inferences to verify the deployment.\n",
    "* Publish the deployed model to an Open Container Initiative (OCI) Registry ARM deployments and verify it inherits the edge deployment architecture based on the model configuration.\n",
    "* Deploy the model to an ARM edge device.\n",
    "* Perform similar inferences on the edge device and show the results.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Demonstrate models uploaded to Wallaroo with the targeted architecture set to ARM are deployable on ARM architecture nodepools and ARM edge devices.\n",
    "\n",
    "### Resources\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* Models:\n",
    "  * `model-with-pixel-intensity.zip`: A custom inference model combined with the Resnet50 model.  This is downloaded from the Wallaroo Public Data bucket from the following URL.  Unzip the following .zip file into the `./models` folder:\n",
    "    * [https://storage.googleapis.com/wallaroo-public-data/cv-demo-models/cv-retail-models.zip](https://storage.googleapis.com/wallaroo-public-data/cv-demo-models/cv-retail-models.zip)\n",
    "  * Various inputs and helper utilities:\n",
    "    * `./utils.py`: A utility library for converting images into tensor values that are used with pandas DataFrames for inference requests.\n",
    "    * `./data/images/example`: A set of example images.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* If using this tutorial outside of the JupyterHub service integrated into a Wallaroo installation by using the [Wallaroo SDK], the following libraries must be included.  See the `./requirements.txt` for a complete list.\n",
    "  * onnx==1.12.0\n",
    "  * onnxruntime==1.12.1\n",
    "  * torchvision\n",
    "  * torch\n",
    "  * matplotlib==3.5.0\n",
    "  * opencv-python\n",
    "  * imutils\n",
    "  * pytz\n",
    "  * ipywidgets\n",
    "* A deployed Wallaroo instance with [Edge Registry Services](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-edge-deployment/#enable-wallaroo-edge-deployment-registry) and [Edge Observability enabled](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-edge-deployment/#set-edge-observability-service).\n",
    "* The following Python libraries installed:\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * `json`: Used for format input data for inference requests.\n",
    "* An ARM Docker deployment environment to deploy the model on an edge location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* Upload the model with the targeted architecture set to `ARM`.\n",
    "* Create the pipeline add the model as a model step.\n",
    "* Deploy the model in the targeted architecture and perform sample inferences.\n",
    "* Publish the pipeline an OCI registry.\n",
    "* Deploy the model from the pipeline publish to the edge deployment with ARM architecture.\n",
    "* Perform sample inferences on the ARM edge model deployment.\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step will be to import our libraries, and set variables used through this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "from wallaroo.engine_config import Architecture\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# used to set the model's input/output schemas\n",
    "import pyarrow as pa\n",
    "\n",
    "import utils\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "workspace_name = f'run-anywhere-architecture-demonstration-cv-byop-tutorial'\n",
    "arm_pipeline_name = f'architecture-demonstration-arm'\n",
    "model_name_arm = f'computer-vision-with-pixel-intensity-arm'\n",
    "model_file_name = './models/model-with-pixel-intensity.zip'\n",
    "\n",
    "# ignoring warnings for demonstration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name, client):\n",
    "    workspace = None\n",
    "    for ws in client.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = client.create_workspace(name)\n",
    "    return workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workspace\n",
    "\n",
    "We will create a workspace to manage our pipeline and models.  The following variables will set the name of our sample workspace then set it as the current workspace.\n",
    "\n",
    "Workspace names are unique across the Wallaroo instance.  Verify either that another workspace with the same name does not exist, or that access is granted to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'run-anywhere-architecture-demonstration-cv-byop-tutorial', 'id': 63, 'archived': False, 'created_by': 'b4a9aa3d-83fc-407a-b4eb-37796e96f1ef', 'created_at': '2024-03-05T15:17:38.68486+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name, wl)\n",
    "\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment on ARM Architecture via the Wallaroo SDK\n",
    "\n",
    "### Upload Models and Set ARM Target Architecture\n",
    "\n",
    "For our example, we will upload the model from the file `./data/model-with-pizel-intensity.zip` with the model name `computer-vision-with-pixel-intensity-arm`.\n",
    "\n",
    "Models are uploaded to Wallaroo via the [`wallaroo.client.upload_model`](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-reference-guide/client/#Client.upload_model) method which takes the following arguments:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| **path** | *String* (*Required*) | The file path to the model. |\n",
    "| **framework** | *wallaroo.framework.Framework* (*Required*) | The model's framework.  See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) for supported model frameworks. |\n",
    "| **input_schema** | *pyarrow.lib.Schema* (*Optional*)  | The model's input schema.  **Only required for non-Native Wallaroo frameworks.  See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) for more details. |\n",
    "| **output_schema** | *pyarrow.lib.Schema* (*Optional*)  | The model's output schema.  **Only required for non-Native Wallaroo frameworks.  See [Wallaroo SDK Essentials Guide: Model Uploads and Registrations](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) for more details. |\n",
    "| **convert_wait** | *bool* (*Optional*)  | Whether to wait in the SDK session to complete the auto-packaging process for non-native Wallaroo frameworks. |\n",
    "| **arch** | *wallaroo.engine_config.Architecture* (*Optional*)  | The targeted architecture for the model.  Options are <ol><li>`X86` (*Default*)</li><li>`ARM`</li></ol> |\n",
    "\n",
    "For this demonstration we set the architecture for the model to `wallaroo.Architecture.ARM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for model loading - this will take up to 10.0min.\n",
      "Model is pending loading to a container runtime..\n",
      "Model is attempting loading to a container runtime...............successful\n",
      "\n",
      "Ready\n"
     ]
    }
   ],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('tensor', pa.list_(\n",
    "        pa.list_(\n",
    "            pa.list_(\n",
    "                pa.float32(), # images are normalized\n",
    "                list_size=640\n",
    "            ),\n",
    "            list_size=480\n",
    "        ),\n",
    "        list_size=3\n",
    "    )),\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('boxes', pa.list_(pa.list_(pa.float32(), list_size=4))),\n",
    "    pa.field('classes', pa.list_(pa.int64())),\n",
    "    pa.field('confidences', pa.list_(pa.float32())),\n",
    "    pa.field('avg_px_intensity', pa.list_(pa.float32())),\n",
    "    pa.field('avg_confidence', pa.list_(pa.float32())),\n",
    "])\n",
    "\n",
    "\n",
    "housing_model_control_arm = wl.upload_model(model_name_arm, \n",
    "                        model_file_name, \n",
    "                        framework=Framework.CUSTOM,\n",
    "                        input_schema=input_schema, \n",
    "                        output_schema=output_schema,\n",
    "                        arch=Architecture.ARM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>computer-vision-with-pixel-intensity-arm</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>23f63ab7-7c17-45bb-af0a-869ba6a7485f</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>model-with-pixel-intensity.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>6d58039b1a02c5cce85646292965d29056deabdfcc6b18c34adf566922c212b0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2024.1.0-main-4609</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Acceleration</td>\n",
       "          <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2024-05-Mar 15:27:51</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'computer-vision-with-pixel-intensity-arm', 'version': '23f63ab7-7c17-45bb-af0a-869ba6a7485f', 'file_name': 'model-with-pixel-intensity.zip', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2024.1.0-main-4609', 'arch': None, 'accel': None, 'last_update_time': datetime.datetime(2024, 3, 5, 15, 27, 51, 480272, tzinfo=tzutc())}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(housing_model_control_arm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Models to ARM Architecture\n",
    "\n",
    "#### Build the Pipeline\n",
    "\n",
    "This pipeline is used as an example of the edge deployment environment for testing.  We will create a pipeline and add our model set to the `ARM` architecture as a pipeline step.\n",
    "\n",
    "The **model's targeted architecture** is inherited by the pipeline version; no additional pipeline settings are required to set that architecture.  The other settings apply the CPU and memory used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arm = wl.build_pipeline(arm_pipeline_name)\n",
    "\n",
    "# clear the previous steps\n",
    "pipeline_arm.clear()\n",
    "\n",
    "# set the model step with the ARM targeted model\n",
    "pipeline_arm.add_model_step(housing_model_control_arm)\n",
    "\n",
    "#minimum deployment config\n",
    "deployment_config = wallaroo.DeploymentConfigBuilder() \\\n",
    "    .replica_count(1) \\\n",
    "    .cpus(1) \\\n",
    "    .memory(\"2Gi\") \\\n",
    "    .sidekick_cpus(housing_model_control_arm, 1) \\\n",
    "    .sidekick_memory(housing_model_control_arm, '6Gi') \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy Pipeline\n",
    "\n",
    "We deploy the pipeline, then show that the deployment configuration architecture is set to `ARM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ............................................"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>*** An error occurred while deploying your pipeline.</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "WaitForDeployError",
     "evalue": "Deployment failed. See status for details.\nStatus: {'status': 'Error', 'details': [], 'engines': [{'ip': '10.124.3.42', 'name': 'engine-77b8cd7674-dcxsj', 'status': 'Running', 'reason': None, 'details': [], 'pipeline_statuses': {'pipelines': []}, 'model_statuses': {'models': []}}], 'engine_lbs': [{'ip': '10.124.0.138', 'name': 'engine-lb-d7cc8fc9c-6vhlz', 'status': 'Running', 'reason': None, 'details': []}], 'sidekicks': []}",
     "output_type": "error",
     "traceback": [
      "Deployment failed. See status for details.\nStatus: {'status': 'Error', 'details': [], 'engines': [{'ip': '10.124.3.42', 'name': 'engine-77b8cd7674-dcxsj', 'status': 'Running', 'reason': None, 'details': [], 'pipeline_statuses': {'pipelines': []}, 'model_statuses': {'models': []}}], 'engine_lbs': [{'ip': '10.124.0.138', 'name': 'engine-lb-d7cc8fc9c-6vhlz', 'status': 'Running', 'reason': None, 'details': []}], 'sidekicks': []}"
     ]
    }
   ],
   "source": [
    "pipeline_arm.deploy(deployment_config=deploy_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arm.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences on ARM Architecture Model Deployments\n",
    "\n",
    "With the pipeline deployed, we'll perform sample inferences through the pipeline's inference API endpoints.  This will be the same method used for inference requests for model edge deployments.\n",
    "\n",
    "The following uses the included `utils.py` to convert the image into its tensor values.  It takes in the file name and the sample height and weight which for this is example is set to 640x480, and returns a DataFrame of the converted image, and the resized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 640, 480\n",
    "\n",
    "sample_image = \"./data/images/input/example/dairy_bottles.png\"\n",
    "\n",
    "dfImage, resizedImage = utils.loadImageAndConvertToDataframe(sample_image, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pipeline deployment urls\n",
    "\n",
    "arm_deploy_url = pipeline_arm._deployment._url()\n",
    "\n",
    "# get authorization header\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# set the content-type and accept headers\n",
    "\n",
    "# set the content type for pandas records\n",
    "headers['Content-Type']= 'application/json; format=pandas-records'\n",
    "\n",
    "# set accept as pandas-records\n",
    "headers['Accept']='application/json; format=pandas-records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Error',\n",
       " 'error': 'Pipeline with id architecture-demonstration-arm not found'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### inferences on arm model deployments\n",
    "\n",
    "\n",
    "headers = {\n",
    "        'Content-Type': 'application/json; format=pandas-records'\n",
    "    }\n",
    "\n",
    "# retrieve response\n",
    "response = requests.post(\n",
    "                    arm_deploy_url, \n",
    "                    headers=headers, \n",
    "                    data=dfImage.to_json(orient=\"records\")\n",
    "                )\n",
    "response.json()\n",
    "# convert response to dataframe\n",
    "\n",
    "inference_result = pd.DataFrame(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference results are displayed.  The bounding boxes of detected objects are displayed with the `utils.drawDetectedObjectsFromInference` method, and the `out.avg_confidence` field displayed directly after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = utils.drawDetectedObjectsFromInference(inference_result)\n",
    "    \n",
    "display(inference_result.loc[:, ['out.avg_confidence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipelines\n",
    "\n",
    "With the inference examples complete, we can undeploy the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arm.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Deployment\n",
    "\n",
    "We now deploy the pipeline versions to our edge devices.\n",
    "\n",
    "* Publish the pipeline versions:  Publishes the pipeline versions to the OCI registry with the deployment configuration inherited from the pipeline versions, with the architecture settings inherited from the model versions.\n",
    "* Deploy Edge:  Deploy the edge device with the edge location settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish Pipeline Versions\n",
    "\n",
    "Publishing the pipeline uses the pipeline `wallaroo.pipeline.publish()` command.  This requires that the Wallaroo Ops instance have [Edge Registry Services](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-edge-deployment/#enable-wallaroo-edge-deployment-registry) enabled.\n",
    "\n",
    "The following publishes the pipeline to the OCI registry and displays the container details.  For more information, see [Wallaroo SDK Essentials Guide: Pipeline Edge Publication](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-publication/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_pub_arm = pipeline_arm.publish()\n",
    "assay_pub_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevOps Deployment on ARM Architecture\n",
    "\n",
    "The edge deployment is performed with `docker run`, `docker compose`, or `helm` installations.  The following command generates the `docker run` command, with the following values provided by the DevOps Engineer:\n",
    "\n",
    "* `$REGISTRYURL`: The URL of the OCI registry service hosting the pipeline publish.\n",
    "* `$OCI_USERNAME`: The username for the OCI registry service.\n",
    "* `$OCI_PASSWORD`: The password or token for the OCI registry service.\n",
    "\n",
    "For more details on model edge deployments with Wallaroo, see [Model Operations: Run Anywhere](https://staging.docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-run-anywhere/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create docker run \n",
    "\n",
    "docker_command = f'''\n",
    "docker run -p 8080:8080 \\\\\n",
    "    -e DEBUG=true \\\\\n",
    "    -e OCI_REGISTRY=$REGISTRYURL \\\\\n",
    "    -e CONFIG_CPUS=1 \\\\\n",
    "    -e OCI_USERNAME=$OCI_USERNAME \\\\\n",
    "    -e OCI_PASSWORD=$OCI_PASSWORD \\\\\n",
    "    -e PIPELINE_URL={assay_pub_arm.pipeline_url} \\\\\n",
    "    {assay_pub_arm.engine_url}\n",
    "'''\n",
    "\n",
    "print(docker_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Inference Examples on ARM Architecture\n",
    "\n",
    "The following examples demonstrate performing inferences on the model deployed on an `ARM` architecture edge device.  `HOSTNAME_ARM` is the hostname for the ARM architecture edge deployment.  Update this variable to match your deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOSTNAME_ARM = 'localhost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the inference through the ARM edge device\n",
    "\n",
    "edge_inference_url = f'{HOSTNAME_ARM}:8080/pipelines/{arm_pipeline_name}'\n",
    "\n",
    "headers = {\n",
    "        'Content-Type': 'application/json; format=pandas-records'\n",
    "    }\n",
    "\n",
    "# retrieve response\n",
    "response = requests.post(\n",
    "                    edge_inference_url, \n",
    "                    headers=headers, \n",
    "                    data=dfImage.to_json(orient=\"records\")\n",
    "                )\n",
    "response.json()\n",
    "# convert response to DataFrame and display\n",
    "\n",
    "inference_result = pd.DataFrame(response.json())\n",
    "image = utils.drawDetectedObjectsFromInference(inference_result)\n",
    "    \n",
    "display(inference_result.loc[:, ['out.avg_confidence']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
