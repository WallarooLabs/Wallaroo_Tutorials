{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tutorials are available from the [Wallaroo Tutorials Repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/notebooks_in_prod).\n",
    "\n",
    "# Stage 3: Deploy the Model in Wallaroo\n",
    " \n",
    "In this stage, we upload the trained model and the processing steps to Wallaroo, then set up and deploy the inference pipeline. \n",
    "\n",
    "Once deployed we can feed the newest batch of data to the pipeline, do the inferences and write the results to a results table.\n",
    "\n",
    "For clarity in this demo, we have split the training/upload task into two notebooks:\n",
    "\n",
    "* `02_automated_training_process.ipynb`: Train and pickle ML model.\n",
    "* `03_deploy_model.ipynb`: Upload the model to Wallaroo and deploy into a pipeline.\n",
    "\n",
    "Assuming no changes are made to the structure of the model, these two notebooks, or a script based on them, can then be scheduled to run on a regular basis, to refresh the model with more recent training data and update the inference pipeline.\n",
    "\n",
    "This notebook is expected to run within the Wallaroo instance's Jupyter Hub service to provide access to all required Wallaroo libraries and functionality.\n",
    "\n",
    "## Resources\n",
    "\n",
    "The following resources are used as part of this tutorial:\n",
    "\n",
    "* **data**\n",
    "  * `data/seattle_housing_col_description.txt`: Describes the columns used as part data analysis.\n",
    "  * `data/seattle_housing.csv`: Sample data of the Seattle, Washington housing market between 2014 and 2015.\n",
    "* **code**\n",
    "  * `simdb.py`: A simulated database to demonstrate sending and receiving queries.\n",
    "* **models**\n",
    "  * `./models/housing_model_xgb.onnx`: Model created in Stage 2: Training Process Automation Setup.\n",
    "  * `./models/preprocess_step.zip`: A preprocessing model that formats the data for acceptance by the model.\n",
    "  * `./models/postprocess_step.zip`: A postprocessing model that formats the data output by `housing_model_xgb.onnx` for the inference output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "The process of uploading the model to Wallaroo follows these steps:\n",
    "\n",
    "* [Connect to Wallaroo](#connect-to-wallaroo): Connect to the Wallaroo instance and set up the workspace.\n",
    "* [Upload The Model](#upload-the-model): Upload the model and autoconvert for use in the Wallaroo engine.\n",
    "* [Upload the Processing Modules](#upload-the-processing-modules): Upload the processing modules.\n",
    "* [Create and Deploy the Pipeline](#create-and-deploy-the-pipeline): Create the pipeline with the model and processing modules as steps, then deploy it.\n",
    "* [Test the Pipeline](#test-the-pipeline): Verify that the pipeline works with the sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "First we import the required libraries to connect to the Wallaroo instance, then connect to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "\n",
    "import simdb # module for the purpose of this demo to simulate pulling data from a database\n",
    "\n",
    "# from wallaroo.ModelConversion import ConvertXGBoostArgs, ModelConversionSource, ModelConversionInputType\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Keycloak token refresh got error: 400 - {\"error\":\"invalid_grant\",\"error_description\":\"Invalid refresh token\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://keycloak.autoscale-uat-gcp.wallaroo.dev/auth/realms/master/device?user_code=GOYG-WRGB\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "wallarooPrefix = \"\"\n",
    "wallarooSuffix = \"autoscale-uat-gcp.wallaroo.dev\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"housepricemodel\"\n",
    "model_file = \"./models/housing_model_xgb.onnx\"\n",
    "pipeline_name = \"housing-pipe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload The Model\n",
    "\n",
    "With the connection set and workspace prepared, upload the model created in `02_automated_training_process.ipynb` into the current workspace.\n",
    "\n",
    "To ensure the model input contract matches the provided input, the configuration `tensor_fields=[\"tensor\"]` is used so regardless of what the model input type is, Wallaroo will ensure inputs of type `tensor` are accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpmodel = (wl.upload_model(model_name, \n",
    "                           model_file, \n",
    "                           framework=wallaroo.framework.Framework.ONNX)\n",
    "                           .configure(tensor_fields=[\"tensor\"]\n",
    "                        )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Processing Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the preprocessing and postprocessing models that formats the incoming data into a shape the model is trained to accept, and the outgoing data from the model into a format we can use in our production system.\n",
    "\n",
    "For more details on deploying Python models in Wallaroo, see [Model Uploads and Registrations: Python Models](https://staging.docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-upload-register/wallaroo-model-operations-upload-register--python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('id', pa.int64()),\n",
    "    pa.field('date', pa.string()),\n",
    "    pa.field('list_price', pa.float64()),\n",
    "    pa.field('bedrooms', pa.int64()),\n",
    "    pa.field('bathrooms', pa.float64()),\n",
    "    pa.field('sqft_living', pa.int64()),\n",
    "    pa.field('sqft_lot', pa.int64()),\n",
    "    pa.field('floors', pa.float64()),\n",
    "    pa.field('waterfront', pa.int64()),\n",
    "    pa.field('view', pa.int64()),\n",
    "    pa.field('condition', pa.int64()),\n",
    "    pa.field('grade', pa.int64()),\n",
    "    pa.field('sqft_above', pa.int64()),\n",
    "    pa.field('sqft_basement', pa.int64()),\n",
    "    pa.field('yr_built', pa.int64()),\n",
    "    pa.field('yr_renovated', pa.int64()),\n",
    "    pa.field('zipcode', pa.int64()),\n",
    "    pa.field('lat', pa.float64()),\n",
    "    pa.field('long', pa.float64()),\n",
    "    pa.field('sqft_living15', pa.int64()),\n",
    "    pa.field('sqft_lot15', pa.int64()),\n",
    "    pa.field('sale_price', pa.float64())\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('tensor', pa.list_(pa.float32(), list_size=18))\n",
    "])\n",
    "\n",
    "preprocess_model = wl.upload_model(\"preprocess-step\", \"./models/preprocess_step.zip\", \\\n",
    "                                   framework=wallaroo.framework.Framework.PYTHON, \\\n",
    "                                   input_schema=input_schema, output_schema=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocess model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('variable', pa.list_(pa.float32()))\n",
    "])\n",
    "\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('variable', pa.list_(pa.float32()))\n",
    "])\n",
    "\n",
    "postprocess_model = wl.upload_model(\"postprocess-step\", \"./models/postprocess_step.zip\", \\\n",
    "                                   framework=wallaroo.framework.Framework.PYTHON, \\\n",
    "                                   input_schema=input_schema, output_schema=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Deploy the Pipeline\n",
    "\n",
    "Create the pipeline with the preprocess module, housing model, and postprocess module as pipeline steps, then deploy the newpipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>housing-pipe</td></tr><tr><th>created</th> <td>2024-04-03 20:28:42.964833+00:00</td></tr><tr><th>last_updated</th> <td>2024-04-03 20:28:44.606224+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>ed46770b-fcf7-4f4a-9462-1a738b586a6d, db66474c-699a-4833-8c94-63627f43c0a2</td></tr><tr><th>steps</th> <td>preprocess-step</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'housing-pipe', 'create_time': datetime.datetime(2024, 4, 3, 20, 28, 42, 964833, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess-step', 'version': '14bb5a41-457a-4859-8a2a-4ab43a96b416', 'sha': 'c09bbca6748ff23d83f48f57446c3ad6b5758c403936157ab731b3c269c0afb9'}]}}, {'ModelInference': {'models': [{'name': 'housepricemodel', 'version': 'f2cfef5f-845b-463c-a4b1-d65cd348aa17', 'sha': 'd8b79e526eed180d39d4653b39bebd9d06e6ae7f68293b5745775a9093a3ae7d'}]}}, {'ModelInference': {'models': [{'name': 'postprocess-step', 'version': 'c98a79f7-3e4d-45a0-a4c4-581218935f1d', 'sha': 'c4dfec3dd259395598646ce85b8efd7811840dc726bf4915c39d862b87fc7070'}]}}]\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = wl.build_pipeline(pipeline_name)\n",
    "\n",
    "pipeline.undeploy()\n",
    "# clear if the tutorial was run before\n",
    "pipeline.clear()\n",
    "\n",
    "pipeline.add_model_step(preprocess_model)\n",
    "pipeline.add_model_step(hpmodel)\n",
    "pipeline.add_model_step(postprocess_model)\n",
    "\n",
    "deploy_config = wallaroo.DeploymentConfigBuilder().replica_count(1).cpus(0.5).memory(\"1Gi\").build()\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline\n",
    "\n",
    "We will use a single query from the simulated `housing_price` table and infer.  When successful, we will undeploy the pipeline to restore the resources back to the Kubernetes environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from house_listings limit 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>list_price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date  list_price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  2023-08-21    221900.0         3        1.0         1180   \n",
       "\n",
       "   sqft_lot  \n",
       "0      5650  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = simdb.simulate_db_connection()\n",
    "\n",
    "# create the query\n",
    "query = f\"select * from {simdb.tablename} limit 1\"\n",
    "print(query)\n",
    "\n",
    "# read in the data\n",
    "singleton = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "display(singleton.loc[:, [\"id\", \"date\", \"list_price\", \"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/wallaroo/deployment.py:638\u001b[0m, in \u001b[0;36mDeployment._make_infer_request\u001b[0;34m(self, data, headers, params, timeout)\u001b[0m\n\u001b[1;32m    629\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url(),\n\u001b[1;32m    631\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    637\u001b[0m     )\n\u001b[0;32m--> 638\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/requests/models.py:943\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api.autoscale-uat-gcp.wallaroo.dev/v1/api/pipelines/infer/housing-pipe-266/housing-pipe?dataset%5B%5D=%2A&dataset.exclude%5B%5D=metadata&dataset.separator=.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingleton\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/wallaroo/pipeline.py:65\u001b[0m, in \u001b[0;36mupdate_timestamp.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 65\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_infer_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;66;03m# could be arbitrary json if not InferenceResult, which may not have \"time\" in results\u001b[39;00m\n\u001b[1;32m     69\u001b[0m             r\u001b[38;5;241m.\u001b[39mtimestamp() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, InferenceResult) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m     71\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/wallaroo/pipeline.py:700\u001b[0m, in \u001b[0;36mPipeline.infer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    698\u001b[0m deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deployment_for_pipeline()\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deployment:\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_exclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_separator\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline \u001b[39m\u001b[38;5;132;01m{self.name}\u001b[39;00m\u001b[38;5;124m is not deployed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/wallaroo/deployment.py:684\u001b[0m, in \u001b[0;36mDeployment.infer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow.Table\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, dict or list is required\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m--> 684\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_with_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, pa\u001b[38;5;241m.\u001b[39mTable):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_with_arrow(tensor, params, timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/wallaroo/deployment.py:535\u001b[0m, in \u001b[0;36mDeployment._infer_with_pandas\u001b[0;34m(self, tensor, params, timeout)\u001b[0m\n\u001b[1;32m    531\u001b[0m input_records \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: PANDAS_RECORDS_HEADER,\n\u001b[1;32m    534\u001b[0m }\n\u001b[0;32m--> 535\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_infer_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_records\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     data \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk.2024.1.beta/lib/python3.9/site-packages/wallaroo/deployment.py:640\u001b[0m, in \u001b[0;36mDeployment._make_infer_request\u001b[0;34m(self, data, headers, params, timeout)\u001b[0m\n\u001b[1;32m    638\u001b[0m     res\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceError(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_error\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    642\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout,\n\u001b[1;32m    643\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mReadTimeout,\n\u001b[1;32m    644\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[1;32m    645\u001b[0m ):\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference did not return within \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, adjust if necessary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "result = pipeline.infer(singleton)\n",
    "# display(result.loc[:, ['time', 'out.variable']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we undeploy the pipeline to return the resources back to the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this stage complete, we can proceed to Stage 4: Regular Batch Inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
