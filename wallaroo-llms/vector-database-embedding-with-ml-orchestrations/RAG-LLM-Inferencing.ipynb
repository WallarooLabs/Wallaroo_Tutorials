{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a749d3e9-2abb-484f-a4aa-360d2c7297a8",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.2_tutorials/wallaroo-llms/vector-database-embedding-with-ml-orchestrations).\n",
    "\n",
    "## RAG LLMs: Inference in Wallaroo\n",
    "\n",
    "The following demonstrates using a Bidirectional Attentive Autoencoder for Inducing Semantics (BAAI) general embedding (BGE) model with a RAG LLM to perform inference requests through Wallaroo agaisnt a vector database.  The vector database is pre-embedded from the same BAAI BGE model.  See the accompanying notebook \"RAG LLMs: Automated Vector Database Enrichment in Wallaroo\".\n",
    "\n",
    "This process uses Wallaroo features to:\n",
    "\n",
    "* Receive an inference request from a requester.\n",
    "* Convert the inference request into an embedding.\n",
    "* Request from the vector database data based on the embedding.\n",
    "* Generate the response from the RAG LLM with the appropriate context, and return the final result to the requester.\n",
    "\n",
    "For this example, the [Mongo Atlas Vector Database](https://www.mongodb.com/lp/cloud/atlas/try4) is used as the representational database.\n",
    "\n",
    "For access to these sample models and for a demonstration of how to use a LLM Validation Listener.\n",
    "\n",
    "* Contact your Wallaroo Support Representative **OR**\n",
    "* [Schedule Your Wallaroo.AI Demo Today](https://wallaroo.ai/request-a-demo/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cda6f-86c4-4b4c-b32c-ea45515efa4c",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Imports\n",
    "\n",
    "We start by importing the libraries used for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae582c-52b4-47d4-ba7f-464a3af8db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.pipeline   import Pipeline\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90f7d4",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "This step sets a connection to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cd707-710f-48b6-8a32-25100751136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07835c32-2191-4f8e-b297-974c3f42c6c6",
   "metadata": {},
   "source": [
    "### Upload BGE Model\n",
    "\n",
    "Before uploading the BGE model, we define the input and output schemas in Apache PyArrow Schema format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a0dff-c893-4cc1-ad69-949eaa0f1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('text', pa.string())\n",
    "])\n",
    "output_schema = pa.schema([\n",
    "    pa.field('embedding', \n",
    "        pa.list_(\n",
    "            pa.float64(), list_size=768\n",
    "        ),\n",
    "    ),\n",
    "    pa.field('text', pa.string())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3ed82-2377-4679-948c-921eb7d6ec8d",
   "metadata": {},
   "source": [
    "The BGE model is a Hugging Face model in a Wallaroo BYOP framework in the file `byop_bge_base2.zip`.  We upload it to Wallaroo via the `wallaroo.client.Client.upload_model` method, providing the following parameters:\n",
    "\n",
    "* The name to assign to the BGE model.\n",
    "* The file path to upload the model.\n",
    "* The Framework set to `wallaroo.framework.Framework.CUSTOM` for our Hugging Face model encapsulated in the BYOP framework.\n",
    "* The input and output schemas.\n",
    "\n",
    "For more information, see the Wallaroo [Model Upload](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-upload-register/) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb99e56-18d2-4bf9-bc89-b9d0137a7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "bge = wl.upload_model('byop-bge-base-v2', \n",
    "    'byop_bge_base2.zip',\n",
    "    framework=Framework.CUSTOM,\n",
    "    input_schema=input_schema,\n",
    "    output_schema=output_schema,\n",
    ")\n",
    "bge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc26d0-8740-4f5d-8cbe-96aebc66791f",
   "metadata": {},
   "source": [
    "### Upload Modified RAG Llama LLM\n",
    "\n",
    "For the RAG LLM, we use a modified Llama.cpp LLM as our RAG LLM.  The RAG LLM uses the embedding from the BGE model to query the vector database index, and uses that result as the context to generate the text.\n",
    "\n",
    "As before, we set the input and output schemas, then upload the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959c269-3b21-4aac-865b-ce4e7c68ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('text', pa.string()),\n",
    "    pa.field('embedding', pa.list_(pa.float32(), list_size=768))\n",
    "]) \n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('generated_text', pa.string()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7351f-3b94-4353-978c-9eb36d17aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = wl.upload_model('byop-llamacpp-rag-v1', \n",
    "    'byop_llamacpp_rag.zip',\n",
    "    framework=Framework.CUSTOM,\n",
    "    input_schema=input_schema,\n",
    "    output_schema=output_schema,\n",
    ")\n",
    "llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13732a4f-4f0d-40e7-8c9b-e7ba4145d927",
   "metadata": {},
   "source": [
    "### Deploy BGE and RAG LLM\n",
    "\n",
    "The models are deployed by:\n",
    "\n",
    "1. Setting the **deployment configuration** that sets the resources allocated from the cluster for the BGE and LLMs exclusive use.  The following settings are used:\n",
    "   1. BGE: 4 cpus, 3 Gi RAM\n",
    "   2. LLM: 4 cpus, 6 Gi RAM\n",
    "2. Adding the BGE model and LLM to a **Wallaroo pipeline** as **model steps**.\n",
    "3. Deploy the models.  Once the deployment is complete, they are ready to accept inference requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc41158-6359-4f7d-ac1b-3da4e7f24f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(1).memory('2Gi') \\\n",
    "    .sidekick_cpus(bge, 4) \\\n",
    "    .sidekick_memory(bge, '3Gi') \\\n",
    "    .sidekick_cpus(llama, 4) \\\n",
    "    .sidekick_memory(llama, '6Gi') \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a2b6c-de68-4ec1-9375-87df85b2c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = wl.build_pipeline(\"byop-rag-llm-bge-v1\")\n",
    "pipeline.add_model_step(bge)\n",
    "pipeline.add_model_step(model)\n",
    "pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc4eb6-33cb-4fbf-84c1-2bfe4841e69c",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Inference requests are submitted either as pandas DataFrames or Apache Arrow tables. The following example shows submitting a pandas DataFrame with the query to suggest an action movie. The response is returned as a pandas DataFrame, and we extract the generated text from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ba0f7-6642-4874-9858-3a04d7b76195",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"text\": [\"Suggest me an action movie, including it's name\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d71120-4f46-4518-90c1-8690f05c5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'1. \"The Battle of Algiers\" (1966) - This film follows the story of the National Liberation Front (FLN) fighters during the Algerian Revolution, and their struggle against French colonial rule. 2. \"The Goodfather\" (1977) - A mobster's rise to power is threatened by his weaknesses, including his loyalty to his family and his own moral code. 3. \"Dog Day Afternoon\" (1975) - A desperate bank clerk turns to a life of crime when he can't pay his bills, but things spiral out'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pipeline.infer(data, timeout=10000)\n",
    "result['out.generated_text'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4a7f0-f2f4-4b7f-a39e-2ea33801fe3b",
   "metadata": {},
   "source": [
    "## Undeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972ace8-ec39-4288-8ccb-5f7e39a3af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fccbe8",
   "metadata": {},
   "source": [
    "For access to these sample models and for a demonstration of how to use a LLM Validation Listener.\n",
    "\n",
    "* Contact your Wallaroo Support Representative **OR**\n",
    "* [Schedule Your Wallaroo.AI Demo Today](https://wallaroo.ai/request-a-demo/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
