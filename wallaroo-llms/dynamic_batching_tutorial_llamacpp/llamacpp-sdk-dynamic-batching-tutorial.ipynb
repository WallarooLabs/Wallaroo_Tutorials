{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acca671d",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.3_tutorials/wallaroo-llms/dynamic_batching_tutorial_llamacpp).\n",
    "\n",
    "## Dynamic Batching with Llama 3 8B Quantized with Llama.cpp CPUs Tutorial\n",
    "\n",
    "When multiple inference requests are sent from one or multiple clients, a **Dynamic Batching Configuration** accumulates those inference requests as one \"batch\", and processed at once.  This increases efficiency and inference result performance by using resources in one accumulated batch rather than starting and stopping for each individual request.  Once complete, the individual inference results are returned back to each client.  \n",
    "\n",
    "The following tutorial demonstrates configuring a Llama 3 8B Instruct vLLM with a Wallaroo Dynamic Batching Configuration.\n",
    "\n",
    "This example uses the Llama V3 8B quantized with Llama.cpp LLM.  For access to these sample models and for a demonstration of how to use LLM Listener Monitoring to monitor LLM performance and outputs:\n",
    "\n",
    "* Contact your Wallaroo Support Representative **OR**\n",
    "* [Schedule Your Wallaroo.AI Demo Today](https://wallaroo.ai/request-a-demo/)\n",
    "\n",
    "## Tutorial Overview\n",
    "\n",
    "This tutorial demonstrates using Wallaroo to:\n",
    "\n",
    "* Upload a LLM\n",
    "* Define a Dynamic Batching Configuration and apply it to the LLM.\n",
    "* Deploy a the LLM with a Deployment Configuration that allocates resources to the LLM; the Dynamic Batch Configuration is applied at the LLM level, so it inherited during deployment.\n",
    "* Demonstrate how to perform a sample inference.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "The following tutorial requires the following:\n",
    "\n",
    "* Llama V3 8B quantized with llama-cpp encapsulated in the Wallaroo Arbitrary Python aka BYOP Framework.  This is available through a Wallaroo representative.\n",
    "* Wallaroo version 2024.3 and above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfd2d4",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca0bc3e-9a4a-4b34-bb17-bd0fffb6a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.pipeline   import Pipeline\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "from wallaroo.framework import Framework\n",
    "from wallaroo.engine_config import Architecture\n",
    "from wallaroo.dynamic_batching_config import DynamicBatchingConfig\n",
    "\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401335cf",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "A connection to Wallaroo is established via the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6712f9-871f-4224-8a9e-d44520a25628",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558ea37-f227-45dc-a637-c8a7a0e552db",
   "metadata": {},
   "source": [
    "### Upload Model\n",
    "\n",
    "For our example, we'll upload the model via the Wallaroo SDk and the `wallaroo.client.Client.upload_model` method which takes the following parameters:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "|`name` | *String* (*Required*) | The name of the model.  Model names are unique per workspace.  Models that are uploaded with the same name are assigned as a new **version** of the model. |\n",
    "|`path` | *String* (*Required*) | The path to the model file being uploaded. |\n",
    "|`framework` |*String* (*Required*) | Set as the `Framework.ONNX`. |\n",
    "|`input_schema` | *pyarrow.lib.Schema* (*Optional*) | The input schema in Apache Arrow schema format. |\n",
    "|`output_schema` | *pyarrow.lib.Schema* (*Optional*) | The output schema in Apache Arrow schema format. |\n",
    "| `convert_wait` | *Boolean* (*Optional*) (*Default: True*) | Not required for native runtimes. <ul><li>**True**: Waits in the script for the model conversion completion.</li><li>**False**:  Proceeds with the script without waiting for the model conversion process to display complete. |\n",
    "\n",
    "A dynamic batching configuration is applied with the `wallaroo.client.Client.upload_model.configure` with following parameters.\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| `dynamic_batching_config` | *wallaroo.DynamicBatchingConfig* (*Default: None*) | Sets the dynamic batch config to apply to the model.  |\n",
    "| `input_schema` | `pyarrow.lib.Schema` (*Required*) | The input schema in Apache Arrow schema format.  This field is **required** when the `dynamic_batch_config` parameter is set. |\n",
    "| `output_schema` | `pyarrow.lib.Schema` (*Required*) | The output schema in Apache Arrow schema format.  This field is **required** when the `dynamic_batch_config` parameter is set. |\n",
    "| `batch_config` | *String* | Batch config is either `None` for multiple-input inferences, or `single` to accept an inference request with only one row of data.  **This setting is mutually exclusive with `dynamic_batching_config`**.  If `dynamic_batching_config` is set, `batch_config` **must** be `None`.  If `batch_config` is set to `single` **and** a `dynamic_batch_config` is set, the following error is returned:  `Dynamic batching is not supported with single batch mode. Please update the model configuration or contact wallaroo for support at support@wallaroo.ai.` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a6693e0-f96b-45e5-8253-437c9ca28bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field(\"text\", pa.string())\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field(\"generated_text\", pa.string())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd8718e6-3475-42d1-b5c5-e3a57fc54b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for model loading - this will take up to 10.0min.\n",
      "Model is pending loading to a container runtime..\n",
      "Model is attempting loading to a container runtime..............successful\n",
      "\n",
      "Ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>llama-cpp-sdk-dynbatch2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>0fb39697-c5ee-4c91-8346-3d05783efe19</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>byop_llamacpp.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>e44db803330cdfdb889c79fb6b5297bccd2b81640d5023b05db9b3845b31e91b</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2024.3.0-main-5713</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>x86</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Acceleration</td>\n",
       "          <td>none</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2024-03-Oct 19:22:28</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Workspace id</td>\n",
       "          <td>28</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Workspace name</td>\n",
       "          <td>younes.amar@wallaroo.ai - Default Workspace</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'llama-cpp-sdk-dynbatch2', 'version': '0fb39697-c5ee-4c91-8346-3d05783efe19', 'file_name': 'byop_llamacpp.zip', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2024.3.0-main-5713', 'arch': 'x86', 'accel': 'none', 'last_update_time': datetime.datetime(2024, 10, 3, 19, 22, 28, 451229, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = wl.upload_model('llama-cpp-sdk-dynbatch2', \n",
    "    'byop_llamacpp.zip',\n",
    "    framework=Framework.CUSTOM,\n",
    "    input_schema=input_schema,\n",
    "    output_schema=output_schema\n",
    ").configure(input_schema=input_schema,\n",
    "            output_schema=output_schema,\n",
    "            dynamic_batching_config=DynamicBatchingConfig(max_batch_delay_ms=1000, \n",
    "                                                          batch_size_target=8)\n",
    "            )\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0767f9-8b74-4025-831e-49ebb06599b6",
   "metadata": {},
   "source": [
    "### Deploy LLM with Dynamic Batch Configuration\n",
    "\n",
    "Deploying a LLM with a Dynamic Batch configuration requires the same steps as deploying a LLM **without** a Dynamic Batch configuration:\n",
    "\n",
    "* Define the deployment configuration to set the number of CPUs, RAM, and GPUs per replica.\n",
    "* Create a Wallaroo pipeline and add the LLM with the Dynamic Batch configuration as a model step.\n",
    "* Deploy the Wallaroo pipeline with the deployment configuration.\n",
    "\n",
    "The deployment configuration sets what resources are allocated to the LLM upon deployment.  For this example, we allocate the following resources:\n",
    "\n",
    "* cpus: 4\n",
    "* memory:  10Gi\n",
    "* gpus: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91e7a7cf-5fc8-44ec-b16b-d0bd82bb22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(1).memory('2Gi') \\\n",
    "    .sidekick_cpus(model, 4) \\\n",
    "    .sidekick_memory(model, '10Gi') \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021ad3d",
   "metadata": {},
   "source": [
    "We create the pipeline with the `wallaroo.client.Client.build_pipeline` method.\n",
    "\n",
    "Wallaroo pipelines are created with the `wallaroo.client.Client.build_pipeline` method.  [Pipeline steps](https://staging.docs.wallaroo.ai/202402/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-deploy-model/#pipeline-steps) are used to determine how inference data is provided to the LLM.  For Dynamic Batching, only **one pipeline step** is allowed.\n",
    "\n",
    "The following demonstrates creating a Wallaroo pipeline, and assigning the LLM as a pipeline step.\n",
    "\n",
    "With LLM, deployment configuration, and pipeline ready, we can deploy.  Note that the Dynamic Batch Config is not specified during the deployment - that is assigned to the LLM, and inherits those settings for its deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0c6c5-bee6-4be3-9fd3-67f30532a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = wl.build_pipeline(\"llamacpp-pipeyns-dynbatch2\")\n",
    "pipeline.add_model_step(model)\n",
    "pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e1e7b8b-f92e-4caf-837c-4444061fdbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.4.3.14',\n",
       "   'name': 'engine-6749ff446f-zftzd',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'llamacpp-pipeyns-dynbatch2',\n",
       "      'status': 'Running',\n",
       "      'version': '56c41ea8-3a5d-44f4-9513-829ae544ab72'}]},\n",
       "   'model_statuses': {'models': [{'model_version_id': 124,\n",
       "      'name': 'llama-cpp-sdk-dynbatch2',\n",
       "      'sha': 'e44db803330cdfdb889c79fb6b5297bccd2b81640d5023b05db9b3845b31e91b',\n",
       "      'status': 'Running',\n",
       "      'version': '0fb39697-c5ee-4c91-8346-3d05783efe19'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.4.2.5',\n",
       "   'name': 'engine-lb-6b59985857-qtcfd',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': [{'ip': '10.4.0.5',\n",
       "   'name': 'engine-sidekick-llama-cpp-sdk-dynbatch2-124-74958d9794-cqgsk',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'statuses': '\\n'}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de95ca9-0a64-4d8f-b91f-60b1527e26f1",
   "metadata": {},
   "source": [
    "### Sample Inference\n",
    "\n",
    "Once the LLM is deployed, we'll perform an inference with the `wallaroo.pipeline.Pipeline.infer` method, which accepts either a pandas DataFrame or an Apache Arrow table.\n",
    "\n",
    "For this example, we'll create a pandas DataFrame with a text query and submit that for our inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c468b4da-ff9f-4639-b972-c8d7cd68da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'text': ['Describe what roland garros is']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c9feef8-ce6d-4aca-9f2e-2105a8efd79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Roland Garros, also known as the French Open, is a major tennis tournament that takes place in Paris, France every June. It is one of the four Grand Slam tennis tournaments held annually around the world, along with the Australian Open, Wimbledon, and the US Open. The tournament is named after the French aviator Roland Garros, who was a pioneer in the field of aircraft design and construction. The tournament was first played in 1891 and has been held continuously ever since, except for a few years during World War I and II. It is one of the most prestigious tennis tournaments in the world and attracts many of the top players from around the globe. The tournament is played on clay courts, which are known for their slow speed and high traction, making it a challenging surface for players to navigate. The Roland Garros tournament typically takes place over a two-week period in late May and early June, with the men's and women's singles competitions being the most highly anticipated events.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pipeline.infer(data, timeout=10000)\n",
    "result[\"out.generated_text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588d038-84e0-4174-a05d-342e7f14586b",
   "metadata": {},
   "source": [
    "### Undeploy LLM\n",
    "\n",
    "With the tutorial complete, we undeploy the LLM and return the resources back to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb5e52-6c24-4a85-ab62-30875554c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
