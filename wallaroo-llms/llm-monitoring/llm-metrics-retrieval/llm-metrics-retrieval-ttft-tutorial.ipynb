{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Retrieval for Llama 3 8B Instruct Tutorial\n",
    "\n",
    "The following tutorial demonstrates using the Wallaroo MLOps API to retrieve Wallaroo metrics data for a Llama v3 8b model.  These requests are compliant with Prometheus API endpoints.\n",
    "\n",
    "This tutorial demonstrates pulling metrics information for a previously deployed a LLM [deployed with OpenAI Compatibility in Wallaroo](https://docs.wallarooai/wallaroo-llm/wallaroo-llm-package-deployment/wallaroo-llm-optimizations-openai-compatibility/).\n",
    "\n",
    "For access to these sample models and for a demonstration:\n",
    "\n",
    "* Contact your Wallaroo Support Representative **OR**\n",
    "* [Schedule Your Wallaroo.AI Demo Today](https://wallaroo.ai/request-a-demo/)\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This tutorial assumes the following:\n",
    "\n",
    "* A Wallaroo Ops environment is installed.\n",
    "* The Wallaroo SDK is installed.  These examples use the Wallaroo SDK to generate the initial inferences information for the metrics requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "This part of the tutorial generates the inference results used for the rest of the tutorial.\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries required.  This includes the Wallaroo SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "import wallaroo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "A connection to Wallaroo is established via the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallaroo Dashboard Metrics Retrieval via the Wallaroo MLOps API\n",
    "\n",
    "The Wallaroo MLOps API allows for metrics retrieval.  These are used to track:\n",
    "\n",
    "* Inference result performance.\n",
    "* Deployed replicas.\n",
    "* Inference Latency.\n",
    "\n",
    "These inference endpoints are compliant with Prometheus endpoints.\n",
    "\n",
    "<details>\n",
    "<summary><h3 id=\"supported-queries\">Supported Queries</h3></summary>\n",
    "The following queries are supported through the Metrics endpoints.  The following references are used here:\n",
    "\n",
    "* `pipelineID`:  The pipeline's numerical identifier, retrieved from the Wallaroo SDK with `wallaroo.pipeline.Pipeline.name()`.  For example:\n",
    "\n",
    "    ```python\n",
    "    pipeline.name()\n",
    "    ```\n",
    "\n",
    "    ```text\n",
    "    sample-pipeline-name\n",
    "    ```\n",
    "\n",
    "* `deployment_id`: The Kubernetes namespace for the deployment.\n",
    "\n",
    "| Name | Parameterized Query | Example Query | Description |\n",
    "|---|---|---|---|\n",
    "| Requests per second | `sum by (pipeline_name) (rate(latency_histogram_ns_count{pipeline_name=\"{pipelineID}\"}[{step}s]))` | `sum by (deploy_id) (rate(latency_histogram_ns_count{deploy_id=\"deployment_id\"}[10s]))` | Number of processed requests per second to a pipeline. |\n",
    "| Cluster inference rate | `sum by (pipeline_name) (rate(tensor_throughput_batch_count{pipeline_name=\"{pipelineID}\"}[{step}s]))` | `sum by (deploy_id) (rate(tensor_throughput_batch_count{deploy_id=\"deployment_id\"}[10s]))` | Number of inferences processed per second.  This notably differs from requests per second when batch inference requests are made. |\n",
    "| P50 inference latency | `histogram_quantile(0.50, sum(rate(latency_histogram_ns_bucket{{deploy_id=\"{deploy_id}\"}}[{step_interval}])) by (le)) / 1e6` | `histogram_quantile(0.50, sum(rate(latency_histogram_ns_bucket{deploy_id=\"deployment_id\"}[10s])) by (le)) / 1e6` | Histogram for P90 total inference time spent per message in an engine, includes transport to and from the sidekick in the case there is one. |\n",
    "| P95 inference latency | `histogram_quantile(0.95, sum(rate(latency_histogram_ns_bucket{{deploy_id=\"{deploy_id}\"}}[{step_interval}])) by (le)) / 1e6` | `histogram_quantile(0.95, sum(rate(latency_histogram_ns_bucket{deploy_id=\"deployment_id\"}[10s])) by (le)) / 1e6` | Histogram for P95 total inference time spent per message in an engine, includes transport to and from the sidekick in the case there is one. |\n",
    "| P99 inference latency | `histogram_quantile(0.99, sum(rate(latency_histogram_ns_bucket{{deploy_id=\"{deploy_id}\"}}[{step_interval}])) by (le)) / 1e6` | `histogram_quantile(0.99, sum(rate(latency_histogram_ns_bucket{deploy_id=\"deployment_id\"}[10s])) by (le)) / 1e6` | Histogram for P99 total inference time spent per message in an engine, includes transport to and from the sidekick in the case there is one. |\n",
    "| Engine replica count | `count(container_memory_usage_bytes{namespace=\"{pipeline_namespace}\", container=\"engine\"}) or vector(0)` | `count(container_memory_usage_bytes{namespace=\"deployment_id\", container=\"engine\"}) or vector(0)` | Number of engine replicas currently running in a pipeline |\n",
    "| Sidekick replica count | `count(container_memory_usage_bytes{namespace=\"{pipeline_namespace}\", container=~\"engine-sidekick-.*\"}) or vector(0)` | `count(container_memory_usage_bytes{namespace=\"deployment_id\", container=~\"engine-sidekick-.*\"}) or vector(0)` | Number of sidekick replicas currently running in a pipeline |\n",
    "| Output tokens per second (TPS) | `sum by (namespace) (rate(vllm:generation_tokens_total{namespace=\"{pipeline_namespace}\"}[{step_interval}]))` | `sum by (namespace) (rate(vllm:generation_tokens_total{namespace=\"deployment_id\"}[10s]))` | LLM output tokens per second: this is the number of tokens generated per second for a LLM deployed in Wallaroo with vLLM |\n",
    "| P99 Time to first token (TTFT) | `histogram_quantile(0.99, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"{pipeline_namespace}\"}[{step_interval}])) by (le)) * 1000` | `histogram_quantile(0.99, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"deployment_id\"}[10s])) by (le)) * 1000` | P99 time to first token: P99 for time to generate the first token for LLMs deployed in Wallaroo with vLLM |\n",
    "| P95 Time to first token (TTFT) | `histogram_quantile(0.95, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"{pipeline_namespace}\"}[{step_interval}])) by (le)) * 1000` | `histogram_quantile(0.95, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"deployment_id\"}[10s])) by (le)) * 1000` | P95 time to first token: P95 for time to generate the first token for LLMs deployed in Wallaroo with vLLM |\n",
    "| P50 Time to first token (TTFT) | `histogram_quantile(0.50, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"{pipeline_namespace}\"}[{step_interval}])) by (le)) * 1000` | `histogram_quantile(0.50, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"deployment_id\"}[10s])) by (le)) * 1000` | P50 time to first token: P50 for time to generate the first token for LLMs deployed in Wallaroo with vLLM |\n",
    "\n",
    "</details>\n",
    "\n",
    "### Query Metric Request Endpoints\n",
    "\n",
    "* **Endpoints**: \n",
    "  * `/v1/api/metrics/query` (**GET**)\n",
    "  * `/v1/api/metrics/query` (**POST**)\n",
    "\n",
    "For full details, see the [Wallaroo MLOps API Reference Guide](https://docs.wallarooai/wallaroo-developer-guides/wallaroo-api-guide/wallaroo-mlops-api-reference-guide/#operations-tag-metrics)\n",
    "\n",
    "#### Query Metric Request Parameters\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| query | *String* | The Prometheus expression query string. |\n",
    "| time | *String* | The evaluation timestamp in either RFC3339 format or Unix timestamp. |\n",
    "| timeout | *String* | The evaluation timeout in duration format (`5m` for 5 minutes, etc). |\n",
    "\n",
    "#### Query Metric Request Returns\n",
    "\n",
    "| Field | &nbsp; | Type | Description |\n",
    "|---|---|---|---|\n",
    "| **status** | &nbsp; | *String* | The status of the request of either `success` or `error`. |\n",
    "| **data** | &nbsp; | *Dict* | The response data. |\n",
    "| &nbsp; | **data.resultType** | *String* | The type of query result. |\n",
    "| &nbsp; | **data.result** | *String* | DateTime of the model's creation. |\n",
    "| **errorType** | &nbsp; | *String* | The error type if `status` is `error`. |\n",
    "| **errorType** | &nbsp; | *String* | The error messages if `status` is `error`. |\n",
    "| **warnings** | &nbsp; | *Array[String]* | An array of error messages. |\n",
    "\n",
    "### Query Range Metric Endpoints\n",
    "\n",
    "* **Endpoints**\n",
    "  * `/v1/api/metrics/query_range` (**GET**)\n",
    "  * `/v1/api/metrics/query_range` (**POST**)\n",
    "\n",
    "Returns a list of models added to a specific workspace.\n",
    "\n",
    "#### Query Range Metric Request Parameters\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| query | *String* | The Prometheus expression query string. |\n",
    "| start | *String* | The starting timestamp in either RFC3339 format or Unix timestamp, inclusive. |\n",
    "| end | *String* | The ending timestamp in either RFC3339 format or Unix timestamp. |\n",
    "| step | *String* | Query resolution step width in either duration format or as a float number of seconds. |\n",
    "| timeout | *String* | The evaluation timeout in duration format (`5m` for 5 minutes, etc). |\n",
    "\n",
    "#### Query Range Metric Request Returns\n",
    "\n",
    "| Field | &nbsp; | Type | Description |\n",
    "|---|---|---|---|\n",
    "| **status** | &nbsp; | *String* | The status of the request of either `success` or `error`. |\n",
    "| **data** | &nbsp; | *Dict* | The response data. |\n",
    "| &nbsp; | **resultType** | *String* | The type of query result. For query range, always `matrix`. |\n",
    "| &nbsp; | **result** | *String* | DateTime of the model's creation. |\n",
    "| **errorType** | &nbsp; | *String* | The error type if `status` is `error`. |\n",
    "| **errorType** | &nbsp; | *String* | The error messages if `status` is `error`. |\n",
    "| **warnings** | &nbsp; | *Array[String]* | An array of error messages. |\n",
    "\n",
    "### TTFT Metrics Example\n",
    "\n",
    "The following request shows an example of a Query Range request for requests per second.  For this example, the following Wallaroo SDK methods are used:\n",
    "\n",
    "* `wl.api_endpoint`: Retrieves the API endpoint for the Wallaroo Ops server.\n",
    "* `wl.auth.auth_header()`: Retrieves the authentication bearer tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTFT Query Example\n",
    "\n",
    "The following example uses the P99 Time to first token (TTFT) query.\n",
    "\n",
    "For this example, we set the following:\n",
    "\n",
    "* Data start and data end periods\n",
    "* Steps of the calculation\n",
    "* The name and deployment of the Wallaroo pipeline the LLM is deployed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram_quantile(0.99, sum(rate(vllm:time_to_first_token_seconds_bucket{namespace=\"llama-3-1-8b-pipeline-210\"}[5m])) by (le)) * 1000\n",
      "{'status': 'success', 'data': {'resultType': 'matrix', 'result': [{'metric': {}, 'values': [[1752505500, '48.45656000000012'], [1752505800, '39.800000000000004'], [1752506100, 'NaN']]}]}}\n"
     ]
    }
   ],
   "source": [
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Central\"\n",
    "\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "\n",
    "# Define the start and end times of 10:00 to 10:15\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 7, 14, 10, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 7, 14, 10, 15, 00))\n",
    "\n",
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query_range\"\n",
    "\n",
    "import time\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# Convert to UTC and get the Unix timestamps\n",
    "start_timestamp = int(data_start.astimezone(pytz.UTC).timestamp())\n",
    "end_timestamp = int(data_end.astimezone(pytz.UTC).timestamp())    \n",
    "\n",
    "pipeline_name = \"llama-3-1-8b-pipeline\" # the name of the pipeline\n",
    "deploy_id = 210 # the deployment id\n",
    "step = \"5m\" # the step of the calculation\n",
    "\n",
    "\n",
    "query_ttft = f'histogram_quantile(0.99, sum(rate(vllm:time_to_first_token_seconds_bucket{{namespace=\"{pipeline_name}-{deploy_id}\"}}[{step}])) by (le)) * 1000'\n",
    "print(query_ttft)\n",
    "\n",
    "#request parameters\n",
    "params_ttft = {\n",
    "    'query': query_ttft,\n",
    "    'start': start_timestamp,\n",
    "    'end': end_timestamp,\n",
    "    'step': step\n",
    "}\n",
    "\n",
    "response_rps = requests.get(query_url, headers=headers, params=params_ttft)\n",
    "\n",
    "if response_rps.status_code == 200:\n",
    "    #print(\"Requests Per Second Data:\")\n",
    "    result = response_rps.json()\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"Failed to fetch TTFT data:\", response_rps.status_code, response_rps.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output tokens per second (TPS)\n",
    "\n",
    "This example uses the \n",
    "\n",
    "TTFT Query Example\n",
    "\n",
    "The following example uses the Output tokens per second (TPS).\n",
    "\n",
    "For this example, we set the following:\n",
    "\n",
    "* Data start and data end periods\n",
    "* Steps of the calculation\n",
    "* The name and deployment of the Wallaroo pipeline the LLM is deployed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum by (namespace) (rate(vllm:generation_tokens_total{namespace=\"llama-3-1-8b-pipeline-210\"}[5m]))\n",
      "{'status': 'success', 'data': {'resultType': 'matrix', 'result': [{'metric': {'namespace': 'llama-3-1-8b-pipeline-210'}, 'values': [[1752505200, '0'], [1752505500, '0.6707186440677967'], [1752505800, '0.6779661016949152'], [1752506100, '0']]}]}}\n"
     ]
    }
   ],
   "source": [
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Central\"\n",
    "\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "\n",
    "# Define the start and end times of 10:00 to 10:15\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 7, 14, 10, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 7, 14, 10, 15, 00))\n",
    "\n",
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query_range\"\n",
    "\n",
    "import time\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# Convert to UTC and get the Unix timestamps\n",
    "start_timestamp = int(data_start.astimezone(pytz.UTC).timestamp())\n",
    "end_timestamp = int(data_end.astimezone(pytz.UTC).timestamp())    \n",
    "\n",
    "pipeline_name = \"llama-3-1-8b-pipeline\" # the name of the pipeline\n",
    "deploy_id = 210 # the deployment id\n",
    "step = \"5m\" # the step of the calculation\n",
    "\n",
    "query_tps = f'sum by (namespace) (rate(vllm:generation_tokens_total{{namespace=\"{pipeline_name}-{deploy_id}\"}}[{step}]))'\n",
    "print(query_tps)\n",
    "\n",
    "#request parameters\n",
    "params_ttft = {\n",
    "    'query': query_tps,\n",
    "    'start': start_timestamp,\n",
    "    'end': end_timestamp,\n",
    "    'step': step\n",
    "}\n",
    "\n",
    "response_rps = requests.get(query_url, headers=headers, params=params_ttft)\n",
    "\n",
    "if response_rps.status_code == 200:\n",
    "    #print(\"Requests Per Second Data:\")\n",
    "    result = response_rps.json()\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"Failed to fetch TTFT data:\", response_rps.status_code, response_rps.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk2025.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
