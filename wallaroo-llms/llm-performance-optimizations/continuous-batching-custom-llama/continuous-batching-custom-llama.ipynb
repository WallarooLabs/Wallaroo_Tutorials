{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9967cde1-bbd3-445b-8267-ab3575b4df2d",
   "metadata": {},
   "source": [
    "# vLLM Handoff - BYOP with Custom Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d4e0c-2ea2-484b-b9bb-4ea47dcac996",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e04a573-b12a-41b5-83dc-fb0548aab169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import wallaroo\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "from wallaroo.framework import Framework\n",
    "from wallaroo.engine_config import Acceleration\n",
    "from wallaroo.continuous_batching_config import ContinuousBatchingConfig\n",
    "from wallaroo.object import EntityNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7683298b-7e1b-4498-b184-7050a9034414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://autoscale-uat-gcp.wallaroo.dev/auth/realms/master/device?user_code=RRFM-MPVG\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba0f33b7-9a4d-4b9c-8c9d-75b298fa2ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025.1.0+4be069be7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wallaroo.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2206be-95e6-4ebc-9a4a-113c6dca0dfd",
   "metadata": {},
   "source": [
    "## Define Schemas & Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c006df23-acb4-4baa-b0db-129a1e7b9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('prompt', pa.string()),\n",
    "    pa.field('max_tokens', pa.int64()),\n",
    "])\n",
    "output_schema = pa.schema([\n",
    "    pa.field('generated_text', pa.string()),\n",
    "    pa.field('num_output_tokens', pa.int64())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105013f0-4688-424a-8aa7-5290fcca0323",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Upload model via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba6154-0eca-47a2-89ce-e70a7314d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64.b64encode(\n",
    "    bytes(input_schema.serialize())\n",
    ").decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695e40c-63dd-4d41-a610-42cef02951ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base64.b64encode(\n",
    "    bytes(output_schema.serialize())\n",
    ").decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec000884-a93a-424b-9d17-1e6ce6853af4",
   "metadata": {},
   "source": [
    "Run the following command in order to upload the model via **API**:\n",
    "\n",
    "```bash\n",
    "curl --progress-bar -X POST   -H \"Content-Type: multipart/form-data\"   -H \"Authorization: Bearer <your-auth-token-here>\"   -F 'metadata={\"name\": \"byop-vllm-tinyllama-async-fc-v3\", \"visibility\": \"private\", \"workspace_id\": <your-workspace-id-here>, \"conversion\": {\"framework\": \"custom\", \"python_version\": \"3.8\", \"requirements\": [], \"framework_config\": {\"config\": {\"gpu_memory_utilization\": 0.9, \"max_model_len\": 128}, \"framework\": \"custom\"}}, \"input_schema\": \"/////7AAAAAQAAAAAAAKAAwABgAFAAgACgAAAAABBAAMAAAACAAIAAAABAAIAAAABAAAAAIAAABUAAAABAAAAMT///8AAAECEAAAACQAAAAEAAAAAAAAAAoAAABtYXhfdG9rZW5zAAAIAAwACAAHAAgAAAAAAAABQAAAABAAFAAIAAYABwAMAAAAEAAQAAAAAAABBRAAAAAcAAAABAAAAAAAAAAGAAAAcHJvbXB0AAAEAAQABAAAAA==\", \"output_schema\": \"/////8AAAAAQAAAAAAAKAAwABgAFAAgACgAAAAABBAAMAAAACAAIAAAABAAIAAAABAAAAAIAAABcAAAABAAAALz///8AAAECEAAAACwAAAAEAAAAAAAAABEAAABudW1fb3V0cHV0X3Rva2VucwAAAAgADAAIAAcACAAAAAAAAAFAAAAAEAAUAAgABgAHAAwAAAAQABAAAAAAAAEFEAAAACQAAAAEAAAAAAAAAA4AAABnZW5lcmF0ZWRfdGV4dAAABAAEAAQAAAA=\"};type=application/json'   -F \"file=@byop-tinyllama-custom-config.zip;type=application/octet-stream\"   https://benchmarkscluster.wallaroocommunity.ninja/v1/api/models/upload_and_convert | cat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dfce1-e1f9-4574-bd0d-d748b04ec685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model\n",
    "model = wl.get_model(\"byop-vllm-tinyllama-async-fc-v3\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39d8cc-3d86-4e94-ba07-32004aaae54f",
   "metadata": {},
   "source": [
    "### Upload model via SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2734d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wallaroo.framework import CustomConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730a5fd6-2a75-4fb4-a1df-dd0cbf45a032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for model loading - this will take up to 10min.\n",
      ".odel is pending loading to a container runtime.\n",
      ".............................successfulner runtime.\n",
      "\n",
      "Ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>byop-vllm-tinyllama-ynsv5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>4b40ba86-8af1-4945-bde6-137245d5e618</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>byop_tinyllama_vllm_v4.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>5e244d5ab73cf718256d1d08b7c0553102215f69c3d70936b2d4b89043499a2e</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2025.1.0-main-6132</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>x86</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Acceleration</td>\n",
       "          <td>cuda</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2025-08-May 18:22:35</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Workspace id</td>\n",
       "          <td>60</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Workspace name</td>\n",
       "          <td>younes.amar@wallaroo.ai - Default Workspace</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'byop-vllm-tinyllama-ynsv5', 'version': '4b40ba86-8af1-4945-bde6-137245d5e618', 'file_name': 'byop_tinyllama_vllm_v4.zip', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2025.1.0-main-6132', 'arch': 'x86', 'accel': 'cuda', 'last_update_time': datetime.datetime(2025, 5, 8, 18, 22, 35, 480335, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = wl.upload_model(\n",
    "    \"byop-vllm-tinyllama-ynsv5\", \n",
    "    \"./byop_tinyllama_vllm_v4.zip\",\n",
    "    framework=Framework.CUSTOM,\n",
    "    framework_config=CustomConfig(\n",
    "        gpu_memory_utilization=0.9, \n",
    "        max_model_len=128\n",
    "    ),\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    "    accel=Acceleration.CUDA\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd4f16b-b40a-4d2f-bb83-806ff285aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define continous batching for Async vLLM (you can choose the number of connections you want)\n",
    "cbc = ContinuousBatchingConfig(max_concurrent_batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c427430d-58b5-4d26-b930-52a175fb2fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>byop-vllm-tinyllama-ynsv5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>4b40ba86-8af1-4945-bde6-137245d5e618</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>byop_tinyllama_vllm_v4.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>5e244d5ab73cf718256d1d08b7c0553102215f69c3d70936b2d4b89043499a2e</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2025.1.0-main-6132</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>x86</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Acceleration</td>\n",
       "          <td>cuda</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2025-08-May 18:22:35</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Workspace id</td>\n",
       "          <td>60</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Workspace name</td>\n",
       "          <td>younes.amar@wallaroo.ai - Default Workspace</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'byop-vllm-tinyllama-ynsv5', 'version': '4b40ba86-8af1-4945-bde6-137245d5e618', 'file_name': 'byop_tinyllama_vllm_v4.zip', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mac-deploy:v2025.1.0-main-6132', 'arch': 'x86', 'accel': 'cuda', 'last_update_time': datetime.datetime(2025, 5, 8, 18, 22, 35, 480335, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = model.configure(\n",
    "    input_schema = input_schema,\n",
    "    output_schema = output_schema,\n",
    "    continuous_batching_config = cbc\n",
    ")\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3496d0",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20972f6c-594c-4b3b-b136-bdf25f6e1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(1.).memory('1Gi') \\\n",
    "    .sidekick_cpus(batch, 1.) \\\n",
    "    .sidekick_memory(batch, '10Gi') \\\n",
    "    .sidekick_gpus(batch, 1) \\\n",
    "    .deployment_label(\"wallaroo.ai/accelerator:t4-shared\") \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be23d51-b4c7-45c1-8f03-f6034f4fb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = wl.build_pipeline(\"byop-tinyllama-cutom-vllm\")\n",
    "pipeline.undeploy()\n",
    "pipeline.clear()\n",
    "\n",
    "pipeline.add_model_step(batch)\n",
    "pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7caa327-22e9-4838-b582-0589430b6476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.4.7.8',\n",
       "   'name': 'engine-65bc55d64f-mdrnh',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'byop-tinyllama-cutom-vllm',\n",
       "      'status': 'Running',\n",
       "      'version': '95a07681-e434-4108-8e9c-01c052b7b5ec'}]},\n",
       "   'model_statuses': {'models': [{'model_version_id': 434,\n",
       "      'name': 'byop-vllm-tinyllama-ynsv5',\n",
       "      'sha': '5e244d5ab73cf718256d1d08b7c0553102215f69c3d70936b2d4b89043499a2e',\n",
       "      'status': 'Running',\n",
       "      'version': '4b40ba86-8af1-4945-bde6-137245d5e618'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.4.1.15',\n",
       "   'name': 'engine-lb-5cf49f9d5f-dkvsz',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': [{'ip': '10.4.7.9',\n",
       "   'name': 'engine-sidekick-byop-vllm-tinyllama-ynsv5-434-5cc6f466fc-zqzbk',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'statuses': '\\n'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3336d28",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8691aaee-2a24-4ec5-90b0-7f87b13163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"prompt\": [\"What is Wallaroo.AI?\"], \"max_tokens\": [200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b89b57d-d8a3-47b0-bc7f-e28a551b932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.max_tokens</th>\n",
       "      <th>in.prompt</th>\n",
       "      <th>out.generated_text</th>\n",
       "      <th>out.num_output_tokens</th>\n",
       "      <th>anomaly.count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-08 18:41:35.436</td>\n",
       "      <td>200</td>\n",
       "      <td>What is Wallaroo.AI?</td>\n",
       "      <td>\\n2.2 How does Wallaroo.AI's Asset Composition...</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  in.max_tokens             in.prompt  \\\n",
       "0 2025-05-08 18:41:35.436            200  What is Wallaroo.AI?   \n",
       "\n",
       "                                  out.generated_text  out.num_output_tokens  \\\n",
       "0  \\n2.2 How does Wallaroo.AI's Asset Composition...                    200   \n",
       "\n",
       "   anomaly.count  \n",
       "0              0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.infer(data, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c94a2a",
   "metadata": {},
   "source": [
    "## Undeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca5100af-0149-48a9-9501-6359f76988b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s ..................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>byop-tinyllama-demo-yns-cudafix</td></tr><tr><th>created</th> <td>2025-05-08 18:23:23.012161+00:00</td></tr><tr><th>last_updated</th> <td>2025-05-08 18:23:23.094326+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>workspace_id</th> <td>60</td></tr><tr><th>workspace_name</th> <td>younes.amar@wallaroo.ai - Default Workspace</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>cuda</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>2ae66497-d235-44b5-8be5-52a6b83cf945, 2c8d7c28-1702-4e6a-9805-c8f5b918ab36</td></tr><tr><th>steps</th> <td>byop-vllm-tinyllama-ynsv5</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'byop-tinyllama-demo-yns-cudafix', 'create_time': datetime.datetime(2025, 5, 8, 18, 23, 23, 12161, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'byop-vllm-tinyllama-ynsv5', 'version': '4b40ba86-8af1-4945-bde6-137245d5e618', 'sha': '5e244d5ab73cf718256d1d08b7c0553102215f69c3d70936b2d4b89043499a2e'}]}}]\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb33b0-396e-4a46-852d-89b802f1c510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
