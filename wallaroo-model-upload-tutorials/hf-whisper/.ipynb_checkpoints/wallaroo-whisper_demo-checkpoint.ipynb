{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e366a97-e938-408d-8d51-ede3cd2f6b59",
   "metadata": {},
   "source": [
    "This tutorial can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/main/wallaroo-model-cookbooks/hf-whisper).\n",
    "\n",
    "## Whisper Demo\n",
    "\n",
    "The following tutorial demonstrates deploying the [openai/whisper-large-v2](https://huggingface.co/openai/whisper-large-v2) on a `Wallaroo` pipeline and performing  inferences on it using the [BYOP](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-arbitrary-python/) feature.\n",
    "\n",
    "\n",
    "## Data Prepartions\n",
    "\n",
    "For this example, the following Python libraries were used:\n",
    "\n",
    "* [librosa](https://pypi.org/project/librosa/)\n",
    "* [datasets](https://pypi.org/project/datasets/)\n",
    "\n",
    "These can be installed with the following command:\n",
    "\n",
    "```python\n",
    "pip install librosa datasets --user\n",
    "```\n",
    "\n",
    "For these libraries, a sample of audio files was retrieved and converted using the following code.\n",
    "\n",
    "```python\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# load the sample dataset and retrieve the audio files\n",
    "dataset = load_dataset(\"Narsil/asr_dummy\")\n",
    "\n",
    "# the following is used to play them\n",
    "audio_1, sr_1 = librosa.load(dataset[\"test\"][0][\"file\"])\n",
    "audio_2, sr_2 = librosa.load(dataset[\"test\"][1][\"file\"])\n",
    "\n",
    "audio_files = [(audio_1, sr_1), (audio_2, sr_2)]\n",
    "\n",
    "# convert the audio files to numpy values in a DataFrame\n",
    "input_data = {\n",
    "        \"inputs\": [audio_1, audio_2],\n",
    "        \"return_timestamps\": [\"word\", \"word\"],\n",
    "}\n",
    "dataframe = pd.DataFrame(input_data)\n",
    "\n",
    "# the following will provide a UI to play the audio file samples\n",
    "\n",
    "def display_audio(audio: np.array, sr: int) -> None:\n",
    "    IPython.display.display(Audio(data=audio, rate=sr))\n",
    "\n",
    "for audio, sr in audio_files:\n",
    "    display_audio(audio, sr)\n",
    "```\n",
    "\n",
    "The resulting pandas DataFrame can either be submitted directly to a deployed Wallaroo pipeline using `wallaroo.pipeline.infer`, or the DataFrame exported to a pandas Record file in pandas JSON format, and used for an inference request using `wallaroo.pipeline.infer_from_file`.\n",
    "\n",
    "For this example, the audio files are pre-converted to a JSON pandas Record table file, and used for the inference result.  This removes the requirements to add additional Python libraries to a virtual environment or Wallaroo JupyterHub service.  The code above is provided as an example of converting the dataset audio into values for inference requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33e888-28a8-48cc-b418-2d95ad206d98",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries we'll be using.  These are included by default in the Wallaroo instance's JupyterHub service or are installed with the Wallaroo SDK.\n",
    "\n",
    "* References\n",
    "  * [Wallaroo SDK Guides](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8228fc-00ce-4770-a863-8985633605b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.pipeline   import Pipeline\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ignoring warnings for demonstration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f909f31-7ffe-4989-b726-316d472174e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.4.1+379cb6b8a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wallaroo.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635c007",
   "metadata": {},
   "source": [
    "## Open a Connection to Wallaroo\n",
    "\n",
    "The next step is connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  If logging in externally, update the `wallarooPrefix` and `wallarooSuffix` variables with the proper DNS information.  For more information on Wallaroo DNS settings, see the [Wallaroo DNS Integration Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-dns-guide/).\n",
    "\n",
    "For this tutorial, the `request_timeout` option is increased to allow the model conversion and pipeline deployment to proceed without any warning messages.\n",
    "\n",
    "* References\n",
    "  * [Wallaroo SDK Essentials Guide: Client Connection](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0857c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client(request_timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b7c4a",
   "metadata": {},
   "source": [
    "### Set Variables and Helper Functions\n",
    "\n",
    "We'll set the name of our workspace, pipeline, models and files.  Workspace names must be unique across the Wallaroo workspace.  For this, we'll add in a randomly generated 4 characters to the workspace name to prevent collisions with other users' workspaces.  If running this tutorial, we recommend hard coding the workspace name so it will function in the same workspace each time it's run.\n",
    "\n",
    "We'll set up some helper functions that will either use existing workspaces and pipelines, or create them if they do not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97af85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name, client):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4a671-4f3b-437c-a417-23b2dbf65708",
   "metadata": {},
   "source": [
    "The names for our workspace, pipeline, model, and model files are set here to make updating this tutorial easier.  \n",
    "\n",
    "* **IMPORTANT NOTE**:  Workspace names must be unique across the Wallaroo instance.  To verify unique names, the randomization code below is provided to allow the workspace name to be unique.  If this is not required, set `suffix` to `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d76610-d78b-4759-9df2-e8a86bcdb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "# make a random 4 character suffix to prevent overwriting other user's workspaces\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "\n",
    "suffix=''\n",
    "\n",
    "workspace_name = f'whisper-tiny-demo{suffix}'\n",
    "pipeline_name = 'whisper-hf-byop'\n",
    "model_name = 'whisper-byop'\n",
    "model_file_name = './models/model-auto-conversion_hugging-face_complex-pipelines_asr-whisper-tiny.zip'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca3c0f",
   "metadata": {},
   "source": [
    "### Create Workspace and Pipeline\n",
    "\n",
    "We will now create the Wallaroo workspace to store our model and set it as the current workspace.  Future commands will default to this workspace for pipeline creation, model uploads, etc.  We'll create our Wallaroo pipeline that is used to deploy our arbitrary Python model.\n",
    "\n",
    "* References\n",
    "  * [Wallaroo SDK Essentials Guide: Workspace Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-workspace/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c884ae67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'whisper-tiny-demo', 'id': 18, 'archived': False, 'created_by': '92b0e5e2-b5de-46af-baa6-0a86c702cfb4', 'created_at': '2024-02-15T21:17:25.358019+00:00', 'models': [], 'pipelines': [{'name': 'whisper-hf-byop', 'create_time': datetime.datetime(2024, 2, 15, 21, 17, 25, 387117, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name, wl)\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = wl.build_pipeline(pipeline_name)\n",
    "\n",
    "display(wl.get_current_workspace())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72de5f7-02ef-4b0b-a478-f6a21335270a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure & Upload Model\n",
    "\n",
    "For this example, we will use the `openai/whisper-tiny` model for the `automatic-speech-recognition` pipeline task from the official `🤗 Hugging Face` [hub](https://huggingface.co/openai/whisper-tiny/tree/main).\n",
    "\n",
    "To manually create an `automatic-speech-recognition` pipeline from the `🤗 Hugging Face` hub link above:\n",
    "\n",
    "1. Download the original model from the the official `🤗 Hugging Face` [hub](https://huggingface.co/openai/whisper-tiny/tree/main).\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-tiny\")\n",
    "pipe.save_pretrained(\"asr-whisper-tiny/\")\n",
    "```\n",
    "\n",
    "As a last step, you can `zip` the folder containing all needed files as follows:\n",
    "\n",
    "```bash\n",
    "zip -r asr-whisper-tiny.zip asr-whisper-tiny/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6a089-7c58-4525-8af9-69552637d3d7",
   "metadata": {},
   "source": [
    "### Configure PyArrow Schema\n",
    "\n",
    "You can find more info on the available inputs for the `automatic-speech-recognition` pipeline under the [official source code](https://github.com/huggingface/transformers/blob/main/src/transformers/pipelines/automatic_speech_recognition.py#L294) from `🤗 Hugging Face`.\n",
    "\n",
    "The input and output schemas are defined in Apache pyarrow Schema format.\n",
    "\n",
    "The model is then uploaded with the `wallaroo.client.model_upload` method, where we define:\n",
    "\n",
    "* The name to assign the model.\n",
    "* The model file path.\n",
    "* The input and output schemas.\n",
    "\n",
    "The model is uploaded to the Wallaroo instance, where it is containerized to run with the Wallaroo Inference Engine.\n",
    "\n",
    "* References\n",
    "  * [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Arbitrary Python](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-arbitrary-python/)\n",
    "  * [Wallaroo SDK Essentials Guide: Model Uploads and Registrations: Hugging Face](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-hugging-face/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef115ab9-9c73-4c28-aad8-e915a92a746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('inputs', pa.list_(pa.float32())), # required: the audio stored in numpy arrays of shape (num_samples,) and data type `float32`\n",
    "    pa.field('return_timestamps', pa.string()) # optional: return start & end times for each predicted chunk\n",
    "]) \n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('text', pa.string()), # required: the output text corresponding to the audio input\n",
    "    pa.field('chunks', pa.list_(pa.struct([('text', pa.string()), ('timestamp', pa.list_(pa.float32()))]))), # required (if `return_timestamps` is set), start & end times for each predicted chunk\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953e0857-45ec-4603-b0be-3bba13df5db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for model loading - this will take up to 10.0min.\n",
      "Model is pending loading to a container runtime..\n",
      "Model is attempting loading to a container runtime......................................................successful\n",
      "\n",
      "Ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "          <td>Name</td>\n",
       "          <td>whisper-byop</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Version</td>\n",
       "          <td>27d873e7-8b7b-4384-9086-e5420adc71c9</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>File Name</td>\n",
       "          <td>model-auto-conversion_hugging-face_complex-pipelines_asr-whisper-tiny.zip</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>SHA</td>\n",
       "          <td>ddd57c9c8d3ed5417783ebb7101421aa1e79429365d20326155c9c02ae1e8a13</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Status</td>\n",
       "          <td>ready</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Image Path</td>\n",
       "          <td>proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mlflow-deploy:v2023.4.1-4514</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Architecture</td>\n",
       "          <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "          <td>Updated At</td>\n",
       "          <td>2024-15-Feb 21:22:09</td>\n",
       "        </tr>\n",
       "      </table>"
      ],
      "text/plain": [
       "{'name': 'whisper-byop', 'version': '27d873e7-8b7b-4384-9086-e5420adc71c9', 'file_name': 'model-auto-conversion_hugging-face_complex-pipelines_asr-whisper-tiny.zip', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mlflow-deploy:v2023.4.1-4514', 'arch': None, 'last_update_time': datetime.datetime(2024, 2, 15, 21, 22, 9, 2806, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = wl.upload_model(model_name, \n",
    "                        model_file_name, \n",
    "                        framework=Framework.HUGGING_FACE_AUTOMATIC_SPEECH_RECOGNITION, \n",
    "                        input_schema=input_schema, \n",
    "                        output_schema=output_schema)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb0930-8246-4731-84f9-eb1e0e1d9091",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "The model is deployed with the `wallaroo.pipeline.deploy(deployment_config)` command.  For the deployment configuration, we set the containerized aka `sidekick` memory to 8 GB to accommodate the size of the model, and CPUs to at least 4.  To optimize performance, a GPU could be assigned to the containerized model.\n",
    "\n",
    "* References\n",
    "  * [Wallaroo SDK Essentials Guide: Pipeline Deployment Configuration](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/)\n",
    "  * [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "  * [GPU Support](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/#gpu-support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ac85a4-1978-4fb9-91c4-a4d728ed04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(0.25).memory('1Gi') \\\n",
    "    .sidekick_memory(model, '8Gi') \\\n",
    "    .sidekick_cpus(model, 4.0) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea455f46-6f8b-4d5f-a195-74634c0c886b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 600s ................................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>whisper-hf-byop</td></tr><tr><th>created</th> <td>2024-02-15 21:17:25.387117+00:00</td></tr><tr><th>last_updated</th> <td>2024-02-15 21:22:12.830028+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>arch</th> <td>None</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>5fee2462-479a-468d-a63d-08f146683452, 6e92d9f3-39cc-45e2-90ef-5c133ea3b68f, f9a5cf6d-1a37-4234-af50-edf62f1eff3d</td></tr><tr><th>steps</th> <td>whisper-byop</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'whisper-hf-byop', 'create_time': datetime.datetime(2024, 2, 15, 21, 17, 25, 387117, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'whisper-byop', 'version': '27d873e7-8b7b-4384-9086-e5420adc71c9', 'sha': 'ddd57c9c8d3ed5417783ebb7101421aa1e79429365d20326155c9c02ae1e8a13'}]}}]\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = wl.build_pipeline(pipeline_name)\n",
    "pipeline.add_model_step(model)\n",
    "\n",
    "pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06caf340-d8fe-4d0e-aacd-9be1cba3abcc",
   "metadata": {},
   "source": [
    "After a couple of minutes we verify the pipeline deployment was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd4abca-2341-4c61-bc83-5dab6cc4e62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.100.1.167',\n",
       "   'name': 'engine-f9dbd4b98-lrbvc',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'whisper-hf-byop',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'whisper-byop',\n",
       "      'version': '27d873e7-8b7b-4384-9086-e5420adc71c9',\n",
       "      'sha': 'ddd57c9c8d3ed5417783ebb7101421aa1e79429365d20326155c9c02ae1e8a13',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.100.0.65',\n",
       "   'name': 'engine-lb-dcd9c8cd7-4b5hb',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': [{'ip': '10.100.2.230',\n",
       "   'name': 'engine-sidekick-whisper-byop-20-5d8f76d88b-j2wrq',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'statuses': '\\n'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ef440-b1dc-4879-9f0c-ff52d582cdd9",
   "metadata": {},
   "source": [
    "### Run inference on the example dataset\n",
    "\n",
    "We perform a sample inference with the provided DataFrame, and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa078ffd-859e-4706-8729-9e7d78f8bf60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 70.7 ms, total: 224 ms\n",
      "Wall time: 3.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = pipeline.infer_from_file('./data/sound-examples.df.json', timeout=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b608a2-fbb3-4659-bf0c-88ba8b11e110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.inputs</th>\n",
       "      <th>in.return_timestamps</th>\n",
       "      <th>out.chunks</th>\n",
       "      <th>out.text</th>\n",
       "      <th>anomaly.count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-15 21:23:08.411</td>\n",
       "      <td>[0.0003229662, 0.0003370901, 0.0002854846, 0.0...</td>\n",
       "      <td>word</td>\n",
       "      <td>[{'text': ' He', 'timestamp': [0.0, 1.08]}, {'...</td>\n",
       "      <td>He hoped there would be Stu for dinner, turni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-15 21:23:08.411</td>\n",
       "      <td>[0.0010076478, 0.0012469155, 0.0008045971, 0.0...</td>\n",
       "      <td>word</td>\n",
       "      <td>[{'text': ' Stuff', 'timestamp': [29.78, 29.78...</td>\n",
       "      <td>Stuff it into you. His belly calcled him.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time                                          in.inputs  \\\n",
       "0 2024-02-15 21:23:08.411  [0.0003229662, 0.0003370901, 0.0002854846, 0.0...   \n",
       "1 2024-02-15 21:23:08.411  [0.0010076478, 0.0012469155, 0.0008045971, 0.0...   \n",
       "\n",
       "  in.return_timestamps                                         out.chunks  \\\n",
       "0                 word  [{'text': ' He', 'timestamp': [0.0, 1.08]}, {'...   \n",
       "1                 word  [{'text': ' Stuff', 'timestamp': [29.78, 29.78...   \n",
       "\n",
       "                                            out.text  anomaly.count  \n",
       "0   He hoped there would be Stu for dinner, turni...              0  \n",
       "1          Stuff it into you. His belly calcled him.              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7d300-3c55-4d2b-b2b7-57564fc8fe86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c35da-ec93-49e1-941b-9853f1c87932",
   "metadata": {},
   "source": [
    "Let's compare the results side by side with the audio inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e3708b2-01c0-4468-adc3-cf2827b06576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  He hoped there would be Stu for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered, flour-fat and sauce.\n",
      "\n",
      "Transcription:  Stuff it into you. His belly calcled him.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for transcription in result['out.text'].values:\n",
    "    print(f\"Transcription: {transcription}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10efccd7-fd4a-4628-907c-e5d84397ea1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Undeploy Pipelines\n",
    "\n",
    "With the demonstration complete, we undeploy the pipelines to return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d053bc-b225-45e0-8e84-f45c30122f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 600s .................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>whisper-hf-byop</td></tr><tr><th>created</th> <td>2024-02-15 21:17:25.387117+00:00</td></tr><tr><th>last_updated</th> <td>2024-02-15 21:22:12.830028+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>arch</th> <td>None</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>5fee2462-479a-468d-a63d-08f146683452, 6e92d9f3-39cc-45e2-90ef-5c133ea3b68f, f9a5cf6d-1a37-4234-af50-edf62f1eff3d</td></tr><tr><th>steps</th> <td>whisper-byop</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'whisper-hf-byop', 'create_time': datetime.datetime(2024, 2, 15, 21, 17, 25, 387117, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'whisper-byop', 'version': '27d873e7-8b7b-4384-9086-e5420adc71c9', 'sha': 'ddd57c9c8d3ed5417783ebb7101421aa1e79429365d20326155c9c02ae1e8a13'}]}}]\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
