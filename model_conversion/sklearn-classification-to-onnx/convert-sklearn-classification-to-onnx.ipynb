{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository]https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_conversion/sklearn-classification-to-onnx).\n",
    "\n",
    "## sk-learn Logistic Model to ONNX Outside Wallaroo\n",
    "\n",
    "The following tutorial is a brief example of how to convert a [scikit-learn](https://scikit-learn.org/stable/) (aka sk-learn) **Classification ML model** to the [ONNX](https://onnx.ai/ ) format for use with Wallaroo.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides the following:\n",
    "\n",
    "* `isolet_logistic_model_numclass.pickle`: a logistic trained sk-learn model.\n",
    "    This model contains 617 columns.\n",
    "* `isolet_test_data.tsv`:  A test file that can be used to verify the output of the converted logistic model.\n",
    "* `test-converted-sklearn-logistics-to-onnx.ipynb`: This Jupyter Notebook demonstrates the use of the converted sk-learn logistic ML model in ONNX with Wallaroo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Process\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The first step is to import our libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to load the sk-learn model\n",
    "import pickle\n",
    "\n",
    "# Used for the conversion process\n",
    "import onnx, skl2onnx, onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.data_types import DoubleTensorType\n",
    "from skl2onnx import convert_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can determine the correct ONNX Target Opset for our libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out the correct opset\n",
    "\n",
    "from onnx.defs import onnx_opset_version\n",
    "from onnxconverter_common.onnx_ex import DEFAULT_OPSET_NUMBER\n",
    "TARGET_OPSET = min(DEFAULT_OPSET_NUMBER, onnx_opset_version())\n",
    "TARGET_OPSET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `TARGET_OPSET` determined, we can convert our sklearn logistic model to onnx.\n",
    "\n",
    "* **IMPORTANT NOTE**:  Note that for the conversion process, `zipmap` is **disabled**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model that we will be converting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# convert model to ONNX\n",
    "\n",
    "# load the model\n",
    "\n",
    "with open(\"./isolet_logistic_model_numclass.pickle\", \"rb\") as f:\n",
    "    logistic_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know the number of columns, so we'll set that variable in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of columns\n",
    "\n",
    "ncols = 617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is to set the options.  As a reminder **zipmap must be disabled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the options\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, ncols]))]\n",
    "options = {id(logistic_model): {'zipmap': False}} # here we turn off the zipmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything ready, we can now convert the sk-learn Logistics model to ONNX, and store it in the variable `onnx_model_converted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the conversion\n",
    "\n",
    "onnx_model_converted = convert_sklearn(logistic_model, initial_types=initial_type, options=options,\n",
    "                       target_opset=TARGET_OPSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save our model to a `onnx` file.  Once complete, we can run it through the `Logistic Version of the Isolet Model Test in Wallaroo` available at the [Wallaroo Tutorials repository]https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_conversion/sklearn-classification-to-onnx) to verify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to a file\n",
    "onnx.save_model(onnx_model_converted, \"isolet_logistic_model_numclass.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e951b583e3fbbcadfc15df61f9ed97fb9a76f59b2130f2cdf4d0033aa05e7e64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
