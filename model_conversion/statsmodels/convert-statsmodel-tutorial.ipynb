{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_conversion/statsmodels).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Organizations can deploy a Machine Learning (ML) model based on the [statsmodels](https://www.statsmodels.org/stable/index.html) directly into Wallaroo through the following process.  This conversion process transforms the model into an open format that can be run across different frameworks at compiled C-language speeds.\n",
    "\n",
    "This example provides the following:\n",
    "\n",
    "* `train-statsmodel.ipynb`: A sample Jupyter Notebook that trains a sample model.  The model predicts how many bikes will be rented on each of the next 7 days, based on the previous 7 days' bike rentals, temperature, and wind speed.  Additional files to support this example are:\n",
    "  * `day.csv`: Data used to train the sample `statsmodel` example.\n",
    "  * `infer.py`: The inference script that is part of the `statsmodel`.\n",
    "* `convert-statsmodel-tutorial.ipynb`: A sample Jupyter Notebook that demonstrates how to upload, convert, and deploy the `statsmodel` example into a Wallaroo instance.    Additional files to support this example are:\n",
    "  * `bike_day_model.pkl`: A `statsmodel` ML model trained from the `train-statsmodel.ipynb` Notebook.\n",
    "\n",
    "    **IMPORTANT NOTE:** The `statsmodel` ML model is composed of two parts that are contained in the .pkl file:\n",
    "\n",
    "    * The pickled Python runtime expects a dictionary with two keys: `model` and `script`:\n",
    "\n",
    "      * `model`—the pickled model, which will be automatically loaded into the python runtime with the name 'model'\n",
    "      * `script`—the text of the python script to be run, in a format similar to the existing python script steps (i.e. defining a wallaroo_json method which operates on the data).  In this case, the file `infer.py` is the script used.\n",
    "\n",
    "  * `bike_day_eval.json`: Evaluation data used to test the model's performance.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before uploading and running an inference with a MLFlow model in Wallaroo the following will be required:\n",
    "\n",
    "* An installed Wallaroo instance.\n",
    "* The following Python libraries installed:\n",
    "  * `os`\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "The following steps will perform the following:\n",
    "    \n",
    "1. Upload the `statsmodel` ML model `bike_day_model.pkl` into a Wallaroo.\n",
    "2. Deploy the model into a pipeline.\n",
    "3. Run a test inference.\n",
    "4. Undeploy the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "import os\n",
    "# Only set the below to make the OS environment ARROW_ENABLED to TRUE.  Otherwise, leave as is.\n",
    "os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize connection\n",
    "\n",
    "Start a connect to the Wallaroo instance and save the connection into the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the login credentials.\n",
    "os.environ[\"WALLAROO_SDK_CREDENTIALS\"] = './creds.json.example'\n",
    "\n",
    "# Client connection from local Wallaroo instance\n",
    "\n",
    "# wl = wallaroo.Client(auth_type=\"user_password\")\n",
    "\n",
    "# Login from external connection\n",
    "\n",
    "wallarooPrefix = \"YOUR PREFIX\"\n",
    "wallarooSuffix = \"YOUR SUFFIX\"\n",
    "\n",
    "wallarooPrefix = \"docreleasetest\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "# wallarooPrefix = \"sparkly-apple-3026\"\n",
    "# wallarooSuffix = \"wallaroo.community\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations\n",
    "\n",
    "The following will set the workspace, model name, and pipeline that will be used for this example.  If the workspace or pipeline already exist, then they will assigned for use in this example.  If they do not exist, they will be created based on the names listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'bikedayevalworkspace2'\n",
    "pipeline_name = 'bikedayevalpipeline2'\n",
    "model_name = 'bikedaymodel2'\n",
    "model_file_name = 'bike_day_model.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Workspace and Pipeline\n",
    "\n",
    "This sample code will create or use the existing workspace `bike-day-workspace` as the current workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bikedayevalpipeline2</td></tr><tr><th>created</th> <td>2023-05-02 17:15:11.572818+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-02 17:15:11.572818+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>001c0345-b472-472c-8b47-6c60e42074ae</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bikedayevalpipeline2', 'create_time': datetime.datetime(2023, 5, 2, 17, 15, 11, 572818, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Pickled Package Statsmodel Model\n",
    "\n",
    "Upload the statsmodel stored into the pickled package `bike_day_model.pkl`.  See the Notebook `train-statsmodel.ipynb` for more details on creating this package.\n",
    "\n",
    "Note that this package is being specified as a `python` configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_day_model = wl.upload_model(model_name, model_file_name).configure(runtime=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "We will now add the uploaded model as a step for the pipeline, then deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bikedayevalpipeline2</td></tr><tr><th>created</th> <td>2023-05-02 17:15:11.572818+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-02 17:15:11.572818+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>001c0345-b472-472c-8b47-6c60e42074ae</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bikedayevalpipeline2', 'create_time': datetime.datetime(2023, 5, 2, 17, 15, 11, 572818, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bikedaymodel2', 'version': 'cc8025c0-1146-49b7-9f83-c523a932108a', 'sha': '978f2274c384f4050f2ece7c96a5f9bb5d6f96b387c0c5cbea5d4f36e2fbf18e'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_model_step(bike_day_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bikedayevalpipeline2</td></tr><tr><th>created</th> <td>2023-05-02 17:15:11.572818+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-02 17:15:14.711340+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>4f663898-2a5b-41bb-902e-7891c2f1489c, 001c0345-b472-472c-8b47-6c60e42074ae</td></tr><tr><th>steps</th> <td>bikedaymodel2</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bikedayevalpipeline2', 'create_time': datetime.datetime(2023, 5, 2, 17, 15, 11, 572818, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bikedaymodel2', 'version': 'cc8025c0-1146-49b7-9f83-c523a932108a', 'sha': '978f2274c384f4050f2ece7c96a5f9bb5d6f96b387c0c5cbea5d4f36e2fbf18e'}]}}]\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.0.23',\n",
       "   'name': 'engine-6db45f45b9-4jxqm',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'bikedayevalpipeline2',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'bikedaymodel2',\n",
       "      'version': 'cc8025c0-1146-49b7-9f83-c523a932108a',\n",
       "      'sha': '978f2274c384f4050f2ece7c96a5f9bb5d6f96b387c0c5cbea5d4f36e2fbf18e',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.4.26',\n",
       "   'name': 'engine-lb-584f54c899-7jv8c',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "\n",
    "Perform an inference from the evaluation data JSON file `bike_day_eval.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceError",
     "evalue": "Inference failed: \n\tInternalError: Error running inference <class 'AttributeError'>, 'str' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_make_infer_request\u001b[0;34m(self, data, headers, params, timeout)\u001b[0m\n\u001b[1;32m    599\u001b[0m             )\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://docreleasetest.api.wallaroocommunity.ninja/v1/api/pipelines/infer/bikedayevalpipeline2-27/bikedayevalpipeline2?dataset%5B%5D=%2A&dataset.exclude%5B%5D=metadata&dataset.separator=.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInferenceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/_cj0q9d51s365wksymljdz4h0000gn/T/ipykernel_63499/3985195530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bike_day_eval.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupdate_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             self._last_infer_time = max(\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/pipeline.py\u001b[0m in \u001b[0;36minfer_from_file\u001b[0;34m(self, filename, data_format, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mdeployment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deployment_for_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             return deployment.infer_from_file(\n\u001b[0m\u001b[1;32m    633\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36minfer_from_file\u001b[0;34m(self, filename, data_format, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_exclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_separator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chunk_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensor, timeout, dataset, dataset_exclude, dataset_separator)\u001b[0m\n\u001b[1;32m    658\u001b[0m                 )\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_with_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_with_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_infer_with_pandas\u001b[0;34m(self, tensor, params, timeout)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPANDAS_RECORDS_HEADER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         }\n\u001b[0;32m--> 502\u001b[0;31m         res = self._make_infer_request(\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_records\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/wallaroosdk202302preview/lib/python3.9/site-packages/wallaroo/deployment.py\u001b[0m in \u001b[0;36m_make_infer_request\u001b[0;34m(self, data, headers, params, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInferenceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         except (\n\u001b[1;32m    604\u001b[0m             \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInferenceError\u001b[0m: Inference failed: \n\tInternalError: Error running inference <class 'AttributeError'>, 'str' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "# inferData = pd.read_json('./bike_day_eval.df.json', orient=\"records\")\n",
    "\n",
    "# results = pipeline.infer(inferData)\n",
    "\n",
    "\n",
    "results = pipeline.infer_from_file('bike_day_eval.json')\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "Undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>bikedayevalpipeline2</td></tr><tr><th>created</th> <td>2023-05-02 17:15:11.572818+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-02 17:15:14.711340+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>4f663898-2a5b-41bb-902e-7891c2f1489c, 001c0345-b472-472c-8b47-6c60e42074ae</td></tr><tr><th>steps</th> <td>bikedaymodel2</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'bikedayevalpipeline2', 'create_time': datetime.datetime(2023, 5, 2, 17, 15, 11, 572818, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'bikedaymodel2', 'version': 'cc8025c0-1146-49b7-9f83-c523a932108a', 'sha': '978f2274c384f4050f2ece7c96a5f9bb5d6f96b387c0c5cbea5d4f36e2fbf18e'}]}}]\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
