{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_conversion/xgboost-autoconversion).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The following tutorial is a brief example of how to convert a [XGBoost](https://xgboost.readthedocs.io/en/stable/index.html) Classification ML model with the `convert_model` method and upload it into your Wallaroo instance.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service.\n",
    "\n",
    "* Convert a `XGBoost` Classification ML model and upload it into the Wallaroo engine.\n",
    "* Run a sample inference on the converted model in a Wallaroo instance.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* `xgb_class.pickle`: A pretrained `XGBoost` Classification model with 25 columns.\n",
    "* `xgb_class_eval.json`: Test data to perform a sample inference.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Wallaroo supports the following model versions:\n",
    "\n",
    "* XGBoost:  Version 1.6.0\n",
    "* SKLearn: 1.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Steps\n",
    "\n",
    "To use the Wallaroo autoconverter `convert_model(path, source_type, conversion_arguments)` method takes 3 parameters.  The parameters for `XGBoost` conversions are:\n",
    "\n",
    "* `path` (STRING):  The path to the ML model file.\n",
    "* `source_type` (ModelConversionSource): The type of ML model to be converted.  As of this time Wallaroo auto-conversion supports the following source types and their associated `ModelConversionSource`:\n",
    "  * **sklearn**: `ModelConversionSource.SKLEARN`\n",
    "  * **xgboost**: `ModelConversionSource.XGBOOST`\n",
    "  * **keras**: `ModelConversionSource.KERAS`\n",
    "* `conversion_arguments`:  The arguments for the conversion based on the type of model being converted.  These are:\n",
    "    * `wallaroo.ModelConversion.ConvertXGBoostArgs`: Used for `XGBoost` models and takes the following parameters:\n",
    "    * `name`: The name of the model being converted.\n",
    "    * `comment`: Any comments for the model.\n",
    "    * `number_of_columns`: The number of columns the model was trained for.\n",
    "    * `input_type`: A [tensorflow Dtype](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) called in the format `ModelConversionInputType.{type}`, where `{type}` is `Float`, `Double`, etc depending on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "\n",
    "from wallaroo.ModelConversion import ConvertXGBoostArgs, ModelConversionSource, ModelConversionInputType\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "import os\n",
    "# For Wallaroo SDK 2023.1\n",
    "os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Connect to your Wallaroo instance and store the connection into the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "# SSO login through keycloak\n",
    "\n",
    "# wallarooPrefix = \"YOUR PREFIX\"\n",
    "# wallarooSuffix = \"YOUR PREFIX\"\n",
    "\n",
    "# wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "#                     auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "#                     auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and Methods\n",
    "\n",
    "The following will set the workspace, pipeline, model name, the model file name used when uploading and converting the `keras` model, and the sample data.\n",
    "\n",
    "The functions `get_workspace(name)` will either set the current workspace to the requested name, or create it if it does not exist.  The function `get_pipeline(name)` will either set the pipeline used to the name requested, or create it in the current workspace if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'xgboost-classification-autoconvert-workspace'\n",
    "pipeline_name = 'xgboost-classification-autoconvert-pipeline'\n",
    "model_name = 'xgb-class-model'\n",
    "model_file_name = 'xgb_class.pickle'\n",
    "\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "Set or create the workspace and pipeline based on the names configured earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>xgboost-classification-autoconvert-pipeline</td></tr><tr><th>created</th> <td>2023-02-22 17:28:53.153447+00:00</td></tr><tr><th>last_updated</th> <td>2023-02-27 20:53:34.397083+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>6017f564-ab0d-4a67-afde-facf2eb601b3, 9020e9aa-ce33-4dcb-a222-6c732d6aeb83, e97e4287-b077-4405-879c-82af763b7b18, 94d9c2f9-45b6-489e-9ceb-912791873086, 84a06ef1-6959-47b3-bacb-3af325d4612e, d57f666c-c958-4eec-a46e-b7e28b145614, 5314a152-8120-4f32-9663-6b01601864e2</td></tr><tr><th>steps</th> <td>xgb-class-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'xgboost-classification-autoconvert-pipeline', 'create_time': datetime.datetime(2023, 2, 22, 17, 28, 53, 153447, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Model Autoconvert Parameters\n",
    "\n",
    "Set the paramters for converting the `xgb-class-model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of columns\n",
    "NF = 25\n",
    "\n",
    "model_conversion_args = ConvertXGBoostArgs(\n",
    "    name=model_name,\n",
    "    comment=\"xgboost classification model test\",\n",
    "    number_of_columns=NF,\n",
    "    input_type=ModelConversionInputType.Float32\n",
    ")\n",
    "model_conversion_type = ModelConversionSource.XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and Convert the Model\n",
    "\n",
    "Now we can upload the convert the model.  Once finished, it will be stored as `{unique-file-id}-converted.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelConversionGenericException",
     "evalue": "This model type could not be deployed successfully. Please contact your Wallaroo support team at community@wallaroo.ai",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/arrowtests/lib/python3.8/site-packages/wallaroo/client.py\u001b[0m in \u001b[0;36mconvert_model\u001b[0;34m(self, path, source_type, conversion_arguments)\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 )\n\u001b[0;32m-> 1627\u001b[0;31m                 \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/arrowtests/lib/python3.8/site-packages/wallaroo/client.py\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(http_response)\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_response\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m             \u001b[0mhttp_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m             \u001b[0mresponse_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/arrowtests/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://wallaroo.api.example.com/v1/convert/xgboost?name=xgb-class-model&number_of_columns=25&input_type=float32&comment=xgboost+classification+model+test&workspace_id=63",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModelConversionGenericException\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/_cj0q9d51s365wksymljdz4h0000gn/T/ipykernel_10455/2322016990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert and upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_wl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_conversion_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_conversion_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/arrowtests/lib/python3.8/site-packages/wallaroo/client.py\u001b[0m in \u001b[0;36mconvert_model\u001b[0;34m(self, path, source_type, conversion_arguments)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             raise ModelConversionGenericException(\n\u001b[0m\u001b[1;32m   1637\u001b[0m                 \u001b[0;34m\"This model type could not be deployed successfully. Please contact your Wallaroo support team at community@wallaroo.ai\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m             )\n",
      "\u001b[0;31mModelConversionGenericException\u001b[0m: This model type could not be deployed successfully. Please contact your Wallaroo support team at community@wallaroo.ai"
     ]
    }
   ],
   "source": [
    "# convert and upload\n",
    "model_wl = wl.convert_model(model_file_name, model_conversion_type, model_conversion_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference\n",
    "\n",
    "With the model uploaded and converted, we can run a sample inference.\n",
    "\n",
    "### Deploy the Pipeline\n",
    "\n",
    "Add the uploaded and converted `model_wl` as a step in the pipeline, then deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_model_step(model_wl).deploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Inference\n",
    "\n",
    "Use the evaluation data to verify the process completed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = 'xgb_class_eval.df.json'\n",
    "result = pipeline.infer_from_file(sample_data)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "With the tests complete, we will undeploy the pipeline to return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrowtests",
   "language": "python",
   "name": "arrowtests"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
