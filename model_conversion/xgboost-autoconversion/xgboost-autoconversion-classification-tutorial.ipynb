{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/releases).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The following tutorial is a brief example of how to convert a [XGBoost](https://xgboost.readthedocs.io/en/stable/index.html) Classification ML model with the `convert_model` method and upload it into your Wallaroo instance.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service.\n",
    "\n",
    "* Convert a `XGBoost` Classification ML model and upload it into the Wallaroo engine.\n",
    "* Run a sample inference on the converted model in a Wallaroo instance.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* `xgb_class.pickle`: A pretrained `XGBoost` Classification model with 25 columns.\n",
    "* `xgb_class_eval.json`: Test data to perform a sample inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Steps\n",
    "\n",
    "## Conversion Steps\n",
    "\n",
    "To use the Wallaroo autoconverter `convert_model(path, source_type, conversion_arguments)` method takes 3 parameters.  The parameters for `XGBoost` conversions are:\n",
    "\n",
    "* `path` (STRING):  The path to the ML model file.\n",
    "* `source_type` (ModelConversionSource): The type of ML model to be converted.  As of this time Wallaroo auto-conversion supports the following source types and their associated `ModelConversionSource`:\n",
    "  * **sklearn**: `ModelConversionSource.SKLEARN`\n",
    "  * **xgboost**: `ModelConversionSource.XGBOOST`\n",
    "  * **keras**: `ModelConversionSource.KERAS`\n",
    "* `conversion_arguments`:  The arguments for the conversion based on the type of model being converted.  These are:\n",
    "    * `wallaroo.ModelConversion.ConvertXGBoostArgs`: Used for `XGBoost` models and takes the following parameters:\n",
    "    * `name`: The name of the model being converted.\n",
    "    * `comment`: Any comments for the model.\n",
    "    * `number_of_columns`: The number of columns the model was trained for.\n",
    "    * `input_type`: A [tensorflow Dtype](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) called in the format `ModelConversionInputType.{type}`, where `{type}` is `Float`, `Double`, etc depending on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "\n",
    "from wallaroo.ModelConversion import ConvertXGBoostArgs, ModelConversionSource, ModelConversionInputType\n",
    "from wallaroo.object import EntityNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and Methods\n",
    "\n",
    "The following will set the workspace, pipeline, model name, the model file name used when uploading and converting the `keras` model, and the sample data.\n",
    "\n",
    "The functions `get_workspace(name)` will either set the current workspace to the requested name, or create it if it does not exist.  The function `get_pipeline(name)` will either set the pipeline used to the name requested, or create it in the current workspace if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'xgboost-classification-autoconvert-workspace'\n",
    "pipeline_name = 'xgboost-classification-autoconvert-pipeline'\n",
    "model_name = 'xgb-class-model'\n",
    "model_file_name = 'xgb_class.pickle'\n",
    "sample_data = 'xgb_class_eval.json'\n",
    "\n",
    "\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Connect to your Wallaroo instance and store the connection into the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "Set or create the workspace and pipeline based on the names configured earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>xgboost-classification-autoconvert-pipeline</td></tr><tr><th>created</th> <td>2022-08-03 15:35:20.889178+00:00</td></tr><tr><th>last_updated</th> <td>2022-08-03 15:35:20.889178+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'xgboost-classification-autoconvert-pipeline', 'create_time': datetime.datetime(2022, 8, 3, 15, 35, 20, 889178, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Model Autoconvert Parameters\n",
    "\n",
    "Set the paramters for converting the `xgb-class-model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of columns\n",
    "NF = 25\n",
    "\n",
    "model_conversion_args = ConvertXGBoostArgs(\n",
    "    name=model_name,\n",
    "    comment=\"xgboost classification model test\",\n",
    "    number_of_columns=NF,\n",
    "    input_type=ModelConversionInputType.Float32\n",
    ")\n",
    "model_conversion_type = ModelConversionSource.XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and Convert the Model\n",
    "\n",
    "Now we can upload the convert the model.  Once finished, it will be stored as `{unique-file-id}-converted.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and upload\n",
    "model_wl = wl.convert_model(model_file_name, model_conversion_type, model_conversion_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference\n",
    "\n",
    "With the model uploaded and converted, we can run a sample inference.\n",
    "\n",
    "### Deploy the Pipeline\n",
    "\n",
    "Add the uploaded and converted `model_wl` as a step in the pipeline, then deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s .... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>xgboost-classification-autoconvert-pipeline</td></tr><tr><th>created</th> <td>2022-08-03 15:35:20.889178+00:00</td></tr><tr><th>last_updated</th> <td>2022-08-03 15:35:23.597027+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>xgb-class-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'xgboost-classification-autoconvert-pipeline', 'create_time': datetime.datetime(2022, 8, 3, 15, 35, 20, 889178, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'xgb-class-model', 'version': 'e3b2d4cb-5c30-4fcb-a2f4-a468c9324ecb', 'sha': 'd68c71dab776a875ee4225eb49099ff7eded485d83ac774f0d3cd322610fccbf'}]}}]\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_model_step(model_wl).deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Inference\n",
    "\n",
    "Use the `test_class_eval.json` as set earlier as our `sample_data` and perform the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for inference response - this will take up to 45s ....... ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.e+000, 0.e+000, 5.e-324, 0.e+000, 5.e-324]),\n",
       " array([[0.99668795, 0.00331205],\n",
       "        [0.52999395, 0.47000605],\n",
       "        [0.14704436, 0.85295564],\n",
       "        [0.995507  , 0.004493  ],\n",
       "        [0.19796491, 0.80203509]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline.infer_from_file(sample_data)\n",
    "result[0].data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "With the tests complete, we will undeploy the pipeline to return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s .............................. ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>xgboost-classification-autoconvert-pipeline</td></tr><tr><th>created</th> <td>2022-08-03 15:35:20.889178+00:00</td></tr><tr><th>last_updated</th> <td>2022-08-03 15:35:23.597027+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>xgb-class-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'xgboost-classification-autoconvert-pipeline', 'create_time': datetime.datetime(2022, 8, 3, 15, 35, 20, 889178, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'xgb-class-model', 'version': 'e3b2d4cb-5c30-4fcb-a2f4-a468c9324ecb', 'sha': 'd68c71dab776a875ee4225eb49099ff7eded485d83ac774f0d3cd322610fccbf'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
