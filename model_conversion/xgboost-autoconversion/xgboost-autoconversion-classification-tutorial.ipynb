{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_conversion/xgboost-autoconversion).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The following tutorial is a brief example of how to convert a [XGBoost](https://xgboost.readthedocs.io/en/stable/index.html) Classification ML model with the `convert_model` method and upload it into your Wallaroo instance.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service.\n",
    "\n",
    "* Convert a `XGBoost` Classification ML model and upload it into the Wallaroo engine.\n",
    "* Run a sample inference on the converted model in a Wallaroo instance.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* `xgb_class.pickle`: A pretrained `XGBoost` Classification model with 25 columns.\n",
    "* `xgb_class_eval.json`: Test data to perform a sample inference.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Wallaroo supports the following model versions:\n",
    "\n",
    "* XGBoost:  Version 1.6.0\n",
    "* SKLearn: 1.1.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Steps\n",
    "\n",
    "To use the Wallaroo autoconverter `convert_model(path, source_type, conversion_arguments)` method takes 3 parameters.  The parameters for `XGBoost` conversions are:\n",
    "\n",
    "* `path` (STRING):  The path to the ML model file.\n",
    "* `source_type` (ModelConversionSource): The type of ML model to be converted.  As of this time Wallaroo auto-conversion supports the following source types and their associated `ModelConversionSource`:\n",
    "  * **sklearn**: `ModelConversionSource.SKLEARN`\n",
    "  * **xgboost**: `ModelConversionSource.XGBOOST`\n",
    "  * **keras**: `ModelConversionSource.KERAS`\n",
    "* `conversion_arguments`:  The arguments for the conversion based on the type of model being converted.  These are:\n",
    "    * `wallaroo.ModelConversion.ConvertXGBoostArgs`: Used for `XGBoost` models and takes the following parameters:\n",
    "    * `name`: The name of the model being converted.\n",
    "    * `comment`: Any comments for the model.\n",
    "    * `number_of_columns`: The number of columns the model was trained for.\n",
    "    * `input_type`: A [tensorflow Dtype](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) called in the format `ModelConversionInputType.{type}`, where `{type}` is `Float`, `Double`, etc depending on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "The first step is to import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "\n",
    "from wallaroo.ModelConversion import ConvertXGBoostArgs, ModelConversionSource, ModelConversionInputType\n",
    "from wallaroo.object import EntityNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Connect to your Wallaroo instance and store the connection into the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSO login through keycloak\n",
    "\n",
    "wallarooPrefix = \"YOUR PREFIX\"\n",
    "wallarooSuffix = \"YOUR SUFFIX\"\n",
    "\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and Methods\n",
    "\n",
    "The following will set the workspace, pipeline, model name, the model file name used when uploading and converting the `keras` model, and the sample data.\n",
    "\n",
    "The functions `get_workspace(name)` will either set the current workspace to the requested name, or create it if it does not exist.  The function `get_pipeline(name)` will either set the pipeline used to the name requested, or create it in the current workspace if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'xgboost-classification-autoconvert-workspace'\n",
    "pipeline_name = 'xgboost-classification-autoconvert-pipeline'\n",
    "model_name = 'xgb-class-model'\n",
    "model_file_name = 'xgb_class.pickle'\n",
    "sample_data = 'xgb_class_eval.json'\n",
    "\n",
    "\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Workspace and Pipeline\n",
    "\n",
    "Set or create the workspace and pipeline based on the names configured earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>xgboost-classification-autoconvert-pipeline</td></tr><tr><th>created</th> <td>2022-12-20 21:52:59.188616+00:00</td></tr><tr><th>last_updated</th> <td>2022-12-20 21:52:59.188616+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>9d486507-314d-4e67-9be4-9a9347c5b7a7</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'xgboost-classification-autoconvert-pipeline', 'create_time': datetime.datetime(2022, 12, 20, 21, 52, 59, 188616, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Model Autoconvert Parameters\n",
    "\n",
    "Set the paramters for converting the `xgb-class-model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of columns\n",
    "NF = 25\n",
    "\n",
    "model_conversion_args = ConvertXGBoostArgs(\n",
    "    name=model_name,\n",
    "    comment=\"xgboost classification model test\",\n",
    "    number_of_columns=NF,\n",
    "    input_type=ModelConversionInputType.Float32\n",
    ")\n",
    "model_conversion_type = ModelConversionSource.XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and Convert the Model\n",
    "\n",
    "Now we can upload the convert the model.  Once finished, it will be stored as `{unique-file-id}-converted.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and upload\n",
    "model_wl = wl.convert_model(model_file_name, model_conversion_type, model_conversion_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference\n",
    "\n",
    "With the model uploaded and converted, we can run a sample inference.\n",
    "\n",
    "### Deploy the Pipeline\n",
    "\n",
    "Add the uploaded and converted `model_wl` as a step in the pipeline, then deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>xgboost-classification-autoconvert-pipeline</td></tr><tr><th>created</th> <td>2022-12-20 21:52:59.188616+00:00</td></tr><tr><th>last_updated</th> <td>2022-12-20 22:05:08.884498+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>13409cae-2fbb-4ea8-9f4b-d546642a3a3e, 9d486507-314d-4e67-9be4-9a9347c5b7a7</td></tr><tr><th>steps</th> <td>xgb-class-model</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'xgboost-classification-autoconvert-pipeline', 'create_time': datetime.datetime(2022, 12, 20, 21, 52, 59, 188616, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'xgb-class-model', 'version': 'e403136e-9e51-4845-9200-7d8acf16abc5', 'sha': 'c3fd14edc2d6ccf3a2d4d7c7b409433fa8de53844c7c84f53f0b30a6e1514277'}]}}]\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_model_step(model_wl).deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Inference\n",
    "\n",
    "Use the `test_class_eval.json` as set earlier as our `sample_data` and perform the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 0, 0, 1]),\n",
       " array([[9.96794522e-01, 3.20547819e-03],\n",
       "        [1.12486482e-02, 9.88751352e-01],\n",
       "        [9.56235230e-01, 4.37647700e-02],\n",
       "        [9.99902725e-01, 9.72747803e-05],\n",
       "        [4.28396463e-03, 9.95716035e-01]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline.infer_from_file(sample_data)\n",
    "result[0].data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "With the tests complete, we will undeploy the pipeline to return the resources back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e951b583e3fbbcadfc15df61f9ed97fb9a76f59b2130f2cdf4d0033aa05e7e64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
