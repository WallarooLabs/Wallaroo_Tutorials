{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_conversion/pytorch-to-onnx).\n",
    "\n",
    "## How to Convert PyTorch to ONNX\n",
    "\n",
    "The following tutorial is a brief example of how to convert a [PyTorth](https://pytorch.org/) (aka sk-learn) ML model to [ONNX](https://onnx.ai/).  This allows organizations that have trained sk-learn models to convert them and use them with Wallaroo.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service.  This sample code is based on the guide [Convert your PyTorch model to ONNX](https://docs.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-convert-model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides the following:\n",
    "\n",
    "* `pytorchbikeshare.pt`: a RandomForestRegressor PyTorch model.  This model has a total of 58 inputs, and uses the class `BikeShareRegressor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Process\n",
    "\n",
    "### Libraries\n",
    "\n",
    "The first step is to import our libraries we will be using.  For this example, the PyTorth `torch` library will be imported into this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.3 MB 4.7 kB/s  eta 0:00:01     |██████                          | 146.9 MB 89.9 MB/s eta 0:00:07     |██████████████████████▍         | 544.4 MB 87.7 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.0\n"
     ]
    }
   ],
   "source": [
    "# the Pytorch libraries\n",
    "# Import into this kernel\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch\n",
    "\n",
    "import torch\n",
    "import torch.onnx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "To load a PyTorch model into a variable, the model's `class` has to be defined.  For out example we are using the `BikeShareRegressor` class as defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeShareRegressor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BikeShareRegressor, self).__init__()\n",
    "\n",
    "        \n",
    "        self.net = nn.Sequential(nn.Linear(input_size, l1),\n",
    "                                 torch.nn.ReLU(),\n",
    "                                 torch.nn.Dropout(p=dropout),\n",
    "                                 nn.BatchNorm1d(l1),\n",
    "                                 nn.Linear(l1, l2),\n",
    "                                 torch.nn.ReLU(),\n",
    "                                 torch.nn.Dropout(p=dropout),                                \n",
    "                                 nn.BatchNorm1d(l2),                                                                                                   \n",
    "                                 nn.Linear(l2, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the model into the variable `pytorch_tobe_converted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Pytorch model\n",
    "model = torch.load(\"./pytorch_bikesharingmodel.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert_ONNX Inputs\n",
    "\n",
    "Now we will define our method `Convert_ONNX()` which has the following inputs:\n",
    "    \n",
    "* **PyTorchModel**: the PyTorch we are converting.\n",
    "* **modelInputs**: the model input or tuple for multiple inputs.\n",
    "* **onnxPath**: The location to save the onnx file.\n",
    "\n",
    "* **opset_version**: The ONNX version to export to.\n",
    "* **input_names**: Array of the model's input names.\n",
    "* **output_names**:  Array of the model's output names.\n",
    "* **dynamic_axes**:  Sets variable length axes in the format, replacing the `batch_size` as necessary:\n",
    "  `{'modelInput' : { 0 : 'batch_size'}, 'modelOutput' : {0 : 'batch_size'}}`\n",
    "* **export_params**:  Whether to store the trained parameter weight inside the model file.  Defaults to `True`.\n",
    "* **do_constant_folding**: Sets whether to execute constant folding for optimization.  Defaults to `True`.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Convert to ONNX \n",
    "def Convert_ONNX(): \n",
    "\n",
    "    # set the model to inference mode \n",
    "    model.eval() \n",
    "\n",
    "    # Export the model   \n",
    "    torch.onnx.export(model,         # model being run \n",
    "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "         pypath,       # where to save the model  \n",
    "         export_params=True,  # store the trained parameter weights inside the model file \n",
    "         opset_version=10,    # the ONNX version to export the model to \n",
    "         do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "         input_names = ['modelInput'],   # the model's input names \n",
    "         output_names = ['modelOutput'], # the model's output names \n",
    "         dynamic_axes = {'modelInput' : {0 : 'batch_size'}, 'modelOutput' : {0 : 'batch_size'}} # variable length axes \n",
    "    ) \n",
    "    print(\" \") \n",
    "    print('Model has been converted to ONNX') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Model\n",
    "\n",
    "We'll now set our variables and run our conversion.  For out example, the `input_size` is known to be 58, and the `device` value we'll derive from `torch.cuda`.  We'll also set the ONNX version for exporting to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Model has been converted to ONNX\n"
     ]
    }
   ],
   "source": [
    "pypath = \"pytorchbikeshare.onnx\"\n",
    "\n",
    "input_size = 58\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "onnx_opset_version = 10\n",
    "\n",
    "# Set up some dummy input tensor for the model\n",
    "dummy_input = torch.randn(1, input_size, requires_grad=True).to(device)\n",
    "\n",
    "Convert_ONNX()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "And now our conversion is complete.  Please feel free to use this sample code in your own projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
