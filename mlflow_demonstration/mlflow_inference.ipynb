{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow Inference with Wallaroo Tutorial\n",
    "\n",
    "Wallaroo users can upload their trained [MLFlow ML Models](https://www.mlflow.org/docs/latest/models.html) into their Wallaroo instance and perform inferences with it through a Wallaroo pipeline.\n",
    "\n",
    "The following tutorial is a brief example of how:\n",
    "\n",
    "* Upload a MLFlow model into your Wallaroo workspace.\n",
    "* Add the MLFlow model as a step in a Wallaroo pipeline.\n",
    "* Perform inferences using submitted data to a deployed pipeline.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service. This tutorial provides the following:\n",
    "\n",
    "* `statsmodels-test`: A statsmodel ML model in MLFlow format.\n",
    "* `statsmodels-test-postprocess`: A post-processing model.\n",
    "\n",
    "### MLFlow Models and Wallaroo\n",
    "\n",
    "MLFlow models are composed of two parts:  the model, and the flavors.  When submitting a MLFlow model to Wallaroo, both aspects must be part of the ML Model included in the container.  For full information about MLFlow model structure, see the [MLFLow Documentation](https://www.mlflow.org/docs/latest/index.html).\n",
    "\n",
    "Wallaroo registers the models as Docker containers.  Organizations will either have to make their containers available in a public Docker or through a private container registry service.  For examples on setting up a private container registry service, see the [Docker Documentation \"Deploy a registry server\"](https://docs.docker.com/registry/deploying/).  For more details on setting up a container registry in a cloud environment, see the related documentation for your preferred cloud provider:\n",
    "  * [Google Cloud Platform Container Registry](https://cloud.google.com/container-registry)\n",
    "  * [Amazon Web Services Elastic Container Registry](https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html)\n",
    "  *  [Microsoft Azure Container Registry](https://azure.microsoft.com/en-us/free/container-registry/)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before uploading and running an inference with a MLFlow model in Wallaroo the following will be needed:\n",
    "\n",
    "* **MLFlow Input Schema**:  The input schema with the fields and data types for each MLFLow model type uploaded to Wallaroo.  In the examples below, the data types are imported using the `pyarrow` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFLow Inference Steps\n",
    "\n",
    "To upload a MLFlow ML Model into Wallaroo, use the following general step:\n",
    "\n",
    "* Import Libraries\n",
    "* Connect to Wallaroo\n",
    "* Set MLFlow Input Schemas\n",
    "* Register MLFlow Model\n",
    "* Create Pipeline and Add Model Steps\n",
    "* Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "We start by importing the libraries we will need to connect to Wallaroo and use our MLFlow models. This includes the `wallaroo` libraries, `pyarrow` for data types, and the `json` library for handling JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Connect to Wallaroo and store the connection in the variable `wl`.\n",
    "\n",
    "The folowing methods are used to create the workspace and pipeline for this tutorial.  A workspace is created and set as the current workspace that will contain the registered models and pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://magical-bear-3782.keycloak.wallaroo.community/auth/realms/master/device?user_code=RCXI-FEGJ\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    wl = wallaroo.Client()\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    wl = wallaroo.Client()\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'statsmodels-test'\n",
    "workspace_name= f\"{prefix}-workspace-{uuid.uuid4()}\"\n",
    "pipeline_name = f\"{prefix}-{uuid.uuid4()}\"\n",
    "\n",
    "mlflowworkspace = get_workspace(workspace_name)\n",
    "wl.set_current_workspace(mlflowworkspace)\n",
    "\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MLFlow Input Schemas\n",
    "\n",
    "Set the MLFlow input schemas through the `pyarrow` library.  In the examples below, the input schemas for both the MLFlow model `statsmodels-test` and the `statsmodels-test-postprocess` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_input_schema = pa.schema([\n",
    "  pa.field('temp', pa.float32()),\n",
    "  pa.field('holiday', pa.uint8()),\n",
    "  pa.field('workingday', pa.uint8()),\n",
    "  pa.field('windspeed', pa.float32())\n",
    "])\n",
    "\n",
    "pp_input_schema = pa.schema([\n",
    "    pa.field('predicted_mean', pa.float32())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register MLFlow Model\n",
    "\n",
    "Use the `register_model_image` method to register the Docker container containing the MLFlow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model = wl.register_model_image(\n",
    "    name=f\"{prefix}-statmodels\",\n",
    "    image=f\"proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mlflow-statsmodels-example:21cfff89\"\n",
    ").configure(\"mlflow\", input_schema=sm_input_schema, output_schema=pp_input_schema)\n",
    "pp_model = wl.register_model_image(\n",
    "    name=f\"{prefix}-postprocess\",\n",
    "    image=f\"proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mlflow-postprocess-example:ca3bcecb\"\n",
    ").configure(\"mlflow\", input_schema=pp_input_schema, output_schema=pp_input_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline and Add Model Steps\n",
    "\n",
    "With the models registered, we can add the MLFlow models as steps in the pipeline.  Once ready, we will deploy the pipeline so it is available for submitting data for running inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869</td></tr><tr><th>created</th> <td>2022-09-22 14:33:00.562180+00:00</td></tr><tr><th>last_updated</th> <td>2022-09-22 14:33:00.562180+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869', 'create_time': datetime.datetime(2022, 9, 22, 14, 33, 0, 562180, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'statsmodels-test-statmodels', 'version': '2f3261e6-cefd-426b-a309-5ec2a9f8ecda', 'sha': '3125d2bd33fbf223d8af6e8d1add555483f343f2ea4260f9fbd22f2f72350932'}]}}, {'ModelInference': {'models': [{'name': 'statsmodels-test-postprocess', 'version': '8ac74f31-2fd6-4f97-a01b-6f7068d8e5c3', 'sha': '142b39c639ea99b79001ed267d42d29785c4c299fc37d482f693dc072ec64df6'}]}}]\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_model_step(sm_model)\n",
    "pipeline.add_model_step(pp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869</td></tr><tr><th>created</th> <td>2022-09-22 14:33:00.562180+00:00</td></tr><tr><th>last_updated</th> <td>2022-09-22 14:34:20.076489+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>statsmodels-test-statmodels</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869', 'create_time': datetime.datetime(2022, 9, 22, 14, 33, 0, 562180, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'statsmodels-test-statmodels', 'version': '2f3261e6-cefd-426b-a309-5ec2a9f8ecda', 'sha': '3125d2bd33fbf223d8af6e8d1add555483f343f2ea4260f9fbd22f2f72350932'}]}}, {'ModelInference': {'models': [{'name': 'statsmodels-test-postprocess', 'version': '8ac74f31-2fd6-4f97-a01b-6f7068d8e5c3', 'sha': '142b39c639ea99b79001ed267d42d29785c4c299fc37d482f693dc072ec64df6'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "\n",
    "Once the pipeline is running, we can submit our data to the pipeline and return our results.  Once finished, we will undeploy the pipeline to return the resources back to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': None,\n",
       " 'engines': [{'ip': '10.244.0.25',\n",
       "   'name': 'engine-76f4b45db6-wkhjg',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'statsmodels-test-postprocess',\n",
       "      'version': '8ac74f31-2fd6-4f97-a01b-6f7068d8e5c3',\n",
       "      'sha': '142b39c639ea99b79001ed267d42d29785c4c299fc37d482f693dc072ec64df6',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'statsmodels-test-statmodels',\n",
       "      'version': '2f3261e6-cefd-426b-a309-5ec2a9f8ecda',\n",
       "      'sha': '3125d2bd33fbf223d8af6e8d1add555483f343f2ea4260f9fbd22f2f72350932',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.3.16',\n",
       "   'name': 'engine-lb-67c854cc86-dd7rq',\n",
       "   'status': 'Running',\n",
       "   'reason': None}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InferenceResult({'check_failures': [],\n",
       "  'elapsed': 600,\n",
       "  'model_name': 'statsmodels-test-postprocess',\n",
       "  'model_version': '8ac74f31-2fd6-4f97-a01b-6f7068d8e5c3',\n",
       "  'original_data': {'holiday': [0, 0, 0, 0, 0, 0, 0],\n",
       "                    'temp': [0.317391,\n",
       "                             0.365217,\n",
       "                             0.415,\n",
       "                             0.54,\n",
       "                             0.4725,\n",
       "                             0.3325,\n",
       "                             0.430435],\n",
       "                    'windspeed': [0.184309,\n",
       "                                  0.203117,\n",
       "                                  0.209579,\n",
       "                                  0.231017,\n",
       "                                  0.368167,\n",
       "                                  0.207721,\n",
       "                                  0.288783],\n",
       "                    'workingday': [1, 1, 1, 1, 0, 0, 1]},\n",
       "  'outputs': [{'Float': {'data': [-0.7701932787895203,\n",
       "                                  -0.15543800592422485,\n",
       "                                  0.36521396040916443,\n",
       "                                  1.739493727684021,\n",
       "                                  -0.07358897477388382,\n",
       "                                  -1.6944431066513062,\n",
       "                                  0.5889557003974915],\n",
       "                         'dim': [7, 1],\n",
       "                         'v': 1}}],\n",
       "  'pipeline_name': 'statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869',\n",
       "  'shadow_data': {},\n",
       "  'time': 1663857267513})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pipeline.infer_from_file('bike_day_eval_engine.json')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert results[0].data()[0].shape == (7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s ...................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869</td></tr><tr><th>created</th> <td>2022-09-22 14:33:00.562180+00:00</td></tr><tr><th>last_updated</th> <td>2022-09-22 14:34:20.076489+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>statsmodels-test-statmodels</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'statsmodels-test-364c7a5c-8754-48c8-aaf0-2cc055a8d869', 'create_time': datetime.datetime(2022, 9, 22, 14, 33, 0, 562180, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'statsmodels-test-statmodels', 'version': '2f3261e6-cefd-426b-a309-5ec2a9f8ecda', 'sha': '3125d2bd33fbf223d8af6e8d1add555483f343f2ea4260f9fbd22f2f72350932'}]}}, {'ModelInference': {'models': [{'name': 'statsmodels-test-postprocess', 'version': '8ac74f31-2fd6-4f97-a01b-6f7068d8e5c3', 'sha': '142b39c639ea99b79001ed267d42d29785c4c299fc37d482f693dc072ec64df6'}]}}]\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
