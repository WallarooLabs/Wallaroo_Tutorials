{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Cybersecurity with Arm Architecture\n",
    "\n",
    "\n",
    "This tutorial demonstrates how to use the Wallaroo combined with ARM processors to perform inferences with pre-trained classification cybersecurity ML models.  This demonstration assumes that:\n",
    "\n",
    "* A Wallaroo version 2023.3 or above instance is installed.\n",
    "* A nodepools with ARM architecture virtual machines are part of the Kubernetes cluster.  For example, Azure supports Ampere® Altra® Arm-based processor included with the following virtual machines:\n",
    "  * [Dpsv5 and Dpdsv5-series](https://learn.microsoft.com/en-us/azure/virtual-machines/dpsv5-dpdsv5-series)\n",
    "  * [Epsv5 and Epdsv5-series](https://learn.microsoft.com/en-us/azure/virtual-machines/epsv5-epdsv5-series)\n",
    "\n",
    "In this notebook we will walk through a simple pipeline deployment to inference on a model. For this example we will be using an open source model that uses an [Aloha CNN LSTM model](https://www.researchgate.net/publication/348920204_Using_Auxiliary_Inputs_in_Deep_Learning_Models_for_Detecting_DGA-based_Domain_Names) for classifying Domain names as being either legitimate or being used for nefarious purposes such as malware distribution.\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "For our example, we will perform the following:\n",
    "\n",
    "* Create a workspace for our work.\n",
    "* Upload the Aloha model.\n",
    "* Create a pipeline using the default architecture that can ingest our submitted data, submit it to the model, and export the results while tracking how long the inference took.\n",
    "* Redeploy the same pipeline on the ARM architecture, then perform the same inference on the same data and model and track how long the inference took.\n",
    "* Compare the inference timing through the default architecture versus the ARM architecture.\n",
    "\n",
    "All sample data and models are available through the [Wallaroo Quick Start Guide Samples repository](https://github.com/WallarooLabs/quickstartguide_samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  If logging in externally, update the `wallarooPrefix` and `wallarooSuffix` variables with the proper DNS information.  For more information on Wallaroo DNS settings, see the [Wallaroo DNS Integration Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-dns-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import pyarrow as pa\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://peters-arm-test.keycloak.wallaroocommunity.ninja/auth/realms/master/device?user_code=ASAD-WJBM\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Workspace\n",
    "\n",
    "We will create a workspace to work in and call it the \"alohaworkspace\", then set it as current workspace environment.  We'll also create our pipeline in advance as `alohapipeline`.  The model name and the model file will be specified for use in later steps.\n",
    "\n",
    "To allow this tutorial to be run multiple times or by multiple users in the same Wallaroo instance, a random 4 character prefix will be added to the workspace, pipeline, and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "# make a random 4 character suffix to verify uniqueness in tutorials\n",
    "suffix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "\n",
    "suffix='john2'\n",
    "\n",
    "workspace_name = f'arm-classification-security{suffix}'\n",
    "pipeline_name = 'alohapipeline'\n",
    "model_name = 'alohamodel'\n",
    "model_file_name = './alohacnnlstm.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-08-15 21:45:11.378943+00:00</td></tr><tr><th>last_updated</th> <td>2023-08-15 21:56:50.968678+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>7f029018-8b6a-4fe8-bb50-d65d0fdd3b00, 60c072a8-2493-451b-b174-a026869b8efd, a9bb9165-ef77-4368-84c3-0f255e66215f</td></tr><tr><th>steps</th> <td>alohamodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 8, 15, 21, 45, 11, 378943, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "aloha_pipeline = get_pipeline(pipeline_name)\n",
    "aloha_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the workspace is created the current default workspace with the `get_current_workspace()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'arm-classification-securityjohn2', 'id': 33, 'archived': False, 'created_by': '26a792cb-25d0-470a-aba2-9b4c4ba373ac', 'created_at': '2023-08-15T21:45:10.591097+00:00', 'models': [{'name': 'alohamodel', 'versions': 3, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 8, 15, 21, 56, 50, 827194, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 8, 15, 21, 45, 11, 238834, tzinfo=tzutc())}], 'pipelines': [{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 8, 15, 21, 45, 11, 378943, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the Models\n",
    "\n",
    "Now we will upload our models.  Note that for this example we are applying the model from a .ZIP file.  The Aloha model is a [protobuf](https://developers.google.com/protocol-buffers) file that has been defined for evaluating web pages, and we will configure it to use data in the `tensorflow` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wl.upload_model(model_name, model_file_name, framework=Framework.TENSORFLOW).configure(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a model\n",
    "\n",
    "Now that we have a model that we want to use we will create a deployment for it. \n",
    "\n",
    "We will tell the deployment we are using a tensorflow model and give the deployment name and the configuration we want for the deployment.\n",
    "\n",
    "To do this, we'll create our pipeline that can ingest the data, pass the data to our Aloha model, and give us a final output.  We'll call our pipeline `aloha-test-demo`, then deploy it so it's ready to receive data.  The deployment process usually takes about 45 seconds.\n",
    "\n",
    "* **Note**:  If you receive an error that the pipeline could not be deployed because there are not enough resources, undeploy any other pipelines and deploy this one again.  This command can quickly undeploy all pipelines to regain resources.  We recommend **not** running this command in a production environment since it will cancel any running pipelines:\n",
    "\n",
    "```python\n",
    "for p in wl.list_pipelines(): p.undeploy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-08-15 21:45:11.378943+00:00</td></tr><tr><th>last_updated</th> <td>2023-08-15 21:56:50.968678+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>7f029018-8b6a-4fe8-bb50-d65d0fdd3b00, 60c072a8-2493-451b-b174-a026869b8efd, a9bb9165-ef77-4368-84c3-0f255e66215f</td></tr><tr><th>steps</th> <td>alohamodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 8, 15, 21, 45, 11, 378943, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '5b99cf30-fac8-4a4a-a13d-a7562fbd20f2', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.clear()\n",
    "aloha_pipeline.add_model_step(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy on Standard Architecture\n",
    "\n",
    "We'll deploy this pipeline on the standard pipeline architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine': {'cpu': 4,\n",
       "  'resources': {'limits': {'cpu': 4, 'memory': '8Gi'},\n",
       "   'requests': {'cpu': 4, 'memory': '8Gi'}}},\n",
       " 'enginelb': {},\n",
       " 'engineAux': {'images': {}},\n",
       " 'node_selector': {}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s .............. ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-08-15 21:45:11.378943+00:00</td></tr><tr><th>last_updated</th> <td>2023-08-15 23:01:08.265285+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>f9af8905-33dd-40c4-b5b6-7ac58b727b20, 25e95e10-7191-490f-a36b-d2041e218d5e, 16f7f894-ec4c-40eb-8604-8496d867c329, 7f029018-8b6a-4fe8-bb50-d65d0fdd3b00, 60c072a8-2493-451b-b174-a026869b8efd, a9bb9165-ef77-4368-84c3-0f255e66215f</td></tr><tr><th>steps</th> <td>alohamodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 8, 15, 21, 45, 11, 378943, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '5b99cf30-fac8-4a4a-a13d-a7562fbd20f2', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_config = (wallaroo.deployment_config\n",
    "                     .DeploymentConfigBuilder()\n",
    "                     .cpus(4)\n",
    "                     .memory('8Gi')\n",
    "                     .build()\n",
    "                    )\n",
    "display(deployment_config)\n",
    "aloha_pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the pipeline is running and list what models are associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.3.15',\n",
       "   'name': 'engine-8598584947-n62hq',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'alohapipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'alohamodel',\n",
       "      'version': '5b99cf30-fac8-4a4a-a13d-a7562fbd20f2',\n",
       "      'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.3.14',\n",
       "   'name': 'engine-lb-584f54c899-8d6bl',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer From File\n",
    "\n",
    "We'll now infer from a large batch file `./data/data_25k.arrow` is an Apache Arrow table with 25,000 records in it.  Once submitted, we'll turn the result into a DataFrame and display the first five results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.99999994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.9999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.9999989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24949</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.9996881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.99981505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24951</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.9999919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24952</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24953</th>\n",
       "      <td>2023-08-15 23:01:23.666</td>\n",
       "      <td>[0.99999803]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time      out.main\n",
       "0     2023-08-15 23:01:23.666    [0.997564]\n",
       "1     2023-08-15 23:01:23.666  [0.99999994]\n",
       "2     2023-08-15 23:01:23.666         [1.0]\n",
       "3     2023-08-15 23:01:23.666   [0.9999997]\n",
       "4     2023-08-15 23:01:23.666   [0.9999989]\n",
       "...                       ...           ...\n",
       "24949 2023-08-15 23:01:23.666   [0.9996881]\n",
       "24950 2023-08-15 23:01:23.666  [0.99981505]\n",
       "24951 2023-08-15 23:01:23.666   [0.9999919]\n",
       "24952 2023-08-15 23:01:23.666         [1.0]\n",
       "24953 2023-08-15 23:01:23.666  [0.99999803]\n",
       "\n",
       "[24954 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "result = aloha_pipeline.infer_from_file('./data_25k.arrow')\n",
    "endTime = time.time()\n",
    "x64_time = endTime-startTime\n",
    "display(result.to_pandas().loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy with ARM\n",
    "\n",
    "We have demonstrated performing our sample inference using a standard pipeline deployment.  Now we will redeploy the same pipeline with the ARM architecture with the Wallaroo deployment setting `wallaroo.engine_config.Architecture.ARM` setting and applying it to the deployment configurations `arch` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine': {'cpu': 4,\n",
       "  'resources': {'limits': {'cpu': 4, 'memory': '8Gi'},\n",
       "   'requests': {'cpu': 4, 'memory': '8Gi'}},\n",
       "  'arch': 'arm'},\n",
       " 'enginelb': {},\n",
       " 'engineAux': {'images': {}},\n",
       " 'node_selector': {}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>alohapipeline</td></tr><tr><th>created</th> <td>2023-08-15 21:45:11.378943+00:00</td></tr><tr><th>last_updated</th> <td>2023-08-15 23:02:01.114999+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>6f2e0f93-03de-40f9-9921-2d75a5acbd81, 64fa00ca-bf81-46d0-b319-cdf219bd7ae4, f9af8905-33dd-40c4-b5b6-7ac58b727b20, 25e95e10-7191-490f-a36b-d2041e218d5e, 16f7f894-ec4c-40eb-8604-8496d867c329, 7f029018-8b6a-4fe8-bb50-d65d0fdd3b00, 60c072a8-2493-451b-b174-a026869b8efd, a9bb9165-ef77-4368-84c3-0f255e66215f</td></tr><tr><th>steps</th> <td>alohamodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'alohapipeline', 'create_time': datetime.datetime(2023, 8, 15, 21, 45, 11, 378943, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'alohamodel', 'version': '5b99cf30-fac8-4a4a-a13d-a7562fbd20f2', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wallaroo.engine_config import Architecture\n",
    "deployment_config_arm = (wallaroo.deployment_config\n",
    "                         .DeploymentConfigBuilder()\n",
    "                         .cpus(4)\n",
    "                         .memory('8Gi')\n",
    "                         .arch(Architecture.ARM)\n",
    "                         .build()\n",
    "                        )\n",
    "display(deployment_config_arm)\n",
    "aloha_pipeline.deploy(deployment_config = deployment_config_arm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Starting',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.3.15',\n",
       "   'name': 'engine-8598584947-n62hq',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'alohapipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'alohamodel',\n",
       "      'version': '5b99cf30-fac8-4a4a-a13d-a7562fbd20f2',\n",
       "      'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.3.14',\n",
       "   'name': 'engine-lb-584f54c899-8d6bl',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer with ARM\n",
    "\n",
    "We will now perform the same inference request, this time through the pipeline with the ARM architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.99999994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.9999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.9999989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24949</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.9996881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.99981505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24951</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.9999919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24952</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24953</th>\n",
       "      <td>2023-08-15 23:02:50.703</td>\n",
       "      <td>[0.99999803]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time      out.main\n",
       "0     2023-08-15 23:02:50.703    [0.997564]\n",
       "1     2023-08-15 23:02:50.703  [0.99999994]\n",
       "2     2023-08-15 23:02:50.703         [1.0]\n",
       "3     2023-08-15 23:02:50.703   [0.9999997]\n",
       "4     2023-08-15 23:02:50.703   [0.9999989]\n",
       "...                       ...           ...\n",
       "24949 2023-08-15 23:02:50.703   [0.9996881]\n",
       "24950 2023-08-15 23:02:50.703  [0.99981505]\n",
       "24951 2023-08-15 23:02:50.703   [0.9999919]\n",
       "24952 2023-08-15 23:02:50.703         [1.0]\n",
       "24953 2023-08-15 23:02:50.703  [0.99999803]\n",
       "\n",
       "[24954 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "result = aloha_pipeline.infer_from_file('./data_25k.arrow',timeout=2500)\n",
    "endTime = time.time()\n",
    "arm_time = endTime-startTime\n",
    "display(result.to_pandas().loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Standard against Arm\n",
    "\n",
    "With the two inferences complete, we'll compare the standard deployment architecture against the ARM architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Standard architecture: 5.88847279548645'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ARM architecture: 15.535664796829224'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"Standard architecture: {x64_time}\")\n",
    "display(f\"ARM architecture: {arm_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy Pipeline\n",
    "\n",
    "When finished with our tests, we will undeploy the pipeline so we have the Kubernetes resources back for other tasks.  Note that if the deployment variable is unchanged aloha_pipeline.deploy() will restart the inference engine in the same configuration as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s ..."
     ]
    }
   ],
   "source": [
    "aloha_pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
