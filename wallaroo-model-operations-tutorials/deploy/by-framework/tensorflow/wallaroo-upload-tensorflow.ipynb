{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2025.2_tutorials/wallaroo-model-operations-tutorials/deploy/by-framework/tensorflow).\n",
    "\n",
    "## Wallaroo SDK Upload Tutorial: Tensorflow\n",
    "\n",
    "In this notebook we will walk through uploading a Tensorflow model to a Wallaroo instance and performing sample inferences.  For this example we will be using an open source model that uses an [Aloha CNN LSTM model](https://www.researchgate.net/publication/348920204_Using_Auxiliary_Inputs_in_Deep_Learning_Models_for_Detecting_DGA-based_Domain_Names) for classifying Domain names as being either legitimate or being used for nefarious purposes such as malware distribution.  \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* An installed Wallaroo instance.\n",
    "* The following Python libraries installed:\n",
    "  * `os`\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * [`pyarrow`](https://pypi.org/project/pyarrow/): PyArrow for Apache Arrow support\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "For our example, we will perform the following:\n",
    "\n",
    "* Create a workspace for our work.\n",
    "* Upload the Aloha model.\n",
    "* Create a pipeline that can ingest our submitted data, submit it to the model, and export the results.\n",
    "\n",
    "All sample data and models are available through the [Wallaroo Quick Start Guide Samples repository](https://github.com/WallarooLabs/quickstartguide_samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/).e/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "\n",
    "import os\n",
    "os.environ[\"MODELS_ENABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Workspace\n",
    "\n",
    "We will create a workspace to work in and call it the \"alohaworkspace\", then set it as current workspace environment.  We'll also create our pipeline in advance as `alohapipeline`.  The model name and the model file will be specified for use in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = f'tensorflowuploadexampleworkspace'\n",
    "pipeline_name = f'tensorflowuploadexample'\n",
    "model_name = f'tensorflowuploadexample'\n",
    "model_file_name = './models/alohacnnlstm.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>tensorflowuploadexample</td></tr><tr><th>created</th> <td>2024-07-25 19:52:22.611940+00:00</td></tr><tr><th>last_updated</th> <td>2024-07-25 19:52:22.611940+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>workspace_id</th> <td>29</td></tr><tr><th>workspace_name</th> <td>tensorflowuploadexampleworkspace</td></tr><tr><th>arch</th> <td>None</td></tr><tr><th>accel</th> <td>None</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>2c9a5df4-95c2-4b9f-b054-8bac58930e13</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'tensorflowuploadexample', 'create_time': datetime.datetime(2024, 7, 25, 19, 52, 22, 611940, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = wl.get_workspace(name=workspace_name, create_if_not_exist=True)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "aloha_pipeline = wl.build_pipeline(pipeline_name)\n",
    "aloha_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the workspace is created the current default workspace with the `get_current_workspace()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tensorflowuploadexampleworkspace', 'id': 29, 'archived': False, 'created_by': '7ed7ae89-c45d-4ed7-ac5d-11cbccbbfa72', 'created_at': '2024-07-25T19:52:22.462832+00:00', 'models': [], 'pipelines': [{'name': 'tensorflowuploadexample', 'create_time': datetime.datetime(2024, 7, 25, 19, 52, 22, 611940, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the Models\n",
    "\n",
    "Now we will upload our models.  Note that for this example we are applying the model from a .ZIP file.  The Aloha model is a [protobuf](https://developers.google.com/protocol-buffers) file that has been defined for evaluating web pages, and we will configure it to use data in the `tensorflow` format.\n",
    "\n",
    "The following parameters are required for TensorFlow models.  Tensorflow models are native runtimes in Wallaroo, so the `input_schema` and `output_schema` parameters are optional.\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "|`name` | `string` (*Required*) | The name of the model.  Model names are unique per workspace.  Models that are uploaded with the same name are assigned as a new **version** of the model. |\n",
    "|`path` | `string` (*Required*) | The path to the model file being uploaded. \n",
    "|`framework` |`string` (*Required*) | Set as the `Framework.TENSORFLOW`. |\n",
    "|`input_schema` | `pyarrow.lib.Schema` (*Optional*) | The input schema in Apache Arrow schema format. |\n",
    "|`output_schema` | `pyarrow.lib.Schema` (*Optional*) | The output schema in Apache Arrow schema format. |\n",
    "| `convert_wait` | `bool` (*Optional*) (*Default: True*) | Not required for native runtimes. <ul><li>**True**: Waits in the script for the model conversion completion.</li><li>**False**:  Proceeds with the script without waiting for the model conversion process to display complete. |\n",
    "\n",
    "### TensorFlow File Format\n",
    "\n",
    "TensorFlow models are .zip file of the SavedModel format.  For example, the Aloha sample TensorFlow model is stored in the directory `alohacnnlstm`:\n",
    "\n",
    "```bash\n",
    "├── saved_model.pb\n",
    "└── variables\n",
    "    ├── variables.data-00000-of-00002\n",
    "    ├── variables.data-00001-of-00002\n",
    "    └── variables.index\n",
    "```\n",
    "\n",
    "This is compressed into the .zip file `alohacnnlstm.zip` with the following command:\n",
    "\n",
    "```python\n",
    "zip -r alohacnnlstm.zip alohacnnlstm/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wl.upload_model(model_name, model_file_name, Framework.TENSORFLOW).configure(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config().runtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a model\n",
    "\n",
    "Now that we have a model that we want to use we will create a deployment for it. \n",
    "\n",
    "We will tell the deployment we are using a tensorflow model and give the deployment name and the configuration we want for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>tensorflowuploadexample</td></tr><tr><th>created</th> <td>2024-07-25 19:52:22.611940+00:00</td></tr><tr><th>last_updated</th> <td>2024-07-25 19:52:22.611940+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>workspace_id</th> <td>29</td></tr><tr><th>workspace_name</th> <td>tensorflowuploadexampleworkspace</td></tr><tr><th>arch</th> <td>None</td></tr><tr><th>accel</th> <td>None</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>2c9a5df4-95c2-4b9f-b054-8bac58930e13</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'tensorflowuploadexample', 'create_time': datetime.datetime(2024, 7, 25, 19, 52, 22, 611940, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'tensorflowuploadexample', 'version': '078a0171-33dc-41a4-811f-1655849c31b2', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.add_model_step(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>tensorflowuploadexample</td></tr><tr><th>created</th> <td>2024-07-25 19:52:22.611940+00:00</td></tr><tr><th>last_updated</th> <td>2024-07-25 19:52:26.330855+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>workspace_id</th> <td>29</td></tr><tr><th>workspace_name</th> <td>tensorflowuploadexampleworkspace</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>3551303c-7be8-49cb-8379-afbbd70351aa, 2c9a5df4-95c2-4b9f-b054-8bac58930e13</td></tr><tr><th>steps</th> <td>tensorflowuploadexample</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'tensorflowuploadexample', 'create_time': datetime.datetime(2024, 7, 25, 19, 52, 22, 611940, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'tensorflowuploadexample', 'version': '078a0171-33dc-41a4-811f-1655849c31b2', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the pipeline is running and list what models are associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.28.1.7',\n",
       "   'name': 'engine-5964448bb9-dd6hw',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'tensorflowuploadexample',\n",
       "      'status': 'Running',\n",
       "      'version': '3551303c-7be8-49cb-8379-afbbd70351aa'}]},\n",
       "   'model_statuses': {'models': [{'name': 'tensorflowuploadexample',\n",
       "      'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8',\n",
       "      'status': 'Running',\n",
       "      'version': '078a0171-33dc-41a4-811f-1655849c31b2'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.28.5.6',\n",
       "   'name': 'engine-lb-6b59985857-pgc4s',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences\n",
    "\n",
    "### Infer 1 row\n",
    "\n",
    "Now that the pipeline is deployed and our Aloha model is in place, we'll perform a smoke test to verify the pipeline is up and running properly.  We'll use the `infer_from_file` command to load a single encoded URL into the inference engine and print the results back out.\n",
    "\n",
    "The result should tell us that the tokenized URL is legitimate (0) or fraud (1).  This sample data should return close to 1 in `out.main`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-25 19:52:44.380</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time    out.main\n",
       "0 2024-07-25 19:52:44.380  [0.997564]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoke_test = pd.DataFrame.from_records(\n",
    "    [\n",
    "    {\n",
    "        \"text_input\":[\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            28,\n",
    "            16,\n",
    "            32,\n",
    "            23,\n",
    "            29,\n",
    "            32,\n",
    "            30,\n",
    "            19,\n",
    "            26,\n",
    "            17\n",
    "        ]\n",
    "    }\n",
    "]\n",
    ")\n",
    "\n",
    "result = aloha_pipeline.infer(smoke_test)\n",
    "display(result.loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy Pipeline\n",
    "\n",
    "When finished with our tests, we will undeploy the pipeline so we have the Kubernetes resources back for other tasks.  Note that if the deployment variable is unchanged aloha_pipeline.deploy() will restart the inference engine in the same configuration as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>tensorflowuploadexample</td></tr><tr><th>created</th> <td>2024-07-25 19:52:22.611940+00:00</td></tr><tr><th>last_updated</th> <td>2024-07-25 19:52:26.330855+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>workspace_id</th> <td>29</td></tr><tr><th>workspace_name</th> <td>tensorflowuploadexampleworkspace</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>3551303c-7be8-49cb-8379-afbbd70351aa, 2c9a5df4-95c2-4b9f-b054-8bac58930e13</td></tr><tr><th>steps</th> <td>tensorflowuploadexample</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'tensorflowuploadexample', 'create_time': datetime.datetime(2024, 7, 25, 19, 52, 22, 611940, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'tensorflowuploadexample', 'version': '078a0171-33dc-41a4-811f-1655849c31b2', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aloha_pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk2024.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
