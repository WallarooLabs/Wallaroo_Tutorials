{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd16a788-cb70-4706-ad63-2ffde0c05cfe",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2024.4_tutorials/wallaroo-model-operations-tutorials/deploy/by-use-case/sentiment-analysis-hugging-face).\n",
    "\n",
    "## Sentiment Analysis with Hugging Face Toxic Bert Model\n",
    "\n",
    "The following tutorial demonstrates performing sentiment analysis via the Hugging Face model Toxic Bert.  This model inputs a set of text, and outputs a set of scores based on whether the text is considered toxic, hateful, etc.\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "* Uploading the model to a Wallaroo environment.\n",
    "* Deploying the model via a Wallaroo pipeline.\n",
    "* Performing a sample inference on the deployed model.\n",
    "* Undeploy the model and return the resources back to the environment.\n",
    "\n",
    "For access to these sample models and for a demonstration of how to use Wallaroo:\n",
    "\n",
    "* Contact your Wallaroo Support Representative **OR**\n",
    "* [Schedule Your Wallaroo.AI Demo Today](https://wallaroo.ai/request-a-demo/)\n",
    "\n",
    "## Tutorial Steps\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49fd2e7a-1a81-4959-a148-209861493ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# used to display DataFrame information without truncating\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import pyarrow as pa\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a511041",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1bdec6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client(request_timeout=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2f781-7288-4b58-aa11-cad4eaf25f0c",
   "metadata": {},
   "source": [
    "### Set Workspace and Variables\n",
    "\n",
    "The following creates or connects to an existing workspace, and sets it as the current workspace.  For more details on Wallaroo workspaces, see [Wallaroo Workspace Management Guide](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-optimize/wallaroo-workspace-management/).\n",
    "\n",
    "We will set the variables used for our deployed LLM model, and the models used for our LLM Listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36769fcf-e7b6-4343-8aa4-9c8ced637e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sentiment-analysis-tutorial', 'id': 16, 'archived': False, 'created_by': 'john.hansarick@wallaroo.ai', 'created_at': '2025-05-01T19:38:22.227711+00:00', 'models': [], 'pipelines': [{'name': 'sentiment-analysis', 'create_time': datetime.datetime(2025, 5, 1, 19, 45, 26, 228651, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_name = \"sentiment-analysis-tutorial\"  \n",
    "\n",
    "wl.set_current_workspace(wl.get_workspace(workspace_name, create_if_not_exist=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf5f98-2156-442f-9b09-a4d732be9cf9",
   "metadata": {},
   "source": [
    "### Upload LLM Listener Models and Create a Monitoring Pipeline\n",
    "\n",
    "This monitoring pipeline consists of a [Hugging Face sentiment analyzer](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-upload-register/#wallaroo-supported-models) step.\n",
    "\n",
    "The following model is used:\n",
    "\n",
    "* `toxic_bert`: A [Hugging Face Text Classification](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-upload-register/#wallaroo-supported-models) model that evaluates LLM outputs and outputs an array of scores including:\n",
    "  * `identity_hate`\n",
    "  * `insult`\n",
    "  * `obscene`\n",
    "  * `severe_toxic`\n",
    "  * `threat`\n",
    "  * `toxic`\n",
    "\n",
    "We upload the model via the [`wallaroo.client.Client.upload_models`](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-upload-register/) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b80e2db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>sentiment-analysis</td></tr><tr><th>created</th> <td>2025-05-01 19:45:26.228651+00:00</td></tr><tr><th>last_updated</th> <td>2025-05-01 20:57:26.958841+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>workspace_id</th> <td>16</td></tr><tr><th>workspace_name</th> <td>sentiment-analysis-tutorial</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>fbf54347-73f4-4042-a4ed-3371914c2e92, f5b2fae4-ffc8-4856-b942-c9f73a048ee6, 05736a38-9942-47e6-941c-177bbf712f84, 9063936f-ee24-4eba-a1c4-3618b905a031, 9924255d-9c92-4f92-9c70-441fd9675075, 5a3938e0-4eba-46b9-9102-c09ae063b29a, 58be18bc-6c7c-44b9-bf1e-3735b40f040b, 0342b954-41bf-4342-a5de-5740a5505c40, 1c94dad4-e77d-4f1a-81e6-5c21870fde08, b061ff23-ba26-4682-a738-2a09b55c1cb8, 55a57661-6199-4175-9d87-a02b4603a270, ea31b3aa-c51a-4604-bed2-7d68ad75dc56, 7b560178-00ce-496d-953b-3cbfcebaed4b, a928dffe-85f9-4f1c-8270-59ac6edfa5a0, 1f435615-77d2-49a0-8775-04d169a85bcd, 82fba0f8-4910-4106-88b9-2ef6235aca16, 0a633695-c33e-46d6-be1f-757690628702, 0b30d696-5c54-43ad-b099-85a7454e231b, 7303a912-5f05-4297-bbeb-09734fe730c9, 00df5dd7-d732-4537-b883-7dae579b4e95, 818d5c76-5aeb-422a-ba9f-6d43ccb337c0, c4555c1c-2c42-4067-8a25-1c3db4e5a682</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'sentiment-analysis', 'create_time': datetime.datetime(2025, 5, 1, 19, 45, 26, 228651, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'toxic-bert-analysis', 'version': '5135dc45-eb4d-47e0-93ce-3c61500d65e0', 'sha': '30b5c2d0c1a2102ad63ef7d84e953b018b45a0c021ea14916708ea1c8142ff38'}]}}]\"}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cf56a60a-21b9-46f8-9863-109a4bd80b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the sentiment analyzer\n",
    "\n",
    "input_schema = pa.schema([\n",
    "     pa.field('inputs', pa.string()), # required\n",
    "     pa.field('top_k', pa.int64()),  \n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "     pa.field('label', pa.list_(pa.string(), list_size=6)), # list with a number of items same as top_k, list_size can be skipped but may lead in worse performance\n",
    "     pa.field('score', pa.list_(pa.float64(), list_size=6)), # list with a number of items same as top_k, list_size can be skipped but may lead in worse performance\n",
    "])\n",
    "\n",
    "framework=Framework.HUGGING_FACE_TEXT_CLASSIFICATION\n",
    "model_name = \"toxic-bert-analysis\"\n",
    "model_file_name = './models/unitary-toxic-bert.zip'\n",
    "\n",
    "bert_model = wl.upload_model(model_name,\n",
    "                         model_file_name,\n",
    "                         framework=framework,\n",
    "                         input_schema=input_schema,\n",
    "                         output_schema=output_schema,\n",
    "                         convert_wait=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae820b",
   "metadata": {},
   "source": [
    "Once uploaded, the following loop verifies the conversion process is complete before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "952b6e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pending_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "attempting_load_container\n",
      "ready\n"
     ]
    }
   ],
   "source": [
    "while bert_model.status() != \"ready\" and bert_model.status() != \"error\":\n",
    "    print(bert_model.status())\n",
    "    time.sleep(10)\n",
    "print(bert_model.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89612555-e4e2-4ed5-a2a8-10b96f0f2be1",
   "metadata": {},
   "source": [
    "### Deploy the Models\n",
    "\n",
    "We deploy with a [deployment configuration](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-deploy-model/wallaroo-model-operations-deploy-model-deployment-configuration/) and set the Hugging Face sentiment analyzer to 4 cpus and 8 Gi RAM.\n",
    "\n",
    "We create the pipeline with the `build_pipeline` method, and add the model as the [pipeline steps](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-deploy/wallaroo-model-operations-deploy-model/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c00c1f2-498f-48b5-948b-4907de6d06e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>sentiment-analysis</td></tr><tr><th>created</th> <td>2025-05-01 19:45:26.228651+00:00</td></tr><tr><th>last_updated</th> <td>2025-05-01 21:11:08.381157+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>workspace_id</th> <td>16</td></tr><tr><th>workspace_name</th> <td>sentiment-analysis-tutorial</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>9dd0df40-f0c9-4dd1-a7ea-85521eca15f2, fbf54347-73f4-4042-a4ed-3371914c2e92, f5b2fae4-ffc8-4856-b942-c9f73a048ee6, 05736a38-9942-47e6-941c-177bbf712f84, 9063936f-ee24-4eba-a1c4-3618b905a031, 9924255d-9c92-4f92-9c70-441fd9675075, 5a3938e0-4eba-46b9-9102-c09ae063b29a, 58be18bc-6c7c-44b9-bf1e-3735b40f040b, 0342b954-41bf-4342-a5de-5740a5505c40, 1c94dad4-e77d-4f1a-81e6-5c21870fde08, b061ff23-ba26-4682-a738-2a09b55c1cb8, 55a57661-6199-4175-9d87-a02b4603a270, ea31b3aa-c51a-4604-bed2-7d68ad75dc56, 7b560178-00ce-496d-953b-3cbfcebaed4b, a928dffe-85f9-4f1c-8270-59ac6edfa5a0, 1f435615-77d2-49a0-8775-04d169a85bcd, 82fba0f8-4910-4106-88b9-2ef6235aca16, 0a633695-c33e-46d6-be1f-757690628702, 0b30d696-5c54-43ad-b099-85a7454e231b, 7303a912-5f05-4297-bbeb-09734fe730c9, 00df5dd7-d732-4537-b883-7dae579b4e95, 818d5c76-5aeb-422a-ba9f-6d43ccb337c0, c4555c1c-2c42-4067-8a25-1c3db4e5a682</td></tr><tr><th>steps</th> <td></td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'sentiment-analysis', 'create_time': datetime.datetime(2025, 5, 1, 19, 45, 26, 228651, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'toxic-bert-analysis', 'version': 'c0e9e44a-4af4-4e98-911e-75757ec848a3', 'sha': '30b5c2d0c1a2102ad63ef7d84e953b018b45a0c021ea14916708ea1c8142ff38'}]}}]\"}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the summarizer config \n",
    "deployment_config = wallaroo.DeploymentConfigBuilder() \\\n",
    "    .cpus(0.25).memory('1Gi') \\\n",
    "    .sidekick_cpus(bert_model, 4) \\\n",
    "    .sidekick_memory(bert_model, \"8Gi\") \\\n",
    "    .build()\n",
    "\n",
    "pipeline_name = 'sentiment-analysis'\n",
    "pipeline=wl.build_pipeline(pipeline_name)\n",
    "pipeline.clear()\n",
    "pipeline.add_model_step(bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d590b",
   "metadata": {},
   "source": [
    "With the pipeline set, we deploy the pipeline with the defined deployment configuration.  This allocates the resources from the cluster for the LLM Listener models use.\n",
    "\n",
    "Once the models are deployed, we check the status and verify it's running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4089f6f-a7ed-4f12-ae82-144afdbae0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment initiated for sentiment-analysis. Please check pipeline status.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>sentiment-analysis</td></tr><tr><th>created</th> <td>2025-05-01 19:45:26.228651+00:00</td></tr><tr><th>last_updated</th> <td>2025-05-01 21:11:15.044982+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>workspace_id</th> <td>16</td></tr><tr><th>workspace_name</th> <td>sentiment-analysis-tutorial</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>ffe6b4f9-99c3-4f35-b72e-8a16cb211c5b, 9dd0df40-f0c9-4dd1-a7ea-85521eca15f2, fbf54347-73f4-4042-a4ed-3371914c2e92, f5b2fae4-ffc8-4856-b942-c9f73a048ee6, 05736a38-9942-47e6-941c-177bbf712f84, 9063936f-ee24-4eba-a1c4-3618b905a031, 9924255d-9c92-4f92-9c70-441fd9675075, 5a3938e0-4eba-46b9-9102-c09ae063b29a, 58be18bc-6c7c-44b9-bf1e-3735b40f040b, 0342b954-41bf-4342-a5de-5740a5505c40, 1c94dad4-e77d-4f1a-81e6-5c21870fde08, b061ff23-ba26-4682-a738-2a09b55c1cb8, 55a57661-6199-4175-9d87-a02b4603a270, ea31b3aa-c51a-4604-bed2-7d68ad75dc56, 7b560178-00ce-496d-953b-3cbfcebaed4b, a928dffe-85f9-4f1c-8270-59ac6edfa5a0, 1f435615-77d2-49a0-8775-04d169a85bcd, 82fba0f8-4910-4106-88b9-2ef6235aca16, 0a633695-c33e-46d6-be1f-757690628702, 0b30d696-5c54-43ad-b099-85a7454e231b, 7303a912-5f05-4297-bbeb-09734fe730c9, 00df5dd7-d732-4537-b883-7dae579b4e95, 818d5c76-5aeb-422a-ba9f-6d43ccb337c0, c4555c1c-2c42-4067-8a25-1c3db4e5a682</td></tr><tr><th>steps</th> <td>toxic-bert-analysis</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'sentiment-analysis', 'create_time': datetime.datetime(2025, 5, 1, 19, 45, 26, 228651, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'toxic-bert-analysis', 'version': 'c0e9e44a-4af4-4e98-911e-75757ec848a3', 'sha': '30b5c2d0c1a2102ad63ef7d84e953b018b45a0c021ea14916708ea1c8142ff38'}]}}]\"}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.deploy(deployment_config=deployment_config, wait_for_status=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719c095-3984-4de3-ace1-49faf709d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Starting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Running'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(30)\n",
    "\n",
    "while pipeline.status()['status'] != 'Running':\n",
    "    time.sleep(30)\n",
    "    print(\"Waiting for deployment.\")\n",
    "    display(pipeline.status()['status'])\n",
    "display(pipeline.status()['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57f08a",
   "metadata": {},
   "source": [
    "### Sample Inference\n",
    "\n",
    "With sentiment analysis models deployed, we perform an inference via a sample pandas DataFrame via the [pipeline inference from file method](https://docs.wallaroo.ai/wallaroo-model-operations/wallaroo-model-operations-serve/).\n",
    "\n",
    "These results are returned as a pandas DataFrame, with the outputs shown in the `out.*` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed8366cd-9efe-43e6-8efe-600ac770ee42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.inputs</th>\n",
       "      <th>in.top_k</th>\n",
       "      <th>out.label</th>\n",
       "      <th>out.score</th>\n",
       "      <th>anomaly.count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-01 21:15:23.449</td>\n",
       "      <td>Wallaroo.AI is an AI platform that enables developers to build, deploy, and manage AI and machine learning models at scale. It provides a cloud-based infrastructure for building, training, and deploying AI models, as well as a set of tools and APIs for integrating AI into various applications.\\n\\nWallaroo.AI is designed to make it easy for developers to build and deploy AI models, regardless of their level of expertise in machine learning. It provides a range of features, including support for popular machine learning frameworks such as TensorFlow and PyTorch, as well as a set of pre-built AI models and APIs for common use cases such as image and speech recognition, natural language processing, and predictive analytics.\\n\\nWallaroo.AI is particularly well-suited for developers who are looking to build AI-powered applications, but may not have extensive expertise in machine learning or AI development. It provides a range of tools and resources to help developers get started with building AI-powered applications, including a cloud-based development environment, a set of pre-built AI models and APIs, and a range of tutorials and documentation.</td>\n",
       "      <td>6</td>\n",
       "      <td>[toxic, obscene, insult, identity_hate, threat, severe_toxic]</td>\n",
       "      <td>[0.0006922021857462823, 0.00018145183275919408, 0.00017831838340498507, 0.00014974642544984818, 0.00013229971227701753, 0.00012232053268235177]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2025-05-01 21:15:23.449   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                in.inputs  \\\n",
       "0  Wallaroo.AI is an AI platform that enables developers to build, deploy, and manage AI and machine learning models at scale. It provides a cloud-based infrastructure for building, training, and deploying AI models, as well as a set of tools and APIs for integrating AI into various applications.\\n\\nWallaroo.AI is designed to make it easy for developers to build and deploy AI models, regardless of their level of expertise in machine learning. It provides a range of features, including support for popular machine learning frameworks such as TensorFlow and PyTorch, as well as a set of pre-built AI models and APIs for common use cases such as image and speech recognition, natural language processing, and predictive analytics.\\n\\nWallaroo.AI is particularly well-suited for developers who are looking to build AI-powered applications, but may not have extensive expertise in machine learning or AI development. It provides a range of tools and resources to help developers get started with building AI-powered applications, including a cloud-based development environment, a set of pre-built AI models and APIs, and a range of tutorials and documentation.   \n",
       "\n",
       "   in.top_k                                                      out.label  \\\n",
       "0         6  [toxic, obscene, insult, identity_hate, threat, severe_toxic]   \n",
       "\n",
       "                                                                                                                                         out.score  \\\n",
       "0  [0.0006922021857462823, 0.00018145183275919408, 0.00017831838340498507, 0.00014974642544984818, 0.00013229971227701753, 0.00012232053268235177]   \n",
       "\n",
       "   anomaly.count  \n",
       "0              0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pipeline.infer_from_file(\"./data/sample_input.json\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73c723",
   "metadata": {},
   "source": [
    "The following allows us to view just the output results using the `models.postprocess` Python script, showing how the sentiment analysis model scored our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8a72be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>threat</th>\n",
       "      <th>severe_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0006922021857462823]</td>\n",
       "      <td>[0.00018145183275919408]</td>\n",
       "      <td>[0.00017831838340498507]</td>\n",
       "      <td>[0.00014974642544984818]</td>\n",
       "      <td>[0.00013229971227701753]</td>\n",
       "      <td>[0.00012232053268235177]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     toxic                   obscene  \\\n",
       "0  [0.0006922021857462823]  [0.00018145183275919408]   \n",
       "\n",
       "                     insult             identity_hate  \\\n",
       "0  [0.00017831838340498507]  [0.00014974642544984818]   \n",
       "\n",
       "                     threat              severe_toxic  \n",
       "0  [0.00013229971227701753]  [0.00012232053268235177]  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models.postprocess\n",
    "import importlib\n",
    "importlib.reload(models.postprocess)\n",
    "\n",
    "df = pd.DataFrame(models.postprocess.process_data(results))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf969b",
   "metadata": {},
   "source": [
    "### Undeploy\n",
    "\n",
    "With the tutorial complete, we undeploy the models to return the resources back to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8aa25307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>sentiment-analysis</td></tr><tr><th>created</th> <td>2025-05-01 19:45:26.228651+00:00</td></tr><tr><th>last_updated</th> <td>2025-05-01 21:11:15.044982+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>workspace_id</th> <td>16</td></tr><tr><th>workspace_name</th> <td>sentiment-analysis-tutorial</td></tr><tr><th>arch</th> <td>x86</td></tr><tr><th>accel</th> <td>none</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>ffe6b4f9-99c3-4f35-b72e-8a16cb211c5b, 9dd0df40-f0c9-4dd1-a7ea-85521eca15f2, fbf54347-73f4-4042-a4ed-3371914c2e92, f5b2fae4-ffc8-4856-b942-c9f73a048ee6, 05736a38-9942-47e6-941c-177bbf712f84, 9063936f-ee24-4eba-a1c4-3618b905a031, 9924255d-9c92-4f92-9c70-441fd9675075, 5a3938e0-4eba-46b9-9102-c09ae063b29a, 58be18bc-6c7c-44b9-bf1e-3735b40f040b, 0342b954-41bf-4342-a5de-5740a5505c40, 1c94dad4-e77d-4f1a-81e6-5c21870fde08, b061ff23-ba26-4682-a738-2a09b55c1cb8, 55a57661-6199-4175-9d87-a02b4603a270, ea31b3aa-c51a-4604-bed2-7d68ad75dc56, 7b560178-00ce-496d-953b-3cbfcebaed4b, a928dffe-85f9-4f1c-8270-59ac6edfa5a0, 1f435615-77d2-49a0-8775-04d169a85bcd, 82fba0f8-4910-4106-88b9-2ef6235aca16, 0a633695-c33e-46d6-be1f-757690628702, 0b30d696-5c54-43ad-b099-85a7454e231b, 7303a912-5f05-4297-bbeb-09734fe730c9, 00df5dd7-d732-4537-b883-7dae579b4e95, 818d5c76-5aeb-422a-ba9f-6d43ccb337c0, c4555c1c-2c42-4067-8a25-1c3db4e5a682</td></tr><tr><th>steps</th> <td>toxic-bert-analysis</td></tr><tr><th>published</th> <td>False</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'sentiment-analysis', 'create_time': datetime.datetime(2025, 5, 1, 19, 45, 26, 228651, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'toxic-bert-analysis', 'version': 'c0e9e44a-4af4-4e98-911e-75757ec848a3', 'sha': '30b5c2d0c1a2102ad63ef7d84e953b018b45a0c021ea14916708ea1c8142ff38'}]}}]\"}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7980ac",
   "metadata": {},
   "source": [
    "For access to these sample models and for a demonstration:\n",
    "\n",
    "* Contact your Wallaroo Support Representative **OR**\n",
    "* [Schedule Your Wallaroo.AI Demo Today](https://wallaroo.ai/request-a-demo/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk2024.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
