{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jupyter Notebooks in Production\n",
    "\n",
    "The following tutorials are available from the [Wallaroo Tutorials Repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/wallaroo2025.1_tutorials/wallaroo-model-operations-tutorials/model-deploy/packaging-and-deployment-by-use-case/notebooks_in_prod).\n",
    "\n",
    "The following tutorials provide an example of an organization moving from experimentation to deployment in production using Jupyter Notebooks as the basis for code research and use.  For this example, we can assume to main actors performing the following tasks.\n",
    "\n",
    "| Number | Notebook Sample | Task | Actor | Description |\n",
    "|---|---|---|---|---|\n",
    "|01| `01_explore_and_train.ipynb` | Data Exploration and Model Selection | Data Scientist | The data scientist evaluates the data and determines the best model to use to solve the proposed problems. |\n",
    "|02| `02_automated_training_process.ipynd` | Training Process Automation Setup | Data Scientist | The data scientist has selected the model and tested how to train it.  In this phase, the data scientist tests automating the training process based on a data store. |\n",
    "|03| `03_deploy_model.ipynb` | Deploy the Model in Wallaroo | MLOps Engineer | The MLOps takes the trained model and deploys a Wallaroo pipeline with it to perform inferences on by feeding it data from a data store. |\n",
    "|04| `04_regular_batch_inferences.ipynb` | Regular Batch Inference | MLOps Engineer | With the pipeline deployed, regular inferences can be made and the results reported to a data store. |\n",
    "\n",
    "Each Jupyter Notebook is arranged to demonstrate each step of the process.\n",
    "\n",
    "## Resources\n",
    "\n",
    "The following resources are provided as part of this tutorial:\n",
    "\n",
    "* **data**\n",
    "  * `data/seattle_housing_col_description.txt`: Describes the columns used as part data analysis.\n",
    "  * `data/seattle_housing.csv`: Sample data of the Seattle, Washington housing market between 2014 and 2015.\n",
    "* **code**\n",
    "  * `simdb.py`: A simulated database to demonstrate sending and receiving queries.\n",
    "  * `preprocess.py` and `postprocess.py`:  Processes the data into a format the model accepts, and formats the model outputs for database use.\n",
    "* **models**\n",
    "  * `housing_model_xgb.onnx`: Model created in Stage 2: Training Process Automation Setup.\n",
    "  * `./models/preprocess_step.zip.`: Formats the incoming data for the model.\n",
    "  * `./models/postprocess_step.zip`: Formats the outgoing data for the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
