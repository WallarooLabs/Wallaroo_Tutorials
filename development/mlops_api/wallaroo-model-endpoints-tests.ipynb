{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-features/wallaroo-model-endpoints).\n",
    "\n",
    "## Wallaroo SDK Inference Tutorial\n",
    "\n",
    "Wallaroo provides the ability to perform inferences through deployed pipelines via the Wallaroo SDK and the Wallaroo MLOps API.  This tutorial demonstrates performing inferences using the Wallaroo SDK.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* `ccfraud.onnx`:  A pre-trained credit card fraud detection model.\n",
    "* `data/cc_data_1k.arrow`, `data/cc_data_10k.arrow`: Sample testing data in Apache Arrow format with 1,000 and 10,000 records respectively.\n",
    "* `wallaroo-model-endpoints-sdk.py`: A code-only version of this tutorial as a Python script.\n",
    "\n",
    "This tutorial and sample data comes from the Machine Learning Group's demonstration on [Credit Card Fraud detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "The following is required for this tutorial:\n",
    "\n",
    "* A [deployed Wallaroo instance](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-install-guides/) with [Model Endpoints Enabled](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-model-endpoints-guide/)\n",
    "* The following Python libraries:\n",
    "  * [`pandas`](https://pypi.org/project/pandas/)\n",
    "  * [`polars`](https://pypi.org/project/polars/)\n",
    "  * [`pyarrow`](https://pypi.org/project/pyarrow/)\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/) (Installed in the Wallaroo JupyterHub service by default).\n",
    "\n",
    "### Tutorial Goals\n",
    "\n",
    "This demonstration provides a quick tutorial on performing inferences using the Wallaroo SDK using the Pipeline `infer` and `infer_from_file` methods.  This following steps will be performed:\n",
    "\n",
    "* Connect to a Wallaroo instance using environmental variables.  This bypasses the browser link confirmation for a seamless login.  For more information, see the [Wallaroo SDK Essentials Guide:  Client Connection](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/).\n",
    "* Create a workspace for our models and pipelines.\n",
    "* Upload the `ccfraud` model.\n",
    "* Create a pipeline and add the `ccfraud` model as a pipeline step.\n",
    "* Run a sample inference through SDK Pipeline `infer` method.\n",
    "* Run a batch inference through SDK Pipeline `infer_from_file` method.\n",
    "* Run a DataFrame and Arrow based inference through the pipeline Inference URL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a Connection to Wallaroo\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  This example will store the user's credentials into the file `./creds.json` which contains the following:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"username\": \"{Connecting User's Username}\", \n",
    "    \"password\": \"{Connecting User's Password}\", \n",
    "    \"email\": \"{Connecting User's Email Address}\"\n",
    "}\n",
    "```\n",
    "\n",
    "Replace the `username`, `password`, and `email` fields with the user account connecting to the Wallaroo instance.  This allows a seamless connection to the Wallaroo instance and bypasses the standard browser based confirmation link.  For more information, see the [Wallaroo SDK Essentials Guide:  Client Connection](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/).\n",
    "\n",
    "If running this example within the internal Wallaroo JupyterHub service, use the `wallaroo.Client(auth_type=\"user_password\")` method. If connecting externally via the [Wallaroo SDK](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-install-guides/), use the following to specify the URL of the Wallaroo instance as defined in the [Wallaroo DNS Integration Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-dns-guide/), replacing `wallarooPrefix` and `wallarooSuffix` with your Wallaroo instance's DNS prefix and suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lqkd'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import os\n",
    "\n",
    "# used for the Wallaroo 2023.1 Wallaroo SDK for Arrow support\n",
    "os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import requests\n",
    "\n",
    "# Used to create unique workspace and pipeline names\n",
    "import string\n",
    "import random\n",
    "\n",
    "# make a random 4 character prefix to prevent workspace and pipeline name clobbering\n",
    "prefix= ''.join(random.choice(string.ascii_lowercase) for i in range(4))\n",
    "display(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the login credentials.\n",
    "os.environ[\"WALLAROO_SDK_CREDENTIALS\"] = './creds.json.example'\n",
    "\n",
    "# Client connection from local Wallaroo instance\n",
    "\n",
    "# wl = wallaroo.Client(auth_type=\"user_password\")\n",
    "\n",
    "# Login from external connection\n",
    "\n",
    "wallarooPrefix = \"YOUR PREFIX\"\n",
    "wallarooSuffix = \"YOUR SUFFIX\"\n",
    "\n",
    "wallarooPrefix = \"doc-test\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"user_password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://doc-test.api.wallaroocommunity.ninja'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "APIURL=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\"\n",
    "display(APIURL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Workspace\n",
    "\n",
    "We will create a workspace to work in and call it the `sdkinferenceexampleworkspace`, then set it as current workspace environment.  We'll also create our pipeline in advance as `sdkinferenceexamplepipeline`.\n",
    "\n",
    "The model to be uploaded and used for inference will be labeled as `ccfraud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = f'{prefix}sdktest'\n",
    "pipeline_name_sdk = f'{prefix}sdktest'\n",
    "pipeline_name_api = f'{prefix}apitest'\n",
    "model_name_sdk = f'{prefix}ccfraudsdkupload'\n",
    "model_name_api = f'{prefix}ccfraudapiupload'\n",
    "model_file_name = './ccfraud.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "workspace_id = workspace.id()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Models\n",
    "\n",
    "First via SDK, then via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via SDK\n",
    "\n",
    "model_sdk = wl.upload_model(model_name_sdk, model_file_name).configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_models': {'returning': [{'models': [{'id': 53}]}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Via API\n",
    "\n",
    "# Retrieve the token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "apiRequest = f\"{APIURL}/v1/api/models/upload\"\n",
    "\n",
    "model_name = f\"{prefix}ccfraud\"\n",
    "\n",
    "data = {\n",
    "    \"name\":model_name,\n",
    "    \"visibility\":\"public\",\n",
    "    \"workspace_id\": workspace_id\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'file': open(model_file_name, 'rb')\n",
    "    }\n",
    "\n",
    "\n",
    "response = requests.post(apiRequest, files=files, data=data, headers=headers).json()\n",
    "display(response)\n",
    "modelId=response['insert_models']['returning'][0]['models'][0]['id']\n",
    "display(modelId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 53,\n",
       " 'owner_id': '\"\"',\n",
       " 'workspace_id': 27,\n",
       " 'name': 'lqkdccfraud',\n",
       " 'updated_at': '2023-04-03T21:14:36.26303+00:00',\n",
       " 'created_at': '2023-04-03T21:14:36.26303+00:00',\n",
       " 'model_config': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the model details\n",
    "\n",
    "# Retrieve the token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# set Content-Type type\n",
    "headers['Content-Type']='application/json'\n",
    "\n",
    "apiRequest = f\"{APIURL}/v1/api/models/get_by_id\"\n",
    "\n",
    "data = {\n",
    "  \"id\": modelId\n",
    "}\n",
    "\n",
    "response = requests.post(apiRequest, json=data, headers=headers, verify=True).json()\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the version, sha and model config id of the model uploaded via api\n",
    "models_api = wl.list_models()[0]\n",
    "model_api = models_api.versions()[0]\n",
    "model_config_ids = model_api.config().id()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline\n",
    "\n",
    "In a production environment, the pipeline would already be set up with the model and pipeline steps.  We would then select it and use it to perform our inferences.\n",
    "\n",
    "For this example we will create the pipeline and add the `ccfraud` model as a pipeline step and deploy it.  Deploying a pipeline allocates resources from the Kubernetes cluster hosting the Wallaroo instance and prepares it for performing inferences.\n",
    "\n",
    "If this process was already completed, it can be commented out and skipped for the next step [Select Pipeline](#select-pipeline).\n",
    "\n",
    "Then we will list the pipelines and select the one we will be using for the inference demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>lqkdsdktest</td></tr><tr><th>created</th> <td>2023-04-03 21:14:33.335415+00:00</td></tr><tr><th>last_updated</th> <td>2023-04-03 21:14:33.335415+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>9ab3c5cb-a2b2-4c59-981d-8775e4c50950</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'lqkdsdktest', 'create_time': datetime.datetime(2023, 4, 3, 21, 14, 33, 335415, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the SDK version of the pipeline\n",
    "pipeline_sdk = get_pipeline(pipeline_name_sdk)\n",
    "pipeline_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICIxNi01alZna1lYMW1ackg3aTZMRnFGN2RtN2ZBN1dOcWJHQnBpYzhta2pvIn0.eyJleHAiOjE2ODA1NTY1MzEsImlhdCI6MTY4MDU1NjQ3MSwianRpIjoiZWRiNWJmNjctOTg4Zi00NTgxLThlOTQtZmFjNTE0ZGMzNTcyIiwiaXNzIjoiaHR0cHM6Ly9kb2MtdGVzdC5rZXljbG9hay53YWxsYXJvb2NvbW11bml0eS5uaW5qYS9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJhdWQiOlsibWFzdGVyLXJlYWxtIiwiYWNjb3VudCJdLCJzdWIiOiI2NzcyYzRjMS0zNTU5LTQ0MmYtYjU3Mi01NDU5Y2NmM2M4OWYiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJzZGstY2xpZW50Iiwic2Vzc2lvbl9zdGF0ZSI6IjZmNDA1MTQzLTIwZjUtNDE2My05MGJlLWYyNTA1ODI3YTlkNCIsImFjciI6IjEiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiZGVmYXVsdC1yb2xlcy1tYXN0ZXIiLCJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsibWFzdGVyLXJlYWxtIjp7InJvbGVzIjpbIm1hbmFnZS11c2VycyIsInZpZXctdXNlcnMiLCJxdWVyeS1ncm91cHMiLCJxdWVyeS11c2VycyJdfSwiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJwcm9maWxlIGVtYWlsIiwic2lkIjoiNmY0MDUxNDMtMjBmNS00MTYzLTkwYmUtZjI1MDU4MjdhOWQ0IiwiZW1haWxfdmVyaWZpZWQiOmZhbHNlLCJodHRwczovL2hhc3VyYS5pby9qd3QvY2xhaW1zIjp7IngtaGFzdXJhLXVzZXItaWQiOiI2NzcyYzRjMS0zNTU5LTQ0MmYtYjU3Mi01NDU5Y2NmM2M4OWYiLCJ4LWhhc3VyYS1kZWZhdWx0LXJvbGUiOiJ1c2VyIiwieC1oYXN1cmEtYWxsb3dlZC1yb2xlcyI6WyJ1c2VyIl0sIngtaGFzdXJhLXVzZXItZ3JvdXBzIjoie30ifSwibmFtZSI6IkpvaG4gSGFuc2FyaWNrIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiam9obi5odW1tZWxAd2FsbGFyb28uYWkiLCJnaXZlbl9uYW1lIjoiSm9obiIsImZhbWlseV9uYW1lIjoiSGFuc2FyaWNrIiwiZW1haWwiOiJqb2huLmh1bW1lbEB3YWxsYXJvby5haSJ9.BsNvTzF-GHdOL9tAcPN1ZnvLxvxcEi_ZUtYqFX7AmbKs82hxG6-JZZIJ8WJLsu0tFv-HrMj6LUHsDt8r0HUFZj1KWUrPLVaIi9ePh13uw9TA8tnl1VWhVqRddIVeJhh55eNn8LGHz6yNPxcZyYS2aK4QxBbV8IeSLmzvhIRPsDAiE66IAwH-iK0Y0HCBbiWPQ2YLATq6ni1ftV2bMB-H2p29fIhOc05rOC1YnJWtO_k90nC07uXZSQTP36qrnGYCmFAp2TWCD43yXIRBdesBDDhTFMHFMaOlcMEHYiRbUWiugMYVzWS0wRqhdye1DgPWgHVjEdCgTOQQCxmY3woPjA'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = wl.auth.auth_header()\n",
    "display(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_pk_id': 46,\n",
       " 'pipeline_variant_pk_id': 46,\n",
       " 'pipeline_variant_version': '74850aad-bfac-42c6-9720-4c0c26492642'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the API version of the pipeline\n",
    "\n",
    "# Create pipeline\n",
    "\n",
    "# Retrieve the token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# set Content-Type type\n",
    "headers['Content-Type']='application/json'\n",
    "\n",
    "apiRequest = f\"{APIURL}/v1/api/pipelines/create\"\n",
    "\n",
    "data = {\n",
    "  \"pipeline_id\": pipeline_name_api,\n",
    "  \"workspace_id\": workspace_id,\n",
    "  \"definition\": {'steps': [{'ModelInference': {'models': [{'name': f'{pipeline_name_api}upload', 'version': model_api.version(), 'sha': model_api.sha()}]}}]}\n",
    "}\n",
    "\n",
    "response = requests.post(apiRequest, json=data, headers=headers, verify=True).json()\n",
    "display(response)\n",
    "pipeline_id = response['pipeline_pk_id']\n",
    "pipeline_variant_id=response['pipeline_variant_pk_id']\n",
    "pipeline_variant_version=['pipeline_variant_version']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Pipeline\n",
    "\n",
    "Via SDK, then API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>lqkdsdktest</td></tr><tr><th>created</th> <td>2023-04-03 21:14:33.335415+00:00</td></tr><tr><th>last_updated</th> <td>2023-04-03 21:14:37.184867+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>14895cba-dc44-4e91-bcc9-ce7e66e60384, 9ab3c5cb-a2b2-4c59-981d-8775e4c50950</td></tr><tr><th>steps</th> <td>lqkdccfraudsdkupload</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'lqkdsdktest', 'create_time': datetime.datetime(2023, 4, 3, 21, 14, 33, 335415, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'lqkdccfraudsdkupload', 'version': '77a8e195-940c-47ff-ad99-a785d91b8774', 'sha': 'bc85ce596945f876256f41515c7501c399fd97ebcb9ab3dd41bf03f8937b4507'}]}}]\"}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SDK method\n",
    "\n",
    "pipeline_sdk.add_model_step(model_sdk).deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 33}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# API method\n",
    "\n",
    "# Deploy Pipeline\n",
    "\n",
    "# Retrieve the token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# set Content-Type type\n",
    "headers['Content-Type']='application/json'\n",
    "\n",
    "apiRequest = f\"{APIURL}/v1/api/pipelines/deploy\"\n",
    "\n",
    "exampleModelDeployId=pipeline_name_api\n",
    "\n",
    "data = {\n",
    "    \"deploy_id\": exampleModelDeployId,\n",
    "    \"pipeline_version_pk_id\": pipeline_variant_id,\n",
    "    \"model_ids\": [\n",
    "        modelId\n",
    "    ],\n",
    "    \"pipeline_id\": pipeline_id\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(apiRequest, json=data, headers=headers, verify=True).json()\n",
    "display(response)\n",
    "exampleModelDeploymentId=response['id']\n",
    "\n",
    "# wait 45 seconds for this to finish deploying\n",
    "import time\n",
    "time.sleep(45)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interferences via SDK\n",
    "\n",
    "Once a pipeline has been deployed, an inference can be run.  This will submit data to the pipeline, where it is processed through each of the pipeline's steps with the output of the previous step providing the input for the next step.  The final step will then output the result of all of the pipeline's steps.\n",
    "\n",
    "* Inputs are either sent one of the following:\n",
    "  * [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).  The return value will be a pandas.DataFrame.\n",
    "  * [Apache Arrow](https://arrow.apache.org/).  The return value will be an Apache Arrow table.\n",
    "  * [Custom JSON](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/#inferenceresult-object).  The return value will be a Wallaroo InferenceResult object.\n",
    "\n",
    "Inferences are performed through the Wallaroo SDK via the Pipeline `infer` and `infer_from_file` methods.\n",
    "\n",
    "### infer Method\n",
    "\n",
    "Now that the pipeline is deployed we'll perform an inference using the Pipeline `infer` method, and submit a pandas DataFrame as our input data.  This will return a pandas DataFrame as the inference output.\n",
    "\n",
    "For more information, see the [Wallaroo SDK Essentials Guide: Inferencing: Run Inference through Local Variable](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/wallaroo-sdk-inferences/#run-inference-through-local-variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.dense_1</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-03 21:14:49.110</td>\n",
       "      <td>[1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]</td>\n",
       "      <td>[0.0014974177]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-04-03 21:14:49.110   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                            in.tensor  \\\n",
       "0  [1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]   \n",
       "\n",
       "      out.dense_1  check_failures  \n",
       "0  [0.0014974177]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoke_test = pd.DataFrame.from_records([\n",
    "    {\n",
    "        \"tensor\":[\n",
    "            1.0678324729,\n",
    "            0.2177810266,\n",
    "            -1.7115145262,\n",
    "            0.682285721,\n",
    "            1.0138553067,\n",
    "            -0.4335000013,\n",
    "            0.7395859437,\n",
    "            -0.2882839595,\n",
    "            -0.447262688,\n",
    "            0.5146124988,\n",
    "            0.3791316964,\n",
    "            0.5190619748,\n",
    "            -0.4904593222,\n",
    "            1.1656456469,\n",
    "            -0.9776307444,\n",
    "            -0.6322198963,\n",
    "            -0.6891477694,\n",
    "            0.1783317857,\n",
    "            0.1397992467,\n",
    "            -0.3554220649,\n",
    "            0.4394217877,\n",
    "            1.4588397512,\n",
    "            -0.3886829615,\n",
    "            0.4353492889,\n",
    "            1.7420053483,\n",
    "            -0.4434654615,\n",
    "            -0.1515747891,\n",
    "            -0.2668451725,\n",
    "            -1.4549617756\n",
    "        ]\n",
    "    }\n",
    "])\n",
    "result = pipeline_sdk.infer(smoke_test)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Starting',\n",
       " 'details': ['containers with unready status: [helm-runner]',\n",
       "  'containers with unready status: [helm-runner]'],\n",
       " 'engines': [],\n",
       " 'engine_lbs': [],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to show the API side - this was deployed via the API.  Note the step, and then the inference results below.\n",
    "\n",
    "pipeline_api = get_pipeline(pipeline_name_api)\n",
    "pipeline_api.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.tensor</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-03 21:15:35.767</td>\n",
       "      <td>[1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]</td>\n",
       "      <td>[1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-04-03 21:15:35.767   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                            in.tensor  \\\n",
       "0  [1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                           out.tensor  \\\n",
       "0  [1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]   \n",
       "\n",
       "   check_failures  \n",
       "0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoke_test = pd.DataFrame.from_records([\n",
    "    {\n",
    "        \"tensor\":[\n",
    "            1.0678324729,\n",
    "            0.2177810266,\n",
    "            -1.7115145262,\n",
    "            0.682285721,\n",
    "            1.0138553067,\n",
    "            -0.4335000013,\n",
    "            0.7395859437,\n",
    "            -0.2882839595,\n",
    "            -0.447262688,\n",
    "            0.5146124988,\n",
    "            0.3791316964,\n",
    "            0.5190619748,\n",
    "            -0.4904593222,\n",
    "            1.1656456469,\n",
    "            -0.9776307444,\n",
    "            -0.6322198963,\n",
    "            -0.6891477694,\n",
    "            0.1783317857,\n",
    "            0.1397992467,\n",
    "            -0.3554220649,\n",
    "            0.4394217877,\n",
    "            1.4588397512,\n",
    "            -0.3886829615,\n",
    "            0.4353492889,\n",
    "            1.7420053483,\n",
    "            -0.4434654615,\n",
    "            -0.1515747891,\n",
    "            -0.2668451725,\n",
    "            -1.4549617756\n",
    "        ]\n",
    "    }\n",
    "])\n",
    "result = pipeline_api.infer(smoke_test)\n",
    "display(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences via HTTP POST\n",
    "\n",
    "Each pipeline has its own Inference URL that allows HTTP/S POST submissions of inference requests.  Full details are available from the [Inferencing via the Wallaroo MLOps API](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-inferences/wallaroo-api-inferences/).\n",
    "\n",
    "This example will demonstrate performing inferences with a DataFrame input and an Apache Arrow input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request JWT Token\n",
    "\n",
    "There are two ways to retrieve the JWT token used to authenticate to the Wallaroo MLOps API.\n",
    "\n",
    "* [Wallaroo SDK](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/wallaroo-mlops-api-essential-guide/#through-the-wallaroo-sdk).  This method requires a Wallaroo based user.\n",
    "* [API Clent Secret](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/wallaroo-mlops-api-essential-guide/#through-keycloak).  This is the recommended method as it is user independent.  It allows any valid user to make an inference request.\n",
    "\n",
    "This tutorial will use the Wallaroo SDK method Wallaroo Client `wl.auth.auth_header()` method, extracting the Authentication header from the response.\n",
    "\n",
    "Reference:  [MLOps API Retrieve Token Through Wallaroo SDK](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/wallaroo-mlops-api-essential-guide/#through-the-wallaroo-sdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICIxNi01alZna1lYMW1ackg3aTZMRnFGN2RtN2ZBN1dOcWJHQnBpYzhta2pvIn0.eyJleHAiOjE2ODA1NTY1OTUsImlhdCI6MTY4MDU1NjUzNSwianRpIjoiZmYwZjQ4MDEtOGU0NS00NmRkLWEyNmEtZTVjNWM2Y2YyYmJmIiwiaXNzIjoiaHR0cHM6Ly9kb2MtdGVzdC5rZXljbG9hay53YWxsYXJvb2NvbW11bml0eS5uaW5qYS9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJhdWQiOlsibWFzdGVyLXJlYWxtIiwiYWNjb3VudCJdLCJzdWIiOiI2NzcyYzRjMS0zNTU5LTQ0MmYtYjU3Mi01NDU5Y2NmM2M4OWYiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJzZGstY2xpZW50Iiwic2Vzc2lvbl9zdGF0ZSI6IjZmNDA1MTQzLTIwZjUtNDE2My05MGJlLWYyNTA1ODI3YTlkNCIsImFjciI6IjEiLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiZGVmYXVsdC1yb2xlcy1tYXN0ZXIiLCJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsibWFzdGVyLXJlYWxtIjp7InJvbGVzIjpbIm1hbmFnZS11c2VycyIsInZpZXctdXNlcnMiLCJxdWVyeS1ncm91cHMiLCJxdWVyeS11c2VycyJdfSwiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJwcm9maWxlIGVtYWlsIiwic2lkIjoiNmY0MDUxNDMtMjBmNS00MTYzLTkwYmUtZjI1MDU4MjdhOWQ0IiwiZW1haWxfdmVyaWZpZWQiOmZhbHNlLCJodHRwczovL2hhc3VyYS5pby9qd3QvY2xhaW1zIjp7IngtaGFzdXJhLXVzZXItaWQiOiI2NzcyYzRjMS0zNTU5LTQ0MmYtYjU3Mi01NDU5Y2NmM2M4OWYiLCJ4LWhhc3VyYS1kZWZhdWx0LXJvbGUiOiJ1c2VyIiwieC1oYXN1cmEtYWxsb3dlZC1yb2xlcyI6WyJ1c2VyIl0sIngtaGFzdXJhLXVzZXItZ3JvdXBzIjoie30ifSwibmFtZSI6IkpvaG4gSGFuc2FyaWNrIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiam9obi5odW1tZWxAd2FsbGFyb28uYWkiLCJnaXZlbl9uYW1lIjoiSm9obiIsImZhbWlseV9uYW1lIjoiSGFuc2FyaWNrIiwiZW1haWwiOiJqb2huLmh1bW1lbEB3YWxsYXJvby5haSJ9.OK7PxrfQxHUoXu4noewisMx3R8oyvPiSNrzey-9mYjVW2IT4LkZqgVA8vRx6eqw4o7iSJtO1PxM5gdQvflGFZBP0mj__LYPpOdygd99froVGdkJp79HNtOJ-kenLnuosyJzFxzGUtb9sZfPi2AyoPIEMBvtUoGmRyFnLfftzULeISIXjOq0g1FRx93y3BUGN09go5vbGTDEOalimJKJSBoH843d-dh1Y6JFqjo0XiLLO7_abqeCedg8oa2qbghUXjeipU2ngEkzitUI9Y3yE0pxOTolbR5-azXrTHwQsi_Vjic99GGPSWQJenmdW73vCEva15NAkTwlwV2a9WzHi3w'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = wl.auth.auth_header()\n",
    "display(headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Pipeline Inference URL\n",
    "\n",
    "The Pipeline Inference URL is retrieved via the Wallaroo SDK with the Pipeline `._deployment._url()` method.\n",
    "\n",
    "* **IMPORTANT NOTE**:  The `_deployment._url()` method will return an **internal** URL when using Python commands from within the Wallaroo instance - for example, the Wallaroo JupyterHub service.  When connecting via an external connection, `_deployment._url()` returns an **external** URL.\n",
    "  * External URL connections requires [the authentication be included in the HTTP request](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/), and [Model Endpoints](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-model-endpoints-guide/) are enabled in the Wallaroo configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doc-test.api.wallaroocommunity.ninja/v1/api/pipelines/infer/lqkdsdktest-32\n",
      "https://doc-test.api.wallaroocommunity.ninja/v1/api/pipelines/infer/lqkdapitest-33\n"
     ]
    }
   ],
   "source": [
    "deploy_sdk_url = pipeline_sdk._deployment._url()\n",
    "print(deploy_sdk_url)\n",
    "\n",
    "deploy_api_url = pipeline_api._deployment._url()\n",
    "print(deploy_api_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP Inference with DataFrame Input\n",
    "\n",
    "The following example performs a HTTP Inference request with a DataFrame input.  The request will be made with first a Python `requests` method, then using `curl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1680556571759</td>\n",
       "      <td>{'dense_1': [0.0014974177]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time                          out\n",
       "0  1680556571759  {'dense_1': [0.0014974177]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Through the Pipeline SDK\n",
    "\n",
    "# get authorization header\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "## Inference through external URL using dataframe\n",
    "\n",
    "# retrieve the json data to submit\n",
    "data = pd.DataFrame.from_records([\n",
    "    {\n",
    "        \"tensor\":[\n",
    "            1.0678324729,\n",
    "            0.2177810266,\n",
    "            -1.7115145262,\n",
    "            0.682285721,\n",
    "            1.0138553067,\n",
    "            -0.4335000013,\n",
    "            0.7395859437,\n",
    "            -0.2882839595,\n",
    "            -0.447262688,\n",
    "            0.5146124988,\n",
    "            0.3791316964,\n",
    "            0.5190619748,\n",
    "            -0.4904593222,\n",
    "            1.1656456469,\n",
    "            -0.9776307444,\n",
    "            -0.6322198963,\n",
    "            -0.6891477694,\n",
    "            0.1783317857,\n",
    "            0.1397992467,\n",
    "            -0.3554220649,\n",
    "            0.4394217877,\n",
    "            1.4588397512,\n",
    "            -0.3886829615,\n",
    "            0.4353492889,\n",
    "            1.7420053483,\n",
    "            -0.4434654615,\n",
    "            -0.1515747891,\n",
    "            -0.2668451725,\n",
    "            -1.4549617756\n",
    "        ]\n",
    "    }\n",
    "])\n",
    "\n",
    "\n",
    "# set the content type for pandas records\n",
    "headers['Content-Type']= 'application/json; format=pandas-records'\n",
    "\n",
    "# set accept as pandas-records\n",
    "headers['Accept']='application/json; format=pandas-records'\n",
    "\n",
    "# submit the request via POST, import as pandas DataFrame\n",
    "response = pd.DataFrame.from_records(\n",
    "                requests.post(\n",
    "                    deploy_sdk_url, \n",
    "                    data=data.to_json(orient=\"records\"), \n",
    "                    headers=headers)\n",
    "                .json()\n",
    "            )\n",
    "display(response.loc[:,[\"time\", \"out\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1680556572058</td>\n",
       "      <td>{'tensor': [1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  \\\n",
       "0  1680556572058   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                              out  \n",
       "0  {'tensor': [1.0678324729, 0.2177810266, -1.7115145262, 0.682285721, 1.0138553067, -0.4335000013, 0.7395859437, -0.2882839595, -0.447262688, 0.5146124988, 0.3791316964, 0.5190619748, -0.4904593222, 1.1656456469, -0.9776307444, -0.6322198963, -0.6891477694, 0.1783317857, 0.1397992467, -0.3554220649, 0.4394217877, 1.4588397512, -0.3886829615, 0.4353492889, 1.7420053483, -0.4434654615, -0.1515747891, -0.2668451725, -1.4549617756]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Through the Pipeline API\n",
    "\n",
    "# get authorization header\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "## Inference through external URL using dataframe\n",
    "\n",
    "# retrieve the json data to submit\n",
    "data = pd.DataFrame.from_records([\n",
    "    {\n",
    "        \"tensor\":[\n",
    "            1.0678324729,\n",
    "            0.2177810266,\n",
    "            -1.7115145262,\n",
    "            0.682285721,\n",
    "            1.0138553067,\n",
    "            -0.4335000013,\n",
    "            0.7395859437,\n",
    "            -0.2882839595,\n",
    "            -0.447262688,\n",
    "            0.5146124988,\n",
    "            0.3791316964,\n",
    "            0.5190619748,\n",
    "            -0.4904593222,\n",
    "            1.1656456469,\n",
    "            -0.9776307444,\n",
    "            -0.6322198963,\n",
    "            -0.6891477694,\n",
    "            0.1783317857,\n",
    "            0.1397992467,\n",
    "            -0.3554220649,\n",
    "            0.4394217877,\n",
    "            1.4588397512,\n",
    "            -0.3886829615,\n",
    "            0.4353492889,\n",
    "            1.7420053483,\n",
    "            -0.4434654615,\n",
    "            -0.1515747891,\n",
    "            -0.2668451725,\n",
    "            -1.4549617756\n",
    "        ]\n",
    "    }\n",
    "])\n",
    "\n",
    "\n",
    "# set the content type for pandas records\n",
    "headers['Content-Type']= 'application/json; format=pandas-records'\n",
    "\n",
    "# set accept as pandas-records\n",
    "headers['Accept']='application/json; format=pandas-records'\n",
    "\n",
    "# submit the request via POST, import as pandas DataFrame\n",
    "response = pd.DataFrame.from_records(\n",
    "                requests.post(\n",
    "                    deploy_api_url, \n",
    "                    data=data.to_json(orient=\"records\"), \n",
    "                    headers=headers)\n",
    "                .json()\n",
    "            )\n",
    "display(response.loc[:,[\"time\", \"out\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy Pipeline\n",
    "\n",
    "When finished with our tests, we will undeploy the pipeline so we have the Kubernetes resources back for other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>lqkdapitest</td></tr><tr><th>created</th> <td>2023-04-03 21:14:34.929600+00:00</td></tr><tr><th>last_updated</th> <td>2023-04-03 21:14:34.929600+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>74850aad-bfac-42c6-9720-4c0c26492642</td></tr><tr><th>steps</th> <td>lqkdccfraud</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'lqkdapitest', 'create_time': datetime.datetime(2023, 4, 3, 21, 14, 34, 929600, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_sdk.undeploy()\n",
    "pipeline_api.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrowtests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
