{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/development/sdk-install-guides/azure-ml-sdk-install).\n",
    "\n",
    "## Installing the Wallaroo SDK into Azure ML Workspace\n",
    "\n",
    "Organizations that use Azure ML for model training and development can deploy models to Wallaroo through the [Wallaroo SDK](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/).  The following guide is created to assist users with installing the Wallaroo SDK, setting up authentication through Azure ML, and making a standard connection to a Wallaroo instance through Azure ML Workspace.\n",
    "\n",
    "These instructions are based on the on the [Wallaroo SSO for Microsoft Azure](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-sso-authentication/wallaroo-sso-azure/) and the [Connect to Wallaroo](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/) guides.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* `aloha-cnn-lstm.zip`: A pre-trained open source model that uses an [Aloha CNN LSTM model](https://www.researchgate.net/publication/348920204_Using_Auxiliary_Inputs_in_Deep_Learning_Models_for_Detecting_DGA-based_Domain_Names) for classifying Domain names as being either legitimate or being used for nefarious purposes such as malware distribution.\n",
    "* Test Data Files:\n",
    "  * `data_1k.arrow`: 1,000 records\n",
    "  * `data_25k.arrow`: 25,000 records\n",
    "\n",
    "To use the Wallaroo SDK within Azure ML Workspace, a virtual environment will be used.  This will set the necessary libraries and specific Python version required.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "The following is required for this tutorial:\n",
    "\n",
    "* A Wallaroo instance version 2023.1 or later.\n",
    "* Python 3.8.6 or later installed locally\n",
    "* [Conda](https://docs.conda.io/en/latest/):  Used for managing python virtual environments.  This is automatically included in Azure ML Workspace.\n",
    "* An Azure ML workspace is created with a compute configured.\n",
    "* The following Python libraries installed:\n",
    "  * `os`\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * [`pyarrow`](https://pypi.org/project/pyarrow/): PyArrow for Apache Arrow support\n",
    "  * [`polars`](https://pypi.org/project/polars/): Polars for DataFrame with native Apache Arrow support\n",
    "\n",
    "## General Steps\n",
    "\n",
    "For our example, we will perform the following:\n",
    "\n",
    "* Wallaroo SDK Install\n",
    "  * Set up a Python virtual environment through `conda` with the libraries that enable the virtual environment for use in a Jupyter Hub environment.\n",
    "  * Install the Wallaroo SDK.\n",
    "* Wallaroo SDK from remote JupyterHub Demonstration (Optional):  The following steps are an optional exercise to demonstrate using the Wallaroo SDK from a remote connection.  The entire tutorial can be found on the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/development/sdk-install-guides/azure-ml-sdk-install)).\n",
    "  * Connect to a remote Wallaroo instance.  \n",
    "  * Create a workspace for our work.\n",
    "  * Upload the Aloha model.\n",
    "  * Create a pipeline that can ingest our submitted data, submit it to the model, and export the results\n",
    "  * Run a sample inference through our pipeline by loading a file\n",
    "  * Retrieve the external deployment URL.  This sample Wallaroo instance has been configured to create external inference URLs for pipelines.  For more information, see the [External Inference URL Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-model-endpoints-guide/).\n",
    "  * Run a sample inference through our pipeline's external URL and store the results in a file.  This assumes that the External Inference URLs have been enabled for the target Wallaroo instance.\n",
    "  * Undeploy the pipeline and return resources back to the Wallaroo instance's Kubernetes environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Wallaroo SDK\n",
    "\n",
    "### Set Up Virtual Python Environment\n",
    "\n",
    "To set up the virtual environment in Azure ML for using the Wallaroo SDK with Azure ML Workspace:\n",
    "\n",
    "1. Select **Notebooks**.\n",
    "1. Create a new folder where the Jupyter Notebooks for Wallaroo will be installed.\n",
    "1. From this repository, upload `sdk-install-guides/azure-ml-sdk-install.zip`, or upload the entire folder `sdk-install-guides/azure-ml-sdk-install`.  This tutorial will assume the .zip file was uploaded.\n",
    "1. Select **Open Terminal**.  Navigate to the target directory.\n",
    "1. Run `unzip azure-ml-sdk-install.zip` to unzip the directory, then cd into it with `cd azure-ml-sdk-install`.\n",
    "1. Create the Python virtual environment with `conda`.  Replace `wallaroosdk` with the name of the virtual environment as required by your organization.  Note that Python 3.8.6 and above is specified as a requirement for Python libraries used with the Wallaroo SDK.  The following will install the latest version of Python 3.8, which as of this time is 3.8.15.\n",
    "\n",
    "    ```bash\n",
    "    conda create -n wallaroosdk python=3.8\n",
    "    ```\n",
    "\n",
    "1. Activate the new environment.\n",
    "\n",
    "    ```bash\n",
    "    conda activate wallaroosdk\n",
    "    ```\n",
    "\n",
    "1. Install the `ipykernel` library.  This allows the JupyterHub notebooks to access the Python virtual environment as a kernel.\n",
    "\n",
    "    ```bash\n",
    "    conda install ipykernel\n",
    "    ```\n",
    "    \n",
    "1. Install the new virtual environment as a python kernel.\n",
    "\n",
    "    ```bash\n",
    "    ipython kernel install --user --name=wallaroosdk\n",
    "    ```\n",
    "    \n",
    "1. Install the Wallaroo SDK.  This process may take several minutes while the other required Python libraries are added to the virtual environment.\n",
    "\n",
    "    * **IMPORTANT NOTE**:  The version of the Wallaroo SDK should match the Wallaroo instance.  For example, this example connects to a Wallaroo Enterprise version `2023.1` instance, so the SDK version should be `wallaroo==2023.1.1`.\n",
    "\n",
    "    ```bash\n",
    "    pip install wallaroo==2023.2.1rc2\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once the conda virtual environment has been installed, it can either be selected as a new Jupyter Notebook kernel, or the Notebook's kernel can be set to an existing Jupyter notebook.  If a notebook is existing, close it then reopen to select the new Wallaroo SDK environment.\n",
    "\n",
    "![](./images/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-install-guides/azureml-sdk-guide/azureml-select-kernel.png)\n",
    "\n",
    "To use a new Notebook:\n",
    "\n",
    "1. From the left navigation panel, select **+->Notebook**.\n",
    "1. From the Kernel selection dropbox on the upper right side, select the new virtual environment - in this case, **wallaroosdk**.\n",
    "\n",
    "To update an existing Notebook to use the new virtual environment as a kernel:\n",
    "\n",
    "1. From the main menu, select **Kernel->Change Kernel**.\n",
    "1. Select the new kernel.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Wallaroo Connection\n",
    "\n",
    "With the Wallaroo Python SDK installed, remote commands and inferences can be performed through the following steps.\n",
    "\n",
    "### Open a Connection to Wallaroo\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client(api_endpoint, auth_endpoint, auth_type command)` command that connects to the Wallaroo instance services.\n",
    "\n",
    "The `Client` method takes the following parameters:\n",
    "\n",
    "* **api_endpoint** (*String*): The URL to the Wallaroo instance API service.\n",
    "* **auth_endpoint** (*String*): The URL to the Wallaroo instance Keycloak service.\n",
    "* **auth_type command** (*String*): The authorization type.  In this case, `SSO`.\n",
    "\n",
    "The URLs are based on the Wallaroo Prefix and Wallaroo Suffix for the Wallaroo instance.  For more information, see the [DNS Integration Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-dns-guide/).  In the example below, replace \"YOUR PREFIX\" and \"YOUR SUFFIX\" with the Wallaroo Prefix and Suffix, respectively.\n",
    "\n",
    "Once run, the `wallaroo.Client` command provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Depending on the configuration of the Wallaroo instance, the user will either be presented with a login request to the Wallaroo instance or be authenticated through a broker such as Google, Github, etc.  To use the broker, select it from the list under the username/password login forms.  For more information on Wallaroo authentication configurations, see the [Wallaroo Authentication Configuration Guides](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-sso-authentication/).\n",
    "\n",
    "![Wallaroo Login](./images/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-install-guides/azureml-sdk-guide/azure-initial-login.png)\n",
    "\n",
    "Once authenticated, the user will verify adding the device the user is establishing the connection from.  Once both steps are complete, then the connection is granted.\n",
    "\n",
    "![Device Registration](./images//wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-install-guides/wallaroo-device-access.png)\n",
    "\n",
    "The connection is stored in the variable `wl` for use in all other Wallaroo calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import pyarrow as pa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "For this example, a connection through the Wallaroo SDK is used.  For more information, see the [Wallaroo SDK Essentials Guide:  Client Connection](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/).\n",
    "\n",
    "For `wallarooPrefix = \"YOUR PREFIX.\"` and `wallarooSuffix = \"YOUR SUFFIX\"`, enter the prefix and suffix for your Wallaroo instance DNS name.  If the prefix instance is blank, then it can be `wallarooPrefix = \"\"`.  **Note that the prefix includes the `.` for proper formatting.**  For example, if the prefix is empty and the suffix is `wallaroo.example.com`, then the settings would be:\n",
    "\n",
    "```python\n",
    "wallarooPrefix = \"\"\n",
    "wallarooSuffix = \"wallaroo.example.com\"\n",
    "```\n",
    "\n",
    "If the prefix is `sales.` and the suffix `example.com`, then the settings would be:\n",
    "\n",
    "```python\n",
    "wallarooPrefix = \"sales.\"\n",
    "wallarooSuffix = \"wallaroo.example.com\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSO login through keycloak\n",
    "\n",
    "wallarooPrefix = \"YOUR PREFIX\"\n",
    "wallarooSuffix = \"YOUR SUFFIX\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Workspace\n",
    "\n",
    "We will create a workspace to work in and call it the `azuremlsdkworkspace`, then set it as current workspace environment.  We'll also create our pipeline in advance as `azuremlsdkpipeline`.\n",
    "\n",
    "* **IMPORTANT NOTE**:  For this example, the Aloha model is stored in the file `alohacnnlstm.zip`.  When using tensor based models, the zip file **must** match the name of the tensor directory.  For example, if the tensor directory is `alohacnnlstm`, then the .zip file must be named `alohacnnlstm.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'azuremlsdkworkspace'\n",
    "pipeline_name = 'azuremlsdkpipeline'\n",
    "model_name = 'azuremlsdkmodel'\n",
    "model_file_name = './alohacnnlstm.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>azuremlsdkpipeline</td></tr><tr><th>created</th> <td>2023-05-17 21:01:46.655024+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-17 21:01:46.655024+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>e011272d-c22c-4b2d-ab9f-b17c60099434</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'azuremlsdkpipeline', 'create_time': datetime.datetime(2023, 5, 17, 21, 1, 46, 655024, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the workspace is created the current default workspace with the `get_current_workspace()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'azuremlsdkworkspace', 'id': 8, 'archived': False, 'created_by': '028c8b48-c39b-4578-9110-0b5bdd3824da', 'created_at': '2023-05-17T21:01:45.647036+00:00', 'models': [], 'pipelines': [{'name': 'azuremlsdkpipeline', 'create_time': datetime.datetime(2023, 5, 17, 21, 1, 46, 655024, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Models\n",
    "\n",
    "Now we will upload our model.  Note that for this example we are applying the model from a .ZIP file.  The Aloha model is a [protobuf](https://developers.google.com/protocol-buffers) file that has been defined for evaluating web pages, and we will configure it to use data in the `tensorflow` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wl.upload_model(model_name, model_file_name).configure(\"tensorflow\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy a Model\n",
    "\n",
    "Now that we have a model that we want to use we will create a deployment for it. \n",
    "\n",
    "We will tell the deployment we are using a tensorflow model and give the deployment name and the configuration we want for the deployment.\n",
    "\n",
    "To do this, we'll create our pipeline that can ingest the data, pass the data to our Aloha model, and give us a final output.  We'll call our pipeline `externalsdkpipeline`, then deploy it so it's ready to receive data.  The deployment process usually takes about 45 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>azuremlsdkpipeline</td></tr><tr><th>created</th> <td>2023-05-17 21:01:46.655024+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-17 21:01:46.655024+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>e011272d-c22c-4b2d-ab9f-b17c60099434</td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'azuremlsdkpipeline', 'create_time': datetime.datetime(2023, 5, 17, 21, 1, 46, 655024, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'azuremlsdkmodel', 'version': 'fb4331da-9f14-4013-8ffb-4d994ab88eac', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_model_step(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>azuremlsdkpipeline</td></tr><tr><th>created</th> <td>2023-05-17 21:01:46.655024+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-17 21:01:51.594226+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>28a7a5aa-5359-4320-842b-bad84258f7e4, e011272d-c22c-4b2d-ab9f-b17c60099434</td></tr><tr><th>steps</th> <td>azuremlsdkmodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'azuremlsdkpipeline', 'create_time': datetime.datetime(2023, 5, 17, 21, 1, 46, 655024, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'azuremlsdkmodel', 'version': 'fb4331da-9f14-4013-8ffb-4d994ab88eac', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.deploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the pipeline is running and list what models are associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.3.137',\n",
       "   'name': 'engine-cb79b5d57-b68lv',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'azuremlsdkpipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'azuremlsdkmodel',\n",
       "      'version': 'fb4331da-9f14-4013-8ffb-4d994ab88eac',\n",
       "      'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.4.167',\n",
       "   'name': 'engine-lb-584f54c899-vzlwz',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interferences\n",
    "\n",
    "### Infer 1 row\n",
    "\n",
    "Now that the pipeline is deployed and our Aloha model is in place, we'll perform a smoke test to verify the pipeline is up and running properly.  We'll use the `infer_from_file` command to load a single encoded URL into the inference engine and print the results back out.\n",
    "\n",
    "The result should tell us that the tokenized URL is legitimate (0) or fraud (1).  This sample data should return close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-17 21:02:11.230</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time    out.main\n",
       "0 2023-05-17 21:02:11.230  [0.997564]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Demonstrate via straight infer\n",
    "\n",
    "smoke_test = pd.DataFrame.from_records(\n",
    "    [\n",
    "    {\n",
    "        \"text_input\":[\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            28,\n",
    "            16,\n",
    "            32,\n",
    "            23,\n",
    "            29,\n",
    "            32,\n",
    "            30,\n",
    "            19,\n",
    "            26,\n",
    "            17\n",
    "        ]\n",
    "    }\n",
    "]\n",
    ")\n",
    "\n",
    "result = pipeline.infer(smoke_test)\n",
    "display(result.loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer 1,000 Rows\n",
    "\n",
    "We can also infer an entire batch as one request either with the Pipeline `infer` method with multiple rows, or loaded from a file using the Pipeline `infer_from_file` method.  For this example, we will run a batch on 1,000 records using the file `data_1k.arrow`.  This is an Apache Arrow table, which gives the added benefit of speed and lower file size as a binary file rather than a text JSON file.\n",
    "\n",
    "We'll infer the 1,000 records, then convert it to a DataFrame and display the first 5 to save space in our Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-17 21:02:12.236</td>\n",
       "      <td>[0.997564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-17 21:02:12.236</td>\n",
       "      <td>[0.9885122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-17 21:02:12.236</td>\n",
       "      <td>[0.9993358]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-17 21:02:12.236</td>\n",
       "      <td>[0.99999857]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-17 21:02:12.236</td>\n",
       "      <td>[0.9984837]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time      out.main\n",
       "0 2023-05-17 21:02:12.236    [0.997564]\n",
       "1 2023-05-17 21:02:12.236   [0.9885122]\n",
       "2 2023-05-17 21:02:12.236   [0.9993358]\n",
       "3 2023-05-17 21:02:12.236  [0.99999857]\n",
       "4 2023-05-17 21:02:12.236   [0.9984837]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pipeline.infer_from_file('./data/data_1k.arrow')\n",
    "\n",
    "outputs = result.to_pandas()\n",
    "display(outputs.head(5).loc[:, [\"time\",\"out.main\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Inference\n",
    "\n",
    "Now that our smoke test is successful, let's really give it some data.  We have two inference files we can use:\n",
    "\n",
    "* `data-1k.arrow`:  Contains 10,000 inferences\n",
    "* `data-25k.arrow`: Contains 25,000 inferences\n",
    "\n",
    "These inference inputs are Apache Arrow tables, which Wallaroo can ingest natively.  These are binary files, and are faster to transmit because of their smaller size compared to JSON.\n",
    "\n",
    "We'll pipe the `data-25k.arrow` file through the `pipeline` deployment URL, and place the results in a file named `response.df`.  Note that for larger batches of 1,000 inferences or more can be difficult to view in Juypter Hub because of its size, so we'll only display the first 5 results of the inference.\n",
    "\n",
    "When retrieving the pipeline inference URL through an external SDK connection, the External Inference URL will be returned.  This URL will function provided that the **Enable external URL inference endpoints** is enabled.  For more information, see the [Wallaroo Model Endpoints Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-model-endpoints-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_url = pipeline._deployment._url()\n",
    "inference_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJDYkFqN19QY0xCWTFkWmJiUDZ6Q3BsbkNBYTd6US0tRHlyNy0yLXlQb25nIn0.eyJleHAiOjE2ODQzNTczNjQsImlhdCI6MTY4NDM1NzMwNCwiYXV0aF90aW1lIjoxNjg0MzU1OTU5LCJqdGkiOiI0N2NjYzIyOS0yMjEzLTRjYWQtYWI4ZS03ZjNjNTE4MWZhMmUiLCJpc3MiOiJodHRwczovL2RvYy10ZXN0LmtleWNsb2FrLndhbGxhcm9vY29tbXVuaXR5Lm5pbmphL2F1dGgvcmVhbG1zL21hc3RlciIsImF1ZCI6WyJtYXN0ZXItcmVhbG0iLCJhY2NvdW50Il0sInN1YiI6IjAyOGM4YjQ4LWMzOWItNDU3OC05MTEwLTBiNWJkZDM4MjRkYSIsInR5cCI6IkJlYXJlciIsImF6cCI6InNkay1jbGllbnQiLCJzZXNzaW9uX3N0YXRlIjoiMGJlODJjN2ItNzg1My00ZjVkLWJiNWEtOTlkYjUwYjhiNDVmIiwiYWNyIjoiMCIsInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJkZWZhdWx0LXJvbGVzLW1hc3RlciIsIm9mZmxpbmVfYWNjZXNzIiwidW1hX2F1dGhvcml6YXRpb24iXX0sInJlc291cmNlX2FjY2VzcyI6eyJtYXN0ZXItcmVhbG0iOnsicm9sZXMiOlsibWFuYWdlLXVzZXJzIiwidmlldy11c2VycyIsInF1ZXJ5LWdyb3VwcyIsInF1ZXJ5LXVzZXJzIl19LCJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiIwYmU4MmM3Yi03ODUzLTRmNWQtYmI1YS05OWRiNTBiOGI0NWYiLCJlbWFpbF92ZXJpZmllZCI6ZmFsc2UsImh0dHBzOi8vaGFzdXJhLmlvL2p3dC9jbGFpbXMiOnsieC1oYXN1cmEtdXNlci1pZCI6IjAyOGM4YjQ4LWMzOWItNDU3OC05MTEwLTBiNWJkZDM4MjRkYSIsIngtaGFzdXJhLWRlZmF1bHQtcm9sZSI6InVzZXIiLCJ4LWhhc3VyYS1hbGxvd2VkLXJvbGVzIjpbInVzZXIiXSwieC1oYXN1cmEtdXNlci1ncm91cHMiOiJ7fSJ9LCJuYW1lIjoiSm9obiBIYW5zYXJpY2siLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJqb2huLmh1bW1lbEB3YWxsYXJvby5haSIsImdpdmVuX25hbWUiOiJKb2huIiwiZmFtaWx5X25hbWUiOiJIYW5zYXJpY2siLCJlbWFpbCI6ImpvaG4uaHVtbWVsQHdhbGxhcm9vLmFpIn0.gT-aE74iiDASRmIkFY3kghHUt3P-fsfWTe3hN-xn3AZMvPzDN1M0p6RCAXx9PbPti7MVizC_Bx0pQSHg6ekJo4mgKpGIUkyP53moSVcZDyT01mmMUsPQDkQtjE5hpYZIdW4_OtDM6WsBHwELyYr_Oezk67JM2mzMBOAG48hztyKZT3xZdZrA8ei-BASjDvnz736C354ivqB_UI1kFOpuF4zKQPkJuedJO6LIbdccpxzA2Vscueeu5wlo2R3h2s2JXDXUZSXibkEihaSJSYOEx5BeGt2JsIx5hb5ZvOo34m-1_Ykg7A7w3-ngySb_yVogQah4v133guviF4sxI8mzPg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection =wl.mlops().__dict__\n",
    "token = connection['token']\n",
    "token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API connection details can be retrieved through the Wallaroo client `mlops()` command.  This will display the connection URL, bearer token, and other information.  The bearer token is available for one hour before it expires.\n",
    "\n",
    "For this example, the API connection details will be retrieved, then used to submit an inference request through the external inference URL retrieved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile=\"./data/data_25k.arrow\"\n",
    "contentType=\"application/vnd.apache.arrow.file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 24.8M  100 20.0M  100 4874k  1926k   457k  0:00:10  0:00:10 --:--:-- 4735k2k 1537k   499k  0:00:13  0:00:09  0:00:04 3379k\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST {inference_url} -H \"Authorization: Bearer {token}\" -H \"Content-Type:{contentType}\" --data-binary @{dataFile} > curl_response.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1684357334487</td>\n",
       "      <td>{'banjori': [0.0015195821], 'corebot': [0.9829147500000001], 'cryptolocker': [0.012099549000000001], 'dircrypt': [4.7591115e-05], 'gozi': [2.0289428e-05], 'kraken': [0.00031977256999999996], 'locky': [0.011029262000000001], 'main': [0.997564], 'matsnu': [0.010341609], 'pykspa': [0.008038961], 'qakbot': [0.016155055], 'ramdo': [0.00623623], 'ramnit': [0.0009985747000000001], 'simda': [1.7933434e-26], 'suppobox': [1.388995e-27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1684357334487</td>\n",
       "      <td>{'banjori': [7.447196e-18], 'corebot': [6.7359245e-08], 'cryptolocker': [0.1708199], 'dircrypt': [1.3220122000000002e-09], 'gozi': [1.2758705999999999e-24], 'kraken': [0.22559543], 'locky': [0.34209849999999997], 'main': [0.99999994], 'matsnu': [0.3080186], 'pykspa': [0.1828217], 'qakbot': [3.8022549999999994e-11], 'ramdo': [0.2062254], 'ramnit': [0.15215826], 'simda': [1.1701982e-30], 'suppobox': [3.1514454e-38]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1684357334487</td>\n",
       "      <td>{'banjori': [2.8598648999999997e-21], 'corebot': [9.302004000000001e-08], 'cryptolocker': [0.04445298], 'dircrypt': [6.1637580000000004e-09], 'gozi': [8.3496755e-23], 'kraken': [0.48234479999999996], 'locky': [0.26332903], 'main': [1.0], 'matsnu': [0.29800338], 'pykspa': [0.22361776], 'qakbot': [1.5238920999999999e-06], 'ramdo': [0.32820392], 'ramnit': [0.029332489000000003], 'simda': [1.1995622e-31], 'suppobox': [0.0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1684357334487</td>\n",
       "      <td>{'banjori': [2.1387213e-15], 'corebot': [3.8817485e-10], 'cryptolocker': [0.045599736], 'dircrypt': [1.9090386e-07], 'gozi': [1.3140123e-25], 'kraken': [0.59542626], 'locky': [0.17374137], 'main': [0.9999996999999999], 'matsnu': [0.23151578], 'pykspa': [0.17591679999999998], 'qakbot': [1.0876152e-09], 'ramdo': [0.21832279999999998], 'ramnit': [0.0128692705], 'simda': [6.1588803e-28], 'suppobox': [1.4386237e-35]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1684357334487</td>\n",
       "      <td>{'banjori': [9.453342500000001e-15], 'corebot': [7.091151e-10], 'cryptolocker': [0.049815163], 'dircrypt': [5.2914135e-09], 'gozi': [7.4132087e-19], 'kraken': [1.5504574999999998e-13], 'locky': [1.079181e-15], 'main': [0.9999988999999999], 'matsnu': [1.5003075e-15], 'pykspa': [0.33075705], 'qakbot': [2.6258850000000004e-07], 'ramdo': [0.5036279], 'ramnit': [0.020393765], 'simda': [0.0], 'suppobox': [2.3292326e-38]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  \\\n",
       "0  1684357334487   \n",
       "1  1684357334487   \n",
       "2  1684357334487   \n",
       "3  1684357334487   \n",
       "4  1684357334487   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                              out  \n",
       "0  {'banjori': [0.0015195821], 'corebot': [0.9829147500000001], 'cryptolocker': [0.012099549000000001], 'dircrypt': [4.7591115e-05], 'gozi': [2.0289428e-05], 'kraken': [0.00031977256999999996], 'locky': [0.011029262000000001], 'main': [0.997564], 'matsnu': [0.010341609], 'pykspa': [0.008038961], 'qakbot': [0.016155055], 'ramdo': [0.00623623], 'ramnit': [0.0009985747000000001], 'simda': [1.7933434e-26], 'suppobox': [1.388995e-27]}  \n",
       "1               {'banjori': [7.447196e-18], 'corebot': [6.7359245e-08], 'cryptolocker': [0.1708199], 'dircrypt': [1.3220122000000002e-09], 'gozi': [1.2758705999999999e-24], 'kraken': [0.22559543], 'locky': [0.34209849999999997], 'main': [0.99999994], 'matsnu': [0.3080186], 'pykspa': [0.1828217], 'qakbot': [3.8022549999999994e-11], 'ramdo': [0.2062254], 'ramnit': [0.15215826], 'simda': [1.1701982e-30], 'suppobox': [3.1514454e-38]}  \n",
       "2         {'banjori': [2.8598648999999997e-21], 'corebot': [9.302004000000001e-08], 'cryptolocker': [0.04445298], 'dircrypt': [6.1637580000000004e-09], 'gozi': [8.3496755e-23], 'kraken': [0.48234479999999996], 'locky': [0.26332903], 'main': [1.0], 'matsnu': [0.29800338], 'pykspa': [0.22361776], 'qakbot': [1.5238920999999999e-06], 'ramdo': [0.32820392], 'ramnit': [0.029332489000000003], 'simda': [1.1995622e-31], 'suppobox': [0.0]}  \n",
       "3                 {'banjori': [2.1387213e-15], 'corebot': [3.8817485e-10], 'cryptolocker': [0.045599736], 'dircrypt': [1.9090386e-07], 'gozi': [1.3140123e-25], 'kraken': [0.59542626], 'locky': [0.17374137], 'main': [0.9999996999999999], 'matsnu': [0.23151578], 'pykspa': [0.17591679999999998], 'qakbot': [1.0876152e-09], 'ramdo': [0.21832279999999998], 'ramnit': [0.0128692705], 'simda': [6.1588803e-28], 'suppobox': [1.4386237e-35]}  \n",
       "4              {'banjori': [9.453342500000001e-15], 'corebot': [7.091151e-10], 'cryptolocker': [0.049815163], 'dircrypt': [5.2914135e-09], 'gozi': [7.4132087e-19], 'kraken': [1.5504574999999998e-13], 'locky': [1.079181e-15], 'main': [0.9999988999999999], 'matsnu': [1.5003075e-15], 'pykspa': [0.33075705], 'qakbot': [2.6258850000000004e-07], 'ramdo': [0.5036279], 'ramnit': [0.020393765], 'simda': [0.0], 'suppobox': [2.3292326e-38]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc_data_from_file =  pd.read_json('./curl_response.df', orient=\"records\")\n",
    "display(cc_data_from_file.head(5).loc[:, [\"time\",\"out\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeploy Pipeline\n",
    "\n",
    "When finished with our tests, we will undeploy the pipeline so we have the Kubernetes resources back for other tasks.  Note that if the deployment variable is unchanged pipeline.deploy() will restart the inference engine in the same configuration as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>azuremlsdkpipeline</td></tr><tr><th>created</th> <td>2023-05-17 21:01:46.655024+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-17 21:01:51.594226+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>28a7a5aa-5359-4320-842b-bad84258f7e4, e011272d-c22c-4b2d-ab9f-b17c60099434</td></tr><tr><th>steps</th> <td>azuremlsdkmodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'azuremlsdkpipeline', 'create_time': datetime.datetime(2023, 5, 17, 21, 1, 46, 655024, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'azuremlsdkmodel', 'version': 'fb4331da-9f14-4013-8ffb-4d994ab88eac', 'sha': 'd71d9ffc61aaac58c2b1ed70a2db13d1416fb9d3f5b891e5e4e2e97180fe22f8'}]}}]\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "wallaroosdk",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "wallaroosdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e951b583e3fbbcadfc15df61f9ed97fb9a76f59b2130f2cdf4d0033aa05e7e64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
