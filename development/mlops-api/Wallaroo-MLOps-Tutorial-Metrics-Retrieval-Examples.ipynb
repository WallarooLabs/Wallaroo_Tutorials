{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallaroo Admin Dashboard Metrics Retrieval Tutorial\n",
    "\n",
    "The following tutorial demonstrates using the Wallaroo MLOps API to retrieve Wallaroo metrics data.  These requests are compliant with Prometheus API endpoints.  \n",
    "\n",
    "This tutorial lists the metrics queries available and demonstrates how to perform each of the queries.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This tutorial assumes the following:\n",
    "\n",
    "* A Wallaroo Ops environment is installed.\n",
    "* The Wallaroo SDK is installed.  These examples use the Wallaroo SDK to generate the initial inferences information for the metrics requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Data Generation\n",
    "\n",
    "This part of the tutorial generates the inference results used for the rest of the tutorial.\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "import wallaroo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "A connection to Wallaroo is established via the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ccfraud-model\"\n",
    "model_file_name = \"./models/ccfraud.onnx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following queries are available for resource consumption.  Note where each request the `/v1/metrics/api/v1/query` endpoint.\n",
    "\n",
    "| Query Name | Description | Example Query | \n",
    "|---|---|---|\n",
    "| Total CPU Requested |   Number of CPUs requested in the Wallaroo cluster |`sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})` |\n",
    "| Total CPU allocated | Total number of available CPUs in the Wallaroo cluster |`sum(kube_node_status_capacity{resource=\"cpu\"})` | \n",
    "| Total GPU Requested | Number of GPUs requested in the Wallaroo cluster |`sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})` | \n",
    "| Total GPU Allocated | Total number of available GPUs in the Wallaroo cluster |`sum(kube_node_status_capacity{resource=~\"nvidia_com_gpu\\|qualcomm_com_qaic\"})` | \n",
    "| Total Memory Requested | Amount of memory requested in the Wallaroo cluster. | `sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})` | \n",
    "| Total Memory Allocated | Total amount of memory available in the Wallaroo cluster. | `sum(kube_node_status_capacity{resource=\"memory\"})` |\n",
    "| Total Inference Log Storage used | Amount of inference log storage used. | `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}` |\n",
    "| Total Inference Log Storage allocated | Total amount of inference log storage available. | `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}` |\n",
    "| Total Artifact Storage used | Amount of model and orchestration artifact storage used. | `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"minio\"}` |\n",
    "| Total Artifact Storage allocated | Total amount of model and orchestration artifact storage available. | `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"minio\"}` |\n",
    "| Average GPU usage over time | Average GPU usage over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average GPU requested over time | Average number of GPU requested over the defined time range in the Wallaroo cluster |  `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average CPU usage over time | Average CPU usage over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=”cpu”})[{duration}] {offset})` |\n",
    "|  Average CPU requested over time | Average CPU requests over the defined time range in the Wallaroo cluster | `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}] {offset})` |\n",
    "| Average Memory usage over time | Average memory usage over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Average Memory requests over time | Average memory requests over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Average pipelines CPU usage over time | Average CPU usage over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_usage{resource=\"cpu\"})[{duration}] {offset})` |\n",
    "| Average pipelines CPU requested over time | Average number of CPUs requested over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}] {offset})` |\n",
    "| Average pipelines GPU usage over time | Average GPU usage over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average pipelines GPU requested over time | Average number of GPUs requested over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average pipelines Mem usage over time | Average memory usage over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace) (wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Average pipelines Mem requested over time | Average amount of memory requested over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by (namespace)(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Pipeline inference log storage | Inference log storage used at the end of the defined time range for an individual Wallaroo pipeline |  `sum by(topic) (topic_bytes@{timestamp})` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for a Specified Time Range in the Past\n",
    "\n",
    "For queries that retrieve metric data between a range of dates in the past, the following example demonstrates how to use start date, end date, and the offset.\n",
    "\n",
    "This example uses three variables parameterized and inserted using the Python variable string replacement method:\n",
    "\n",
    "* `date_start`: The date starting the metric analysis period.\n",
    "* `date_end`: The end date of the metric analysis period.\n",
    "* `current_time`: The current time.\n",
    "\n",
    "These values are then converted into the following:\n",
    "\n",
    "* `duration`: The amount of time in seconds between `date_start` and `date_end`.\n",
    "* `offset`: The amount of time in seconds between `date_start` and `current_time`.\n",
    "\n",
    "The following example show retrieving the average CPU usage over a period of time for the dates 12/1/2025 to 12/3/2025.\n",
    "\n",
    "```bash\n",
    "# this is the URL to get this metric\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 12, 1, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 12, 3, 15, 59, 59))\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query_avg_cpu_usage = f'avg_over_time(sum(wallaroo_kube_pod_resource_usage{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_avg_cpu_usage = {\n",
    "    'query': query_avg_cpu_usage,\n",
    "}\n",
    "\n",
    "response_avg_cpu_usage = requests.get(query_url, headers=headers, params=params_avg_cpu_usage)\n",
    "\n",
    "\n",
    "if response_avg_cpu_usage.status_code == 200:\n",
    "    print(\"Average CPU usage over time:\")\n",
    "    display(response_avg_cpu_usage.json())\n",
    "else:\n",
    "    print(\"Failed to fetch Avg CPU usage data:\", response_avg_cpu_usage.status_code, response_avg_cpu_usage.text)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CPU Requested\n",
    "\n",
    "* Total CPU Requested\n",
    "* query \n",
    "* `sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})`\n",
    "* Number of CPUs requested in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866061.844, '14.406']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CPU allocated\n",
    "\n",
    "* Total CPU allocated\n",
    "* query\n",
    "* `sum(kube_node_status_capacity{resource=\"cpu\"})`\n",
    "* Total number of available CPUs in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.086, '48']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(kube_node_status_capacity{resource=\"cpu\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total GPU Requested\n",
    "\n",
    "* Total GPU Requested\n",
    "* query\n",
    "* `sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})`\n",
    "* Number of GPUs requested in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.314, '2']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total GPU Allocated\n",
    "\n",
    "* Total GPU Allocated\n",
    "* query\n",
    "* `sum(kube_node_status_capacity{resource=~\"nvidia_com_gpu|qualcomm_com_qaic\"})` \n",
    "* Total number of available GPUs in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.545, '5']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(kube_node_status_capacity{resource=~\"nvidia_com_gpu|qualcomm_com_qaic\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Memory Requested\n",
    "\n",
    "* Total Memory Requested\n",
    "* query\n",
    "* `sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})`\n",
    "* Amount of memory requested in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.778, '32220643328']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Memory Allocated\n",
    "\n",
    "* Total Memory Allocated\n",
    "* query\n",
    "* `sum(kube_node_status_capacity{resource=\"memory\"})`\n",
    "* Total amount of memory available in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.982, '197850009600']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(kube_node_status_capacity{resource=\"memory\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Inference Log Storage used\n",
    "\n",
    "* Total Inference Log Storage used\n",
    "* query\n",
    "* `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}`\n",
    "* Amount of inference log storage used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_used_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'plateau-managed-disk',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.272, '23963860992']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Inference Log Storage allocated\n",
    "\n",
    "* Total Inference Log Storage allocated\n",
    "* query\n",
    "* `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}`\n",
    "* Total amount of inference log storage available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_capacity_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'plateau-managed-disk',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.494, '210779168768']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Artifact Storage used\n",
    "\n",
    "* Total Artifact Storage used\n",
    "* query\n",
    "* `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"minio\"}`\n",
    "* Amount of model and orchestration artifact storage used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_capacity_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'minio',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.689, '791522189312']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"minio\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Artifact Storage allocated\n",
    "\n",
    "* Total Artifact Storage allocated\n",
    "* query\n",
    "* `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"minio\"}`\n",
    "* Total amount of model and orchestration artifact storage available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_used_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'minio',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.926, '623442173952']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"minio\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average GPU usage over time\n",
    "\n",
    "* Average GPU usage over time\n",
    "* Endpoint: `query`\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average GPU usage over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973184.648, '2']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {duration}s)'\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average GPU requested over time\n",
    "\n",
    "* Average GPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average number of GPU requested over the defined time range in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973243.038, '1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average CPU usage over time\n",
    "\n",
    "* Average CPU usage over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average CPU usage over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {},\n",
       "    'value': [1764973280.342, '0.12934791422175926']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_usage{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average CPU requested over time\n",
    "\n",
    "* Average CPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average CPU requests over the defined time range in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973311.064, '7.720675925925926']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Memory usage over time\n",
    "\n",
    "* Average Memory usage over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average memory usage over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973398.031, '6001859973.583539']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_usage{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Memory requests over time\n",
    "\n",
    "* Average Memory requests over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average memory requests over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973426.54, '18013261854.34074']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines CPU usage over time\n",
    "\n",
    "* Average pipelines CPU usage over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_usage{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average CPU usage over the defined time range for an individual Wallaroo pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973580.279, '0.00932672794025501']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973580.279, '0.10730162002134773']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973580.279, '0.011238805135648148']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973580.279, '0.00949052053616255']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_usage{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines CPU requested over time\n",
    "\n",
    "* Average pipelines CPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average number of CPUs requested over the defined time range for an individual Wallaroo pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973599.822, '0.10392870134594398']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973599.822, '3.2560000000000002']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973599.822, '4.35']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973599.822, '0.1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines GPU usage over time\n",
    "\n",
    "* Average pipelines GPU usage over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average GPU usage over the defined time range for an individual Wallaroo pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973624.499, '1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines GPU requested over time\n",
    "\n",
    "* Average pipelines GPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average number of GPUs requested over the defined time range for an individual Wallaroo pipeline. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973660.241, '1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines Mem usage over time\n",
    "\n",
    "* Average pipelines Mem usage over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace) (wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average memory usage over the defined time range for an individual Wallaroo pipeline. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973697.645, '16573120.303096538']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973697.645, '5039891965.050206']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973697.645, '940454186.7720164']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973697.645, '19173635.792592593']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace) (wallaroo_kube_pod_resource_usage{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines Mem requested over time\n",
    "\n",
    "* Average pipelines Mem requested over time\n",
    "* query\n",
    "* `avg_over_time(sum by (namespace)(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Inference log storage used at the end of the defined time range for an individual Wallaroo pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973721.216, '139498425.49508196']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973721.216, '8061452288']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973721.216, '9797894144']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973721.216, '134217728']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by (namespace)(wallaroo_kube_pod_resource_requests{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline inference log storage\n",
    "\n",
    "* Pipeline inference log storage\n",
    "* query\n",
    "* `avg_over_time(sum by(topic) (topic_bytes)[{duration}:] offset {offset})`\n",
    "* Inference log storage used at the end of the defined time range for an individual Wallaroo pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum by(topic) (topic_bytes@1764111599)\n",
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'topic': 'workspace-121-pipeline-whisper-hf-byop-jcw-inference'},\n",
       "    'value': [1765409252.95, '0']},\n",
       "   {'metric': {'topic': 'workspace-1444-pipeline-dlrm-click-prediction-inference'},\n",
       "    'value': [1765409252.95, '4282479']},\n",
       "   {'metric': {'topic': 'workspace-1526-pipeline-ma-consumptionchanges-stage-inference'},\n",
       "    'value': [1765409252.95, '1148670']},\n",
       "   {'metric': {'topic': 'workspace-1529-pipeline-rum-assay-nan-jcw-inference'},\n",
       "    'value': [1765409252.95, '2041174']},\n",
       "   {'metric': {'topic': 'workspace-1786-pipeline-ai-screening-inference'},\n",
       "    'value': [1765409252.95, '2817923']},\n",
       "   {'metric': {'topic': 'workspace-42-pipeline-retail-inv-tracker-edge-obs-inference'},\n",
       "    'value': [1765409252.95, '3500604']},\n",
       "   {'metric': {'topic': 'workspace-71-pipeline-assay-demonstration-tutorial-jcw-inference'},\n",
       "    'value': [1765409252.95, '60325542']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-predictor-drift-inference'},\n",
       "    'value': [1765409252.95, '77898428']},\n",
       "   {'metric': {'topic': 'workspace-87-pipeline-whisper-hf-byop-replicatest-inference'},\n",
       "    'value': [1765409252.95, '38852525']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "# This example uses the data_end period to get sizes at a specific point in time\n",
    "timestamp = int(data_end.timestamp())\n",
    "\n",
    "# Other example: now() to retrieve sizes for the current time\n",
    "# timestamp = int(datetime.datetime.now(selected_timezone).timestamp())\n",
    "\n",
    "# Get the total size of all the pipeline files by pipeline AND pipeline_version\n",
    "query = f'sum by(topic) (topic_bytes@{timestamp})'\n",
    "\n",
    "print(query)\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk2025.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
