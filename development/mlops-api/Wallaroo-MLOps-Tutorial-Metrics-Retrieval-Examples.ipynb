{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallaroo Admin Dashboard Metrics Retrieval Tutorial\n",
    "\n",
    "The following tutorial demonstrates using the Wallaroo MLOps API to retrieve Wallaroo metrics data.  These requests are compliant with Prometheus API endpoints.  \n",
    "\n",
    "This tutorial lists the metrics queries available and demonstrates how to perform each of the queries.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This tutorial assumes the following:\n",
    "\n",
    "* A Wallaroo Ops environment is installed.\n",
    "* The Wallaroo SDK is installed.  These examples use the Wallaroo SDK to generate the initial inferences information for the metrics requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Data Generation\n",
    "\n",
    "This part of the tutorial generates the inference results used for the rest of the tutorial.\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "import wallaroo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "A connection to Wallaroo is established via the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ccfraud-model\"\n",
    "model_file_name = \"./models/ccfraud.onnx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following queries are available for resource consumption.  Note where each request the `/v1/metrics/api/v1/query` endpoint.\n",
    "\n",
    "| Query Name | Description | Example Query | \n",
    "|---|---|---|\n",
    "| Total CPU Requested |   Number of CPUs requested in the Wallaroo cluster |`sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})` |\n",
    "| Total CPU allocated | Total number of available CPUs in the Wallaroo cluster |`sum(kube_node_status_capacity{resource=\"cpu\"})` | \n",
    "| Total GPU Requested | Number of GPUs requested in the Wallaroo cluster |`sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})` | \n",
    "| Total GPU Allocated | Total number of available GPUs in the Wallaroo cluster |`sum(kube_node_status_capacity{resource=~\"nvidia_com_gpu\\|qualcomm_com_qaic\"})` | \n",
    "| Total Memory Requested | Amount of memory requested in the Wallaroo cluster. | `sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})` | \n",
    "| Total Memory Allocated | Total amount of memory available in the Wallaroo cluster. | `sum(kube_node_status_capacity{resource=\"memory\"})` |\n",
    "| Total Inference Log Storage used | Amount of inference log storage used. | `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}` |\n",
    "| Total Inference Log Storage allocated | Total amount of inference log storage available. | `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}` |\n",
    "| Total Artifact Storage used | Amount of model and orchestration artifact storage used. | `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"minio\"}` |\n",
    "| Total Artifact Storage allocated | Total amount of model and orchestration artifact storage available. | `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"minio\"}` |\n",
    "| Average GPU usage over time | Average GPU usage over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average GPU requested over time | Average number of GPU requested over the defined time range in the Wallaroo cluster |  `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average CPU usage over time | Average CPU usage over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=”cpu”})[{duration}] {offset})` |\n",
    "|  Average CPU requested over time | Average CPU requests over the defined time range in the Wallaroo cluster | `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}] {offset})` |\n",
    "| Average Memory usage over time | Average memory usage over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Average Memory requests over time | Average memory requests over the defined time range in the Wallaroo cluster. | `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Average pipelines CPU usage over time | Average CPU usage over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_usage{resource=\"cpu\"})[{duration}] {offset})` |\n",
    "| Average pipelines CPU requested over time | Average number of CPUs requested over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}] {offset})` |\n",
    "| Average pipelines GPU usage over time | Average GPU usage over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average pipelines GPU requested over time | Average number of GPUs requested over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}] {offset})` |\n",
    "| Average pipelines Mem usage over time | Average memory usage over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by(namespace) (wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Average pipelines Mem requested over time | Average amount of memory requested over the defined time range for an individual Wallaroo pipeline. | `avg_over_time(sum by (namespace)(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}] {offset})` |\n",
    "| Pipeline inference log storage | Average inference log storage used over the defined time range for an individual Wallaroo pipeline |  `sum by(topic) (topic_bytes@{timestamp})` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for a Specified Time Range in the Past\n",
    "\n",
    "For queries that retrieve metric data between a range of dates in the past, the following example demonstrates how to use start date, end date, and the offset.\n",
    "\n",
    "This example uses three variables parameterized and inserted using the Python variable string replacement method:\n",
    "\n",
    "* `date_start`: The date starting the metric analysis period.\n",
    "* `date_end`: The end date of the metric analysis period.\n",
    "* `current_time`: The current time.\n",
    "\n",
    "These values are then converted into the following:\n",
    "\n",
    "* `duration`: The amount of time in seconds between `date_start` and `date_end`.\n",
    "* `offset`: The amount of time in seconds between `date_start` and `current_time`.\n",
    "\n",
    "The following example show retrieving the average CPU usage over a period of time for the dates 12/1/2025 to 12/3/2025.\n",
    "\n",
    "```bash\n",
    "# this is the URL to get this metric\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 12, 1, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 12, 3, 15, 59, 59))\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query_avg_cpu_usage = f'avg_over_time(sum(wallaroo_kube_pod_resource_usage{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_avg_cpu_usage = {\n",
    "    'query': query_avg_cpu_usage,\n",
    "}\n",
    "\n",
    "response_avg_cpu_usage = requests.get(query_url, headers=headers, params=params_avg_cpu_usage)\n",
    "\n",
    "\n",
    "if response_avg_cpu_usage.status_code == 200:\n",
    "    print(\"Average CPU usage over time:\")\n",
    "    display(response_avg_cpu_usage.json())\n",
    "else:\n",
    "    print(\"Failed to fetch Avg CPU usage data:\", response_avg_cpu_usage.status_code, response_avg_cpu_usage.text)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CPU Requested\n",
    "\n",
    "* Total CPU Requested\n",
    "* query \n",
    "* `sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})`\n",
    "* Number of CPUs requested in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866061.844, '14.406']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CPU allocated\n",
    "\n",
    "* Total CPU allocated\n",
    "* query\n",
    "* `sum(kube_node_status_capacity{resource=\"cpu\"})`\n",
    "* Total number of available CPUs in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.086, '48']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(kube_node_status_capacity{resource=\"cpu\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total GPU Requested\n",
    "\n",
    "* Total GPU Requested\n",
    "* query\n",
    "* `sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})`\n",
    "* Number of GPUs requested in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.314, '2']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total GPU Allocated\n",
    "\n",
    "* Total GPU Allocated\n",
    "* query\n",
    "* `sum(kube_node_status_capacity{resource=~\"nvidia_com_gpu|qualcomm_com_qaic\"})` \n",
    "* Total number of available GPUs in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.545, '5']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(kube_node_status_capacity{resource=~\"nvidia_com_gpu|qualcomm_com_qaic\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Memory Requested\n",
    "\n",
    "* Total Memory Requested\n",
    "* query\n",
    "* `sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})`\n",
    "* Amount of memory requested in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.778, '32220643328']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Memory Allocated\n",
    "\n",
    "* Total Memory Allocated\n",
    "* query\n",
    "* `sum(kube_node_status_capacity{resource=\"memory\"})`\n",
    "* Total amount of memory available in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764866062.982, '197850009600']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'sum(kube_node_status_capacity{resource=\"memory\"})'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Inference Log Storage used\n",
    "\n",
    "* Total Inference Log Storage used\n",
    "* query\n",
    "* `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}`\n",
    "* Amount of inference log storage used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_used_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'plateau-managed-disk',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.272, '23963860992']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Inference Log Storage allocated\n",
    "\n",
    "* Total Inference Log Storage allocated\n",
    "* query\n",
    "* `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}`\n",
    "* Total amount of inference log storage available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_capacity_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'plateau-managed-disk',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.494, '210779168768']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"plateau-managed-disk\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Artifact Storage used\n",
    "\n",
    "* Total Artifact Storage used\n",
    "* query\n",
    "* `kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"minio\"}`\n",
    "* Amount of model and orchestration artifact storage used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_capacity_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'minio',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.689, '791522189312']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=\"minio\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Artifact Storage allocated\n",
    "\n",
    "* Total Artifact Storage allocated\n",
    "* query\n",
    "* `kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"minio\"}`\n",
    "* Total amount of model and orchestration artifact storage available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'__name__': 'kubelet_volume_stats_used_bytes',\n",
       "     'beta_kubernetes_io_arch': 'amd64',\n",
       "     'beta_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'beta_kubernetes_io_os': 'linux',\n",
       "     'cloud_google_com_gke_boot_disk': 'pd-balanced',\n",
       "     'cloud_google_com_gke_container_runtime': 'containerd',\n",
       "     'cloud_google_com_gke_cpu_scaling_level': '8',\n",
       "     'cloud_google_com_gke_logging_variant': 'DEFAULT',\n",
       "     'cloud_google_com_gke_max_pods_per_node': '110',\n",
       "     'cloud_google_com_gke_memory_gb_scaling_level': '32',\n",
       "     'cloud_google_com_gke_nodepool': 'persistent',\n",
       "     'cloud_google_com_gke_os_distribution': 'cos',\n",
       "     'cloud_google_com_gke_provisioning': 'standard',\n",
       "     'cloud_google_com_gke_stack_type': 'IPV4',\n",
       "     'cloud_google_com_machine_family': 'e2',\n",
       "     'cloud_google_com_private_node': 'false',\n",
       "     'failure_domain_beta_kubernetes_io_region': 'us-central1',\n",
       "     'failure_domain_beta_kubernetes_io_zone': 'us-central1-c',\n",
       "     'instance': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'job': 'kubernetes-nodes',\n",
       "     'kubernetes_io_arch': 'amd64',\n",
       "     'kubernetes_io_hostname': 'gke-autoscale-uat-gcp-persistent-e78fe29f-osra',\n",
       "     'kubernetes_io_os': 'linux',\n",
       "     'namespace': 'wallaroo',\n",
       "     'node_kubernetes_io_instance_type': 'e2-standard-8',\n",
       "     'persistentvolumeclaim': 'minio',\n",
       "     'topology_gke_io_zone': 'us-central1-c',\n",
       "     'topology_kubernetes_io_region': 'us-central1',\n",
       "     'topology_kubernetes_io_zone': 'us-central1-c',\n",
       "     'wallaroo_ai_node_purpose': 'persistent'},\n",
       "    'value': [1764866063.926, '623442173952']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "query = 'kubelet_volume_stats_used_bytes{persistentvolumeclaim=\"minio\"}'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average GPU usage over time\n",
    "\n",
    "* Average GPU usage over time\n",
    "* Endpoint: `query`\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average GPU usage over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973184.648, '2']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {duration}s)'\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average GPU requested over time\n",
    "\n",
    "* Average GPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average number of GPU requested over the defined time range in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973243.038, '1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average CPU usage over time\n",
    "\n",
    "* Average CPU usage over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average CPU usage over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {},\n",
       "    'value': [1764973280.342, '0.12934791422175926']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_usage{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average CPU requested over time\n",
    "\n",
    "* Average CPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average CPU requests over the defined time range in the Wallaroo cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973311.064, '7.720675925925926']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Memory usage over time\n",
    "\n",
    "* Average Memory usage over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average memory usage over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973398.031, '6001859973.583539']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_usage{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Memory requests over time\n",
    "\n",
    "* Average Memory requests over time\n",
    "* query\n",
    "* `avg_over_time(sum(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average memory requests over the defined time range in the Wallaroo cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {}, 'value': [1764973426.54, '18013261854.34074']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum(wallaroo_kube_pod_resource_requests{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines CPU usage over time\n",
    "\n",
    "* Average pipelines CPU usage over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_usage{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average CPU usage over the defined time range for an individual Wallaroo pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973580.279, '0.00932672794025501']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973580.279, '0.10730162002134773']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973580.279, '0.011238805135648148']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973580.279, '0.00949052053616255']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_usage{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines CPU requested over time\n",
    "\n",
    "* Average pipelines CPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=\"cpu\"})[{duration}:] offset {offset})`\n",
    "* Average number of CPUs requested over the defined time range for an individual Wallaroo pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973599.822, '0.10392870134594398']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973599.822, '3.2560000000000002']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973599.822, '4.35']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973599.822, '0.1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{{resource=\"cpu\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines GPU usage over time\n",
    "\n",
    "* Average pipelines GPU usage over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu\\|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average GPU usage over the defined time range for an individual Wallaroo pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973624.499, '1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines GPU requested over time\n",
    "\n",
    "* Average pipelines GPU requested over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"})[{duration}:] offset {offset})`\n",
    "* Average number of GPUs requested over the defined time range for an individual Wallaroo pipeline. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973660.241, '1']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace)(wallaroo_kube_pod_resource_requests{{resource=~\"nvidia.com/gpu|qualcomm.com/qaic\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines Mem usage over time\n",
    "\n",
    "* Average pipelines Mem usage over time\n",
    "* query\n",
    "* `avg_over_time(sum by(namespace) (wallaroo_kube_pod_resource_usage{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average memory usage over the defined time range for an individual Wallaroo pipeline. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973697.645, '16573120.303096538']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973697.645, '5039891965.050206']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973697.645, '940454186.7720164']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973697.645, '19173635.792592593']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by(namespace) (wallaroo_kube_pod_resource_usage{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pipelines Mem requested over time\n",
    "\n",
    "* Average pipelines Mem requested over time\n",
    "* query\n",
    "* `avg_over_time(sum by (namespace)(wallaroo_kube_pod_resource_requests{resource=\"memory\"})[{duration}:] offset {offset})`\n",
    "* Average amount of memory requested over the defined time range for an individual Wallaroo pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'namespace': 'tinyllama-openai-414'},\n",
       "    'value': [1764973721.216, '139498425.49508196']},\n",
       "   {'metric': {'namespace': 'wallaroo'},\n",
       "    'value': [1764973721.216, '8061452288']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-jcw-48'},\n",
       "    'value': [1764973721.216, '9797894144']},\n",
       "   {'metric': {'namespace': 'whisper-hf-byop-replicatest-53'},\n",
       "    'value': [1764973721.216, '134217728']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "current_time = datetime.datetime.now(selected_timezone)\n",
    "\n",
    "duration = int((data_end-data_start).total_seconds())\n",
    "offset = int((current_time-data_start).total_seconds())\n",
    "\n",
    "\n",
    "query = f'avg_over_time(sum by (namespace)(wallaroo_kube_pod_resource_requests{{resource=\"memory\"}})[{duration}s:] offset {offset}s)'\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline inference log storage\n",
    "\n",
    "* Pipeline inference log storage\n",
    "* query\n",
    "* `avg_over_time(sum by(topic) (topic_bytes)[{duration}:] offset {offset})`\n",
    "* Average inference log storage used over the defined time range for an individual Wallaroo pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum by(topic) (topic_bytes@1765407963)\n",
      "Query Response:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'data': {'resultType': 'vector',\n",
       "  'result': [{'metric': {'topic': 'workspace-124-pipeline-replica-scaling-static-inference'},\n",
       "    'value': [1765407963.993, '498288767']},\n",
       "   {'metric': {'topic': 'workspace-67-pipeline-llama-31-8b-pipeline-inference'},\n",
       "    'value': [1765407963.993, '47138']},\n",
       "   {'metric': {'topic': 'workspace-1441-pipeline-summarizer-listener-yns-inference'},\n",
       "    'value': [1765407963.993, '6475']},\n",
       "   {'metric': {'topic': 'workspace-1618-pipeline-parallel-infer-aloha-pipeline-201371-inference'},\n",
       "    'value': [1765407963.993, '35958']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacpp-pipeyns-inference'},\n",
       "    'value': [1765407963.993, '5119']},\n",
       "   {'metric': {'topic': 'workspace-1613-pipeline-sleep-passthrough-pipe-inference'},\n",
       "    'value': [1765407963.993, '5071']},\n",
       "   {'metric': {'topic': 'workspace-1444-pipeline-dlrm-click-prediction-inference'},\n",
       "    'value': [1765407963.993, '4282479']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacpp-pipeyns-arm-inference'},\n",
       "    'value': [1765407963.993, '5119']},\n",
       "   {'metric': {'topic': 'workspace-128-pipeline-assay-demonstration-tutorial-jcw-2-inference'},\n",
       "    'value': [1765407963.993, '972971']},\n",
       "   {'metric': {'topic': 'workspace-1698-pipeline-edge-observability-pipeline-inference'},\n",
       "    'value': [1765407963.993, '350747']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llama-31-8b-vllm-ynsv5-inference'},\n",
       "    'value': [1765407963.993, '6015']},\n",
       "   {'metric': {'topic': 'workspace-1752-pipeline-logging-pipeline-236223-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1598-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1437-pipeline-assay-demonstration-tutorial-4551-inference'},\n",
       "    'value': [1765407963.993, '9123443']},\n",
       "   {'metric': {'topic': 'workspace-1651-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-64-pipeline-llama-8b-inference'},\n",
       "    'value': [1765407963.993, '39039']},\n",
       "   {'metric': {'topic': 'workspace-1757-pipeline-logging-pipeline-153932-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1529-pipeline-rum-assay-nan-jcw-inference'},\n",
       "    'value': [1765407963.993, '2041174']},\n",
       "   {'metric': {'topic': 'workspace-1518-pipeline-deployment-status-ccfraud-pipeline-653166-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-87-pipeline-whisper-hf-byop-testshared-inference'},\n",
       "    'value': [1765407963.993, '1216831']},\n",
       "   {'metric': {'topic': 'workspace-1635-pipeline-python-onnx-pipeline-inference'},\n",
       "    'value': [1765407963.993, '7003']},\n",
       "   {'metric': {'topic': 'workspace-1520-pipeline-deployment-status-ccfraud-pipeline-547909-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1436-pipeline-deployment-status-ccfraud-pipeline-355413-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1581-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-65-pipeline-preethi-retail-inv-tracker-edge-obs-inference'},\n",
       "    'value': [1765407963.993, '497502']},\n",
       "   {'metric': {'topic': 'workspace-59-pipeline-ccfraudpipeline-inference'},\n",
       "    'value': [1765407963.993, '43655937']},\n",
       "   {'metric': {'topic': 'workspace-1685-pipeline-tinyllama-openai-inference'},\n",
       "    'value': [1765407963.993, '5615']},\n",
       "   {'metric': {'topic': 'workspace-108-pipeline-hf-summarization-pipeline-inference'},\n",
       "    'value': [1765407963.993, '8687']},\n",
       "   {'metric': {'topic': 'workspace-17-pipeline-tinyllama3-inference'},\n",
       "    'value': [1765407963.993, '9215']},\n",
       "   {'metric': {'topic': 'workspace-1744-pipeline-logging-no-validation-pipeline-140699-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-llama-31-8b-vllm-demo-inference'},\n",
       "    'value': [1765407963.993, '6463']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-byop-tinyllama-demo-yns2-inference'},\n",
       "    'value': [1765407963.993, '6079']},\n",
       "   {'metric': {'topic': 'workspace-1492-pipeline-deployment-status-ccfraud-pipeline-204102-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1790-pipeline-ai-screening-inference'},\n",
       "    'value': [1765407963.993, '35240974']},\n",
       "   {'metric': {'topic': 'workspace-1530-pipeline-rum-assay-inference-failures'},\n",
       "    'value': [1765407963.993, '155199']},\n",
       "   {'metric': {'topic': 'pipeline-assay-demonstration-tutorial-jcw-inference'},\n",
       "    'value': [1765407963.993, '62640374']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-llama-31-8b-vllm-c1000-inference'},\n",
       "    'value': [1765407963.993, '3544151']},\n",
       "   {'metric': {'topic': 'workspace-1640-pipeline-deployment-status-ccfraud-pipeline-641845-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1451-pipeline-keras-sequential-single-io-inference'},\n",
       "    'value': [1765407963.993, '19998']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-rag-cb-inference'},\n",
       "    'value': [1765407963.993, '148263']},\n",
       "   {'metric': {'topic': 'workspace-1761-pipeline-logging-pipeline-839648-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1574-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1578-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1688-pipeline-ab-testing-pipeline-721493-inference'},\n",
       "    'value': [1765407963.993, '11098']},\n",
       "   {'metric': {'topic': 'workspace-1713-pipeline-metrics-retrieval-tutorial-pipeline-inference'},\n",
       "    'value': [1765407963.993, '1175661644']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-with-challengers-inference'},\n",
       "    'value': [1765407963.993, '997398']},\n",
       "   {'metric': {'topic': 'workspace-1577-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1668-pipeline-yolo8demonstration-inference'},\n",
       "    'value': [1765407963.993, '11305230']},\n",
       "   {'metric': {'topic': 'workspace-1434-pipeline-whse-a-demand-forecast-inference'},\n",
       "    'value': [1765407963.993, '18907']},\n",
       "   {'metric': {'topic': 'workspace-1582-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1687-pipeline-replace-model-ccfraud-pipeline-548655-inference'},\n",
       "    'value': [1765407963.993, '10170']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-predictor-drift-inference-failures'},\n",
       "    'value': [1765407963.993, '5015086']},\n",
       "   {'metric': {'topic': 'workspace-1651-pipeline-empty-config-lazyadam-pipeline-410913-inference'},\n",
       "    'value': [1765407963.993, '11359']},\n",
       "   {'metric': {'topic': 'workspace-1677-pipeline-clip-demo-jcw-inference'},\n",
       "    'value': [1765407963.993, '36887754']},\n",
       "   {'metric': {'topic': 'workspace-1445-pipeline-retail-inv-tracker-jetson-inference'},\n",
       "    'value': [1765407963.993, '21473']},\n",
       "   {'metric': {'topic': 'workspace-1696-pipeline-assay-demonstration-tutorial-pk-inference'},\n",
       "    'value': [1765407963.993, '10746990']},\n",
       "   {'metric': {'topic': 'workspace-1707-pipeline-mobilenetpipeline-inference'},\n",
       "    'value': [1765407963.993, '7915']},\n",
       "   {'metric': {'topic': 'workspace-1644-pipeline-replace-model-ccfraud-pipeline-374815-inference'},\n",
       "    'value': [1765407963.993, '10170']},\n",
       "   {'metric': {'topic': 'workspace-1747-pipeline-deployment-status-ccfraud-pipeline-669117-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-scale-test-ya-inference'},\n",
       "    'value': [1765407963.993, '18493']},\n",
       "   {'metric': {'topic': 'workspace-1459-pipeline-llamacpp-pipe-ynstest-inference'},\n",
       "    'value': [1765407963.993, '5311']},\n",
       "   {'metric': {'topic': 'workspace-1775-pipeline-logging-pipeline-375742-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-1640-pipeline-deploy-specific-version-737646-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-87-pipeline-whisper-hf-byop-inference'},\n",
       "    'value': [1765407963.993, '3646710']},\n",
       "   {'metric': {'topic': 'workspace-1655-pipeline-auto-packaging-byop-extra-reqs-591104-inference'},\n",
       "    'value': [1765407963.993, '6879']},\n",
       "   {'metric': {'topic': 'workspace-1776-pipeline-logging-pipeline-949260-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-11-pipeline-passthrough-vc-test-inference'},\n",
       "    'value': [1765407963.993, '60555542']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacpp-pipeyns-openvino1-inference'},\n",
       "    'value': [1765407963.993, '5247']},\n",
       "   {'metric': {'topic': 'workspace-1453-pipeline-vgg16-clustering-pipeline-inference'},\n",
       "    'value': [1765407963.993, '54315']},\n",
       "   {'metric': {'topic': 'workspace-1641-pipeline-replace-model-ccfraud-pipeline-594544-inference'},\n",
       "    'value': [1765407963.993, '10170']},\n",
       "   {'metric': {'topic': 'workspace-1643-pipeline-ab-testing-pipeline-931264-inference'},\n",
       "    'value': [1765407963.993, '11098']},\n",
       "   {'metric': {'topic': 'workspace-1700-pipeline-assay-demonstration-tutorial-inference'},\n",
       "    'value': [1765407963.993, '10678']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-with-challengers-inference-failures'},\n",
       "    'value': [1765407963.993, '21758']},\n",
       "   {'metric': {'topic': 'workspace-21-pipeline-mac-keras-single-io-example-pipeline-inference'},\n",
       "    'value': [1765407963.993, '1367856']},\n",
       "   {'metric': {'topic': 'workspace-1459-pipeline-byopllamacpp-safeguards-pegasi-single-3-inference'},\n",
       "    'value': [1765407963.993, '5131']},\n",
       "   {'metric': {'topic': 'workspace-1434-pipeline-whse-c-demand-forecast-inference'},\n",
       "    'value': [1765407963.993, '21595']},\n",
       "   {'metric': {'topic': 'workspace-1579-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llama-31-8b-vllm-demo1-inference'},\n",
       "    'value': [1765407963.993, '12094']},\n",
       "   {'metric': {'topic': 'workspace-1786-pipeline-ai-screening-inference'},\n",
       "    'value': [1765407963.993, '2817923']},\n",
       "   {'metric': {'topic': 'workspace-42-pipeline-retail-inv-tracker-edge-obs-inference'},\n",
       "    'value': [1765407963.993, '3500604']},\n",
       "   {'metric': {'topic': 'workspace-1693-pipeline-tinyllama-openai-inference'},\n",
       "    'value': [1765407963.993, '24734']},\n",
       "   {'metric': {'topic': 'workspace-1772-pipeline-shadow-pipeline-801466-inference'},\n",
       "    'value': [1765407963.993, '5903']},\n",
       "   {'metric': {'topic': 'workspace-1604-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1517-pipeline-deployment-status-ccfraud-pipeline-856429-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-llama-31-8b-vllm-demo-2-inference'},\n",
       "    'value': [1765407963.993, '896447']},\n",
       "   {'metric': {'topic': 'workspace-1605-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1452-pipeline-keras-sequential-single-io-jcw-inference'},\n",
       "    'value': [1765407963.993, '9999']},\n",
       "   {'metric': {'topic': 'workspace-1740-pipeline-auto-packaging-byop-llamacpp-376166-inference'},\n",
       "    'value': [1765407963.993, '4991']},\n",
       "   {'metric': {'topic': 'workspace-1515-pipeline-deployment-status-ccfraud-pipeline-528122-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1636-pipeline-python-onnx-pipeline-inference'},\n",
       "    'value': [1765407963.993, '7003']},\n",
       "   {'metric': {'topic': 'workspace-1542-pipeline-assay-demonstration-tutorial-inference'},\n",
       "    'value': [1765407963.993, '394449']},\n",
       "   {'metric': {'topic': 'workspace-1772-pipeline-logging-pipeline-566299-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacpp-pipeyns-akmel-inference'},\n",
       "    'value': [1765407963.993, '4607']},\n",
       "   {'metric': {'topic': 'workspace-1614-pipeline-parallel-infer-aloha-pipeline-126534-inference'},\n",
       "    'value': [1765407963.993, '31862']},\n",
       "   {'metric': {'topic': 'workspace-1743-pipeline-resident-signal-staging-pipeline-inference'},\n",
       "    'value': [1765407963.993, '106241054']},\n",
       "   {'metric': {'topic': 'workspace-1760-pipeline-logging-pipeline-278379-inference'},\n",
       "    'value': [1765407963.993, '15253']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llama-31-8b-vllm-demo-swap3-inference'},\n",
       "    'value': [1765407963.993, '6015']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-predictor-drift-inference'},\n",
       "    'value': [1765407963.993, '77898428']},\n",
       "   {'metric': {'topic': 'workspace-1688-pipeline-shadow-pipeline-554344-inference'},\n",
       "    'value': [1765407963.993, '5903']},\n",
       "   {'metric': {'topic': 'workspace-1572-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1679-pipeline-auto-packaging-keras-multi-io-pipeline-310172-inference'},\n",
       "    'value': [1765407963.993, '9487']},\n",
       "   {'metric': {'topic': 'workspace-54-pipeline-llama-cpp-inference'},\n",
       "    'value': [1765407963.993, '597110']},\n",
       "   {'metric': {'topic': 'workspace-1753-pipeline-logging-pipeline-930939-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1571-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1605-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1444-pipeline-recommender-ab-test-inference'},\n",
       "    'value': [1765407963.993, '548303']},\n",
       "   {'metric': {'topic': 'workspace-1651-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1459-pipeline-byopllamacpp-safeguards-pegasi-multi-inference'},\n",
       "    'value': [1765407963.993, '12958']},\n",
       "   {'metric': {'topic': 'workspace-1621-pipeline-sleep-passthrough-pipe-inference'},\n",
       "    'value': [1765407963.993, '5071']},\n",
       "   {'metric': {'topic': 'workspace-1601-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1671-pipeline-edge-hf-summarization-inference'},\n",
       "    'value': [1765407963.993, '21261']},\n",
       "   {'metric': {'topic': 'workspace-1504-pipeline-deployment-status-ccfraud-pipeline-993757-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-87-pipeline-whisper-hf-arm-inference'},\n",
       "    'value': [1765407963.993, '1221950']},\n",
       "   {'metric': {'topic': 'workspace-11-pipeline-passthrough-vc-flatten-reshape-inference'},\n",
       "    'value': [1765407963.993, '20168839']},\n",
       "   {'metric': {'topic': 'workspace-1754-pipeline-logging-pipeline-909582-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1696-pipeline-assay-demonstration-tutorial-pk-2-inference'},\n",
       "    'value': [1765407963.993, '3472155']},\n",
       "   {'metric': {'topic': 'workspace-1670-pipeline-pt-unet-inference'},\n",
       "    'value': [1765407963.993, '1059390']},\n",
       "   {'metric': {'topic': 'workspace-1762-pipeline-logging-pipeline-332650-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-1522-pipeline-deployment-status-ccfraud-pipeline-241064-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1640-pipeline-redeploy-ccfraud-pipeline-805593-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1649-pipeline-shadow-pipeline-646553-inference'},\n",
       "    'value': [1765407963.993, '5903']},\n",
       "   {'metric': {'topic': 'workspace-1516-pipeline-deployment-status-ccfraud-pipeline-227665-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-67-pipeline-mock-viability-pipeline-inference'},\n",
       "    'value': [1765407963.993, '858628']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-scale-test-fm-inference'},\n",
       "    'value': [1765407963.993, '121847']},\n",
       "   {'metric': {'topic': 'workspace-1591-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-rag-cb3-inference'},\n",
       "    'value': [1765407963.993, '13406']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-logs-pipeline-inference'},\n",
       "    'value': [1765407963.993, '9086']},\n",
       "   {'metric': {'topic': 'workspace-1488-pipeline-deployment-status-ccfraud-pipeline-455172-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1645-pipeline-deploy-specific-version-311428-inference'},\n",
       "    'value': [1765407963.993, '15253']},\n",
       "   {'metric': {'topic': 'workspace-1606-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1691-pipeline-tinyllama-openai-inference'},\n",
       "    'value': [1765407963.993, '14383']},\n",
       "   {'metric': {'topic': 'workspace-71-pipeline-assay-demonstration-tutorial-jcw-inference'},\n",
       "    'value': [1765407963.993, '60325542']},\n",
       "   {'metric': {'topic': 'workspace-1672-pipeline-edge-pipeline-inference'},\n",
       "    'value': [1765407963.993, '7109866']},\n",
       "   {'metric': {'topic': 'workspace-1686-pipeline-auto-conversion-pytorch-multi-io-pipeline-799130-inference'},\n",
       "    'value': [1765407963.993, '9295']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-scale-test-cp-inference'},\n",
       "    'value': [1765407963.993, '8255']},\n",
       "   {'metric': {'topic': 'workspace-1610-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1543-pipeline-validation-demo-jcw-inference-failures'},\n",
       "    'value': [1765407963.993, '27039']},\n",
       "   {'metric': {'topic': 'workspace-64-pipeline-llama-cpp-inference'},\n",
       "    'value': [1765407963.993, '82877']},\n",
       "   {'metric': {'topic': 'workspace-1599-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1615-pipeline-parallel-infer-aloha-pipeline-913986-inference'},\n",
       "    'value': [1765407963.993, '33654']},\n",
       "   {'metric': {'topic': 'workspace-1434-pipeline-whse-s-demand-forecast-inference'},\n",
       "    'value': [1765407963.993, '21595']},\n",
       "   {'metric': {'topic': 'workspace-1595-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1722-pipeline-sleep-passthrough-pipe-inference'},\n",
       "    'value': [1765407963.993, '5071']},\n",
       "   {'metric': {'topic': 'workspace-1666-pipeline-processing-step-pipe-inference'},\n",
       "    'value': [1765407963.993, '4783']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-safeguards-llamacpp-2-inference'},\n",
       "    'value': [1765407963.993, '13278']},\n",
       "   {'metric': {'topic': 'workspace-1530-pipeline-rum-assay-nan-inference'},\n",
       "    'value': [1765407963.993, '1752405']},\n",
       "   {'metric': {'topic': 'workspace-1443-pipeline-prophet-pipeline-inference'},\n",
       "    'value': [1765407963.993, '50219']},\n",
       "   {'metric': {'topic': 'workspace-124-pipeline-sidekick-replica-static-inference'},\n",
       "    'value': [1765407963.993, '14567925']},\n",
       "   {'metric': {'topic': 'workspace-1531-pipeline-alohapipeline-101-inference'},\n",
       "    'value': [1765407963.993, '107069']},\n",
       "   {'metric': {'topic': 'workspace-1644-pipeline-deployment-status-ccfraud-pipeline-894029-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1600-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1434-pipeline-lstm-demand-forecast-inference'},\n",
       "    'value': [1765407963.993, '29118']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llama-31-8b-vllm-ynsv6-inference'},\n",
       "    'value': [1765407963.993, '6015']},\n",
       "   {'metric': {'topic': 'workspace-1612-pipeline-parallel-infer-aloha-pipeline-367533-inference'},\n",
       "    'value': [1765407963.993, '20059']},\n",
       "   {'metric': {'topic': 'workspace-1793-pipeline-noop-pipeline-227333-inference'},\n",
       "    'value': [1765407963.993, '4879']},\n",
       "   {'metric': {'topic': 'workspace-1626-pipeline-edge-pipeline-classification-cybersecurity-inference'},\n",
       "    'value': [1765407963.993, '544267']},\n",
       "   {'metric': {'topic': 'workspace-1448-pipeline-rx-gender-pipeline-inference'},\n",
       "    'value': [1765407963.993, '5327']},\n",
       "   {'metric': {'topic': 'workspace-11-pipeline-passthrough-vc-test-2-inference'},\n",
       "    'value': [1765407963.993, '30277771']},\n",
       "   {'metric': {'topic': 'workspace-1549-pipeline-edge-pipeline-inference'},\n",
       "    'value': [1765407963.993, '39082477']},\n",
       "   {'metric': {'topic': 'workspace-1756-pipeline-replace-model-ccfraud-pipeline-845532-inference'},\n",
       "    'value': [1765407963.993, '10170']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-inference'},\n",
       "    'value': [1765407963.993, '164438']},\n",
       "   {'metric': {'topic': 'workspace-1699-pipeline-edge-low-connection-demonstration-inference'},\n",
       "    'value': [1765407963.993, '375195']},\n",
       "   {'metric': {'topic': 'workspace-1526-pipeline-ma-consumptionchanges-stage-inference'},\n",
       "    'value': [1765407963.993, '1148670']},\n",
       "   {'metric': {'topic': 'workspace-92-pipeline-preethi-retail-inv-tracker-edge-obs-inference'},\n",
       "    'value': [1765407963.993, '85551']},\n",
       "   {'metric': {'topic': 'workspace-1573-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-11-pipeline-passthrough-test-inference'},\n",
       "    'value': [1765407963.993, '20182723']},\n",
       "   {'metric': {'topic': 'workspace-1449-pipeline-resnetnetpipeline-inference'},\n",
       "    'value': [1765407963.993, '9899']},\n",
       "   {'metric': {'topic': 'workspace-1570-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-87-pipeline-whisper-hf-byop-testshared2-inference'},\n",
       "    'value': [1765407963.993, '2433662']},\n",
       "   {'metric': {'topic': 'workspace-42-pipeline-resnet-pipeline-inference'},\n",
       "    'value': [1765407963.993, '13439']},\n",
       "   {'metric': {'topic': 'workspace-1712-pipeline-redeploy-ccfraud-pipeline-327896-inference'},\n",
       "    'value': [1765407963.993, '15249']},\n",
       "   {'metric': {'topic': 'workspace-1441-pipeline-llama-rag-pipeline-inference'},\n",
       "    'value': [1765407963.993, '4991']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llama-31-8b-vllm-egde-yns1-inference'},\n",
       "    'value': [1765407963.993, '12030']},\n",
       "   {'metric': {'topic': 'workspace-1450-pipeline-new-edge-inline-replacement-inference'},\n",
       "    'value': [1765407963.993, '5019']},\n",
       "   {'metric': {'topic': 'workspace-1611-pipeline-tensorflow-lazyadam-pipeline-274014-inference'},\n",
       "    'value': [1765407963.993, '11359']},\n",
       "   {'metric': {'topic': 'workspace-1744-pipeline-logging-pipeline-443908-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1716-pipeline-metrics-retrieval-tutorial-summarization-pipeline-inference'},\n",
       "    'value': [1765407963.993, '341359']},\n",
       "   {'metric': {'topic': 'workspace-1745-pipeline-logging-pipeline-242166-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-predictor-inference-failures'},\n",
       "    'value': [1765407963.993, '51960']},\n",
       "   {'metric': {'topic': 'workspace-1644-pipeline-redeploy-ccfraud-pipeline-198252-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'pipeline-apiinferenceexamplepipeline-inference'},\n",
       "    'value': [1765407963.993, '3486750']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-rag-inference'},\n",
       "    'value': [1765407963.993, '166669']},\n",
       "   {'metric': {'topic': 'workspace-127-pipeline-whisper-byop-jcw-inference'},\n",
       "    'value': [1765407963.993, '7300986']},\n",
       "   {'metric': {'topic': 'workspace-1751-pipeline-logging-pipeline-446586-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1593-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1526-pipeline-ma-consumptionchanges-stage-inference-failures'},\n",
       "    'value': [1765407963.993, '854590']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-llama3-8b-instruct-llamacpp-inference'},\n",
       "    'value': [1765407963.993, '6207']},\n",
       "   {'metric': {'topic': 'workspace-1529-pipeline-rum-assay-nan-jcw-inference-failures'},\n",
       "    'value': [1765407963.993, '1483222']},\n",
       "   {'metric': {'topic': 'workspace-1653-pipeline-auto-packaging-byop-332646-inference'},\n",
       "    'value': [1765407963.993, '6751']},\n",
       "   {'metric': {'topic': 'workspace-1624-pipeline-noop-pipeline-593114-inference'},\n",
       "    'value': [1765407963.993, '4879']},\n",
       "   {'metric': {'topic': 'workspace-1567-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1688-pipeline-replace-model-ccfraud-pipeline-663217-inference'},\n",
       "    'value': [1765407963.993, '10170']},\n",
       "   {'metric': {'topic': 'workspace-1535-pipeline-assay-demonstration-tutorial-inference'},\n",
       "    'value': [1765407963.993, '767326']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-byop-vllm-100cb-inference'},\n",
       "    'value': [1765407963.993, '870527']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-llama3-8b-instruct-llamacpp3-inference'},\n",
       "    'value': [1765407963.993, '6207']},\n",
       "   {'metric': {'topic': 'workspace-1575-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1450-pipeline-edge-inline-replacement-demon-inference'},\n",
       "    'value': [1765407963.993, '25415']},\n",
       "   {'metric': {'topic': 'workspace-1769-pipeline-logging-pipeline-389182-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-1646-pipeline-deploy-specific-version-697543-inference'},\n",
       "    'value': [1765407963.993, '15253']},\n",
       "   {'metric': {'topic': 'workspace-72-pipeline-simpleorchestrationtutorial-jcw-inference'},\n",
       "    'value': [1765407963.993, '47411']},\n",
       "   {'metric': {'topic': 'workspace-1594-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5659']},\n",
       "   {'metric': {'topic': 'workspace-1795-pipeline-auto-packaging-keras-multi-io-pipeline-464266-inference'},\n",
       "    'value': [1765407963.993, '9487']},\n",
       "   {'metric': {'topic': 'workspace-1770-pipeline-logging-pipeline-702016-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-86-pipeline-house-price-predictor-inference'},\n",
       "    'value': [1765407963.993, '1290104']},\n",
       "   {'metric': {'topic': 'workspace-43-pipeline-pk-mock-viability-pipeline-1-inference'},\n",
       "    'value': [1765407963.993, '15471']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-scale-test-jb-inference'},\n",
       "    'value': [1765407963.993, '336756']},\n",
       "   {'metric': {'topic': 'workspace-1767-pipeline-auto-packaging-byop-llamacpp-814365-inference'},\n",
       "    'value': [1765407963.993, '4991']},\n",
       "   {'metric': {'topic': 'workspace-1738-pipeline-auto-packaging-byop-llamacpp-934757-inference'},\n",
       "    'value': [1765407963.993, '5055']},\n",
       "   {'metric': {'topic': 'workspace-1759-pipeline-shadow-pipeline-329308-inference'},\n",
       "    'value': [1765407963.993, '5903']},\n",
       "   {'metric': {'topic': 'workspace-1439-pipeline-house-price-with-challengers-inference-failures'},\n",
       "    'value': [1765407963.993, '9247']},\n",
       "   {'metric': {'topic': 'workspace-125-pipeline-alohapipeline-jcw-inference'},\n",
       "    'value': [1765407963.993, '162862322']},\n",
       "   {'metric': {'topic': 'workspace-122-pipeline-alohapipeline-jcw-inference'},\n",
       "    'value': [1765407963.993, '1638681404']},\n",
       "   {'metric': {'topic': 'workspace-1530-pipeline-rum-assay-nan-inference-failures'},\n",
       "    'value': [1765407963.993, '1120573']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-byop-tinyllama-cutom-vllm-inference'},\n",
       "    'value': [1765407963.993, '6079']},\n",
       "   {'metric': {'topic': 'workspace-1683-pipeline-deploy-specific-version-583663-inference'},\n",
       "    'value': [1765407963.993, '15253']},\n",
       "   {'metric': {'topic': 'workspace-1524-pipeline-assay-demonstration-tutorial-pk-inference'},\n",
       "    'value': [1765407963.993, '24800358']},\n",
       "   {'metric': {'topic': 'workspace-1576-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-43-pipeline-simpleorchestrationpipeline-jcw-inference'},\n",
       "    'value': [1765407963.993, '7945747']},\n",
       "   {'metric': {'topic': 'workspace-1541-pipeline-assay-demo-tutorial-inference'},\n",
       "    'value': [1765407963.993, '760478']},\n",
       "   {'metric': {'topic': 'workspace-1695-pipeline-ccfraudpipeline-jcw-inference'},\n",
       "    'value': [1765407963.993, '635831']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-hotswap-vllm-2-inference'},\n",
       "    'value': [1765407963.993, '17230']},\n",
       "   {'metric': {'topic': 'workspace-114-pipeline-test-pipeline-inference'},\n",
       "    'value': [1765407963.993, '3744029']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-rag-cb1-inference'},\n",
       "    'value': [1765407963.993, '8751']},\n",
       "   {'metric': {'topic': 'workspace-126-pipeline-simpleorchestrationpipeline-jcw-2-inference'},\n",
       "    'value': [1765407963.993, '1913123']},\n",
       "   {'metric': {'topic': 'workspace-1644-pipeline-ab-testing-pipeline-851978-inference'},\n",
       "    'value': [1765407963.993, '11098']},\n",
       "   {'metric': {'topic': 'workspace-1758-pipeline-logging-pipeline-850802-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1777-pipeline-logging-pipeline-311696-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-1688-pipeline-deployment-status-ccfraud-pipeline-431950-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-rag-pipeline-inference'},\n",
       "    'value': [1765407963.993, '4991']},\n",
       "   {'metric': {'topic': 'workspace-1748-pipeline-redeploy-ccfraud-pipeline-142849-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1484-pipeline-hf-zero-shot-classification-jcw-inference'},\n",
       "    'value': [1765407963.993, '2436987']},\n",
       "   {'metric': {'topic': 'workspace-1693-pipeline-llama-openai-inference'},\n",
       "    'value': [1765407963.993, '3230010']},\n",
       "   {'metric': {'topic': 'workspace-1596-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1638-pipeline-noop-pipeline-405143-inference'},\n",
       "    'value': [1765407963.993, '4879']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacpp-pipeyns-arm2-inference'},\n",
       "    'value': [1765407963.993, '6335']},\n",
       "   {'metric': {'topic': 'workspace-1514-pipeline-deployment-status-ccfraud-pipeline-818148-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1439-pipeline-house-price-predictor-inference'},\n",
       "    'value': [1765407963.993, '327837']},\n",
       "   {'metric': {'topic': 'workspace-1519-pipeline-deployment-status-ccfraud-pipeline-813380-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1569-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-43-pipeline-pk-mock-viability-pipeline-5-inference'},\n",
       "    'value': [1765407963.993, '117566']},\n",
       "   {'metric': {'topic': 'workspace-1612-pipeline-sleep-passthrough-pipe-inference'},\n",
       "    'value': [1765407963.993, '5071']},\n",
       "   {'metric': {'topic': 'workspace-1549-pipeline-edge-pipeline-jb-inference'},\n",
       "    'value': [1765407963.993, '3565019']},\n",
       "   {'metric': {'topic': 'workspace-121-pipeline-whisper-hf-byop-jcw-inference'},\n",
       "    'value': [1765407963.993, '10238']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacpp-pipeyns-arm1-inference'},\n",
       "    'value': [1765407963.993, '9470']},\n",
       "   {'metric': {'topic': 'workspace-1485-pipeline-deployment-status-ccfraud-pipeline-518264-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1446-pipeline-assay-demonstration-tutorial-4551-test-inference'},\n",
       "    'value': [1765407963.993, '805827']},\n",
       "   {'metric': {'topic': 'workspace-1778-pipeline-pk-resident-signal-staging-pipeline-inference'},\n",
       "    'value': [1765407963.993, '35453839']},\n",
       "   {'metric': {'topic': 'workspace-1490-pipeline-deployment-status-ccfraud-pipeline-763604-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1434-pipeline-whse-j-demand-forecast-inference'},\n",
       "    'value': [1765407963.993, '21595']},\n",
       "   {'metric': {'topic': 'workspace-11-pipeline-passthrough-vc-flatten-reshape-test-inference'},\n",
       "    'value': [1765407963.993, '50415871']},\n",
       "   {'metric': {'topic': 'workspace-1609-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-91-pipeline-retail-inv-tracker-edge-obs-inference'},\n",
       "    'value': [1765407963.993, '170462']},\n",
       "   {'metric': {'topic': 'workspace-1511-pipeline-deployment-status-ccfraud-pipeline-959225-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1772-pipeline-ab-testing-pipeline-841882-inference'},\n",
       "    'value': [1765407963.993, '11098']},\n",
       "   {'metric': {'topic': 'workspace-1543-pipeline-validation-demo-jcw-inference'},\n",
       "    'value': [1765407963.993, '395679']},\n",
       "   {'metric': {'topic': 'workspace-1441-pipeline-summarizer-listener-yns-inference-failures'},\n",
       "    'value': [1765407963.993, '6475']},\n",
       "   {'metric': {'topic': 'pipeline-simpleorchestrationpipeline-jcw-inference'},\n",
       "    'value': [1765407963.993, '3802186054']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-llama-3dot1-8b-pipe-inference'},\n",
       "    'value': [1765407963.993, '6575']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-llama-inference'},\n",
       "    'value': [1765407963.993, '6191']},\n",
       "   {'metric': {'topic': 'workspace-1592-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5915']},\n",
       "   {'metric': {'topic': 'workspace-1580-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1439-pipeline-house-price-predictor-inference-failures'},\n",
       "    'value': [1765407963.993, '12990']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-retail-inv-openvino-inference'},\n",
       "    'value': [1765407963.993, '7883']},\n",
       "   {'metric': {'topic': 'workspace-1489-pipeline-deployment-status-ccfraud-pipeline-482650-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1644-pipeline-deploy-specific-version-751387-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1512-pipeline-deployment-status-ccfraud-pipeline-273957-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1617-pipeline-parallel-infer-aloha-pipeline-540652-inference'},\n",
       "    'value': [1765407963.993, '20059']},\n",
       "   {'metric': {'topic': 'workspace-37-pipeline-scale-test-fm-2-inference'},\n",
       "    'value': [1765407963.993, '11924331']},\n",
       "   {'metric': {'topic': 'workspace-1724-pipeline-sleep-passthrough-pipe-inference'},\n",
       "    'value': [1765407963.993, '5071']},\n",
       "   {'metric': {'topic': 'workspace-1523-pipeline-assay-demonstration-tutorial-jb-inference'},\n",
       "    'value': [1765407963.993, '4009387']},\n",
       "   {'metric': {'topic': 'workspace-1654-pipeline-auto-packaging-byop-985934-inference'},\n",
       "    'value': [1765407963.993, '6751']},\n",
       "   {'metric': {'topic': 'workspace-1460-pipeline-shadowimagepipelinetest-inference'},\n",
       "    'value': [1765407963.993, '12699']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-byop-tinyllama-cutom-vllmedgeynsjb-inference'},\n",
       "    'value': [1765407963.993, '6079']},\n",
       "   {'metric': {'topic': 'workspace-72-pipeline-simpleorchestrationpipeline-jcw-inference'},\n",
       "    'value': [1765407963.993, '12631455989']},\n",
       "   {'metric': {'topic': 'workspace-87-pipeline-whisper-hf-byop-replicatest-inference'},\n",
       "    'value': [1765407963.993, '38855975']},\n",
       "   {'metric': {'topic': 'workspace-1688-pipeline-deploy-specific-version-434108-inference'},\n",
       "    'value': [1765407963.993, '15253']},\n",
       "   {'metric': {'topic': 'workspace-43-pipeline-assay-demonstration-tutorial-jcw-inference'},\n",
       "    'value': [1765407963.993, '5339']},\n",
       "   {'metric': {'topic': 'workspace-1528-pipeline-preethi-assay-test-pipeline-inference'},\n",
       "    'value': [1765407963.993, '7823547']},\n",
       "   {'metric': {'topic': 'workspace-1774-pipeline-logging-pipeline-968262-inference'},\n",
       "    'value': [1765407963.993, '20336']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-rag-cb2-inference'},\n",
       "    'value': [1765407963.993, '6703']},\n",
       "   {'metric': {'topic': 'workspace-1766-pipeline-auto-packaging-byop-llamacpp-150240-inference'},\n",
       "    'value': [1765407963.993, '5055']},\n",
       "   {'metric': {'topic': 'workspace-108-pipeline-yolo8demonstration-openvino-inference'},\n",
       "    'value': [1765407963.993, '11302135']},\n",
       "   {'metric': {'topic': 'workspace-1530-pipeline-rum-assay-inference'},\n",
       "    'value': [1765407963.993, '231103']},\n",
       "   {'metric': {'topic': 'workspace-21-pipeline-mac-keras-single-io-eng-5621-inference'},\n",
       "    'value': [1765407963.993, '15064810']},\n",
       "   {'metric': {'topic': 'workspace-1531-pipeline-alohapipeline-inference'},\n",
       "    'value': [1765407963.993, '3740721']},\n",
       "   {'metric': {'topic': 'workspace-1688-pipeline-redeploy-ccfraud-pipeline-532802-inference'},\n",
       "    'value': [1765407963.993, '10166']},\n",
       "   {'metric': {'topic': 'workspace-1679-pipeline-auto-packaging-keras-multi-io-pipeline-517349-inference'},\n",
       "    'value': [1765407963.993, '9487']},\n",
       "   {'metric': {'topic': 'workspace-1566-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1739-pipeline-auto-packaging-byop-llamacpp-568890-inference'},\n",
       "    'value': [1765407963.993, '5055']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-byop-tinyllama-cutom-vllmedgeyns-inference'},\n",
       "    'value': [1765407963.993, '6079']},\n",
       "   {'metric': {'topic': 'workspace-67-pipeline-bench-aloha-pipeline-inference'},\n",
       "    'value': [1765407963.993, '50907']},\n",
       "   {'metric': {'topic': 'workspace-1620-pipeline-parallel-infer-aloha-pipeline-926947-inference'},\n",
       "    'value': [1765407963.993, '32950']},\n",
       "   {'metric': {'topic': 'workspace-70-pipeline-assay-demonstration-tutorial-inference'},\n",
       "    'value': [1765407963.993, '7823547']},\n",
       "   {'metric': {'topic': 'workspace-1689-pipeline-tinyllama-openai-error1-inference'},\n",
       "    'value': [1765407963.993, '24973']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-byop-tinyllama-demo-yns-cudafix-inference'},\n",
       "    'value': [1765407963.993, '6079']},\n",
       "   {'metric': {'topic': 'workspace-1686-pipeline-auto-conversion-xgboost-classification-pipeline-112261-inference'},\n",
       "    'value': [1765407963.993, '7611']},\n",
       "   {'metric': {'topic': 'workspace-1521-pipeline-deployment-status-ccfraud-pipeline-151654-inference'},\n",
       "    'value': [1765407963.993, '5083']},\n",
       "   {'metric': {'topic': 'workspace-1764-pipeline-sleep-passthrough-pipe-inference'},\n",
       "    'value': [1765407963.993, '5071']},\n",
       "   {'metric': {'topic': 'workspace-92-pipeline-preethi2-retail-inv-tracker-edge-obs-inference'},\n",
       "    'value': [1765407963.993, '40687']},\n",
       "   {'metric': {'topic': 'workspace-1714-pipeline-simpleorchestrationtutorial-inference'},\n",
       "    'value': [1765407963.993, '2957237502']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llama-31-8b-vllm-demo-inference'},\n",
       "    'value': [1765407963.993, '6015']},\n",
       "   {'metric': {'topic': 'workspace-1604-pipeline-image-pipeline-list-inference'},\n",
       "    'value': [1765407963.993, '6159']},\n",
       "   {'metric': {'topic': 'workspace-1568-pipeline-image-pipeline-b64-inference'},\n",
       "    'value': [1765407963.993, '5279']},\n",
       "   {'metric': {'topic': 'workspace-1783-pipeline-processing-step-pipe-inference'},\n",
       "    'value': [1765407963.993, '4783']},\n",
       "   {'metric': {'topic': 'workspace-1431-pipeline-vgg16-clustering-pipeline-inference'},\n",
       "    'value': [1765407963.993, '316204']},\n",
       "   {'metric': {'topic': 'workspace-43-pipeline-pk-mock-viability-pipeline-3-inference'},\n",
       "    'value': [1765407963.993, '102109']},\n",
       "   {'metric': {'topic': 'workspace-1619-pipeline-parallel-infer-aloha-pipeline-205619-inference'},\n",
       "    'value': [1765407963.993, '33526']},\n",
       "   {'metric': {'topic': 'workspace-1613-pipeline-parallel-infer-aloha-pipeline-987498-inference'},\n",
       "    'value': [1765407963.993, '33654']},\n",
       "   {'metric': {'topic': 'workspace-38-pipeline-retail-inv-cuda-inference'},\n",
       "    'value': [1765407963.993, '6795']},\n",
       "   {'metric': {'topic': 'workspace-43-pipeline-alohapipeline-101-inference'},\n",
       "    'value': [1765407963.993, '15835']},\n",
       "   {'metric': {'topic': 'workspace-1785-pipeline-cgo-multi-step-pipeline-inference'},\n",
       "    'value': [1765407963.993, '28769']},\n",
       "   {'metric': {'topic': 'workspace-71-pipeline-assay-demonstration-tutorial-jcw-2-inference'},\n",
       "    'value': [1765407963.993, '54357617']},\n",
       "   {'metric': {'topic': 'workspace-123-pipeline-alohapipeline-inference'},\n",
       "    'value': [1765407963.993, '578177']},\n",
       "   {'metric': {'topic': 'workspace-1640-pipeline-shadow-pipeline-880880-inference'},\n",
       "    'value': [1765407963.993, '5903']},\n",
       "   {'metric': {'topic': 'workspace-1447-pipeline-alohapipeline-imp-inference'},\n",
       "    'value': [1765407963.993, '84938366']},\n",
       "   {'metric': {'topic': 'workspace-1642-pipeline-replace-model-ccfraud-pipeline-699333-inference'},\n",
       "    'value': [1765407963.993, '10170']},\n",
       "   {'metric': {'topic': 'workspace-1547-pipeline-multi-io-example-inference'},\n",
       "    'value': [1765407963.993, '9167']},\n",
       "   {'metric': {'topic': 'workspace-1639-pipeline-noop-pipeline-814814-inference'},\n",
       "    'value': [1765407963.993, '4879']},\n",
       "   {'metric': {'topic': 'workspace-60-pipeline-llamacppovms1-inference'},\n",
       "    'value': [1765407963.993, '5247']},\n",
       "   {'metric': {'topic': 'workspace-1439-pipeline-house-price-with-challengers-inference'},\n",
       "    'value': [1765407963.993, '334239']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-0-inference'},\n",
       "    'value': [1765407963.993, '22696']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-1-inference'},\n",
       "    'value': [1765407963.993, '15668']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-2-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'pipeline-bo-lightgbm-model-pipeline-0-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-6-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-3-inference'},\n",
       "    'value': [1765407963.993, '11220']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-5-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-4-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-9-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-8-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-7-inference'},\n",
       "    'value': [1765407963.993, '11348']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-10-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-11-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-12-inference'},\n",
       "    'value': [1765407963.993, '6964']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-13-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-14-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-15-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-16-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-17-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-18-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-19-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-20-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-21-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-22-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-23-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-24-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-26-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-25-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-27-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-28-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-29-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-30-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-31-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-33-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-32-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-34-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-35-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-36-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-37-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-38-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-39-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-40-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-41-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-42-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-43-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-44-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-45-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-46-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-47-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-48-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-49-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-50-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-51-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-52-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-53-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-54-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-55-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-56-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-57-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-58-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-59-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-60-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-61-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-62-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-63-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-64-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-65-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-66-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-67-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-68-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-69-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-70-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-71-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-73-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-72-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-74-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-75-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-76-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-77-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-78-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-79-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-80-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-81-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-82-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-83-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-84-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-85-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-86-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-87-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-88-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-89-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-90-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-91-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-92-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-93-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-94-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-95-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-96-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-97-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-98-inference'},\n",
       "    'value': [1765407963.993, '7028']},\n",
       "   {'metric': {'topic': 'workspace-1803-pipeline-bo-lightgbm-model-pipeline-99-inference'},\n",
       "    'value': [1765407963.993, '7028']}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the URL to get prometheus metrics\n",
    "query_url = f\"{wl.api_endpoint}/v1/metrics/api/v1/query\"\n",
    "\n",
    "# Retrieve the token \n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "# this will also format the timezone in the parsing section\n",
    "timezone = \"US/Mountain\"\n",
    "selected_timezone = pytz.timezone(timezone)\n",
    "data_start = selected_timezone.localize(datetime.datetime(2025, 11, 24, 13, 0, 0))\n",
    "data_end = selected_timezone.localize(datetime.datetime(2025, 11, 25, 15, 59, 59))\n",
    "\n",
    "# This example uses the data_end period to get sizes at a specific point in time\n",
    "timestamp = int(data_end.timestamp())\n",
    "\n",
    "# Other example: now() to retrieve sizes for the current time\n",
    "timestamp = int(datetime.datetime.now(selected_timezone).timestamp())\n",
    "\n",
    "# Get the total size of all the pipeline files by pipeline AND pipeline_version\n",
    "query = f'sum by(topic) (topic_bytes@{timestamp})'\n",
    "\n",
    "print(query)\n",
    "\n",
    "#request parameters\n",
    "params_rps = {\n",
    "    'query': query,\n",
    "}\n",
    "\n",
    "response = requests.get(query_url, headers=headers, params=params_rps)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Query Response:\")\n",
    "    display(response.json())\n",
    "else:\n",
    "    print(\"Failed to fetch query response:\", response.status_code, response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk2025.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
