{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b7ac3",
   "metadata": {},
   "source": [
    "The following tutorial is available on the [Wallaroo Github Repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/20231004-wallaroo-inference-server/wallaroo-inference-server-tutorials/wallaroo-inference-server-hf-summarizer).\n",
    "\n",
    "## Wallaroo Inference Server:  Hugging Face Summarizer\n",
    "\n",
    "This notebook is used in conjunction with the [Wallaroo Inference Server Free Edition](https://docs.wallaroo.ai/wallaroo-inferencing-server/) for LLama 2.  This provides a free license for performing inferences through the Hugging Face Summarizer model.  For more information, see [the Llama 2 reference page](https://ai.meta.com/llama/).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* A deployed Wallaroo Inference Server Free Edition with one of the following options:\n",
    "  * **Wallaroo.AI Llama Inference Server - GPU**\n",
    "* Access via port 8080 to the Wallaroo Inference Server Free Edition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e2edc",
   "metadata": {},
   "source": [
    "## Wallaroo Inference Server API Endpoints\n",
    "\n",
    "The following HTTPS API endpoints are available for Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4659e8",
   "metadata": {},
   "source": [
    "### Pipelines Endpoint\n",
    "\n",
    "* Endpoint: HTTPS GET `/pipelines`\n",
    "* Returns:\n",
    "  * List of `pipelines` with the following fields.\n",
    "    * **id** (*String*): The name of the pipeline.\n",
    "    * **status** (*String*): The pipeline status.  `Running` indicates the pipeline is available for inferences.\n",
    "\n",
    "#### Pipeline Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Pipelines endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9267efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"pipelines\":[{\"id\":\"hf-summarizer-standard\",\"status\":\"Running\"}]}"
     ]
    }
   ],
   "source": [
    "!curl mb-freemium-hfstd86.eastus.cloudapp.azure.com:8080/pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04d17c",
   "metadata": {},
   "source": [
    "### Models Endpoint\n",
    "\n",
    "* Endpoint: GET `/models`\n",
    "* Returns:\n",
    "  * List of `models` with the following fields.\n",
    "    * **name** (*String*):  The name of the model.\n",
    "    * **sha** (*String*):  The `sha` hash of the model.\n",
    "    * **status** (*String*):  The model status.  `Running` indicates the models is available for inferences.\n",
    "    * **version** (*String*): The model version in UUID format.\n",
    "\n",
    "#### Models Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Models endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eaa60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"models\":[{\"name\":\"hf-summarizer-standard\",\"sha\":\"ee71d066a83708e7ca4a3c07caf33fdc528bb000039b6ca2ef77fa2428dc6268\",\"status\":\"Running\",\"version\":\"7dbae7b4-20d0-40f7-a3f5-eeabdd77f418\"}]}"
     ]
    }
   ],
   "source": [
    "!curl doc-example-hf-summarizer.westus2.cloudapp.azure.com:8080/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8e6c2",
   "metadata": {},
   "source": [
    "### Inference Endpoint\n",
    "\n",
    "The inference endpoint takes the following pattern:\n",
    "\n",
    "* `/pipelines/{pipeline-name}`:  The `pipeline-name` is the same as returned from the [`/pipelines`](#list-pipelines) endpoint as `id`.\n",
    "\n",
    "Wallaroo inference endpoint URLs accept the following data inputs through the `Content-Type` header:\n",
    "\n",
    "* `Content-Type: application/vnd.apache.arrow.file`: For Apache Arrow tables.\n",
    "* `Content-Type: application/json; format=pandas-records`: For pandas DataFrame in record format.\n",
    "\n",
    "Once deployed, we can perform an inference through the deployment URL.\n",
    "\n",
    "  * Endpoint: HTTPS POST `/pipelines/hf-summarizer-standard`\n",
    "  * Headers:\n",
    "    * `Content-Type: application/vnd.apache.arrow.file`: For Apache Arrow tables.\n",
    "    * `Content-Type: application/json; format=pandas-records`: For pandas DataFrame in record format.\n",
    "  * Input Parameters: DataFrame in `/pipelines/hf-summarizer-standard` **OR** Apache Arrow table in `application/vnd.apache.arrow.file` with the following inputs:\n",
    "    * **inputs** (*String* *Required*): One or several articles to summarize.\n",
    "    * **return_text** (*Bool* *Optional*): Whether or not to include the decoded texts in the outputs.\n",
    "    * **return_tensor** (*Bool* *Optional*): Whether or not to include the tensors of predictions (as token indices) in the outputs.\n",
    "    * **clean_up_tokenization_spaces**(*Bool* *Optional*): Whether or not to clean up the potential extra spaces in the text output.\n",
    "  * Returns:\n",
    "    * Headers\n",
    "      * `Content-Type: application/json; format=pandas-records`: pandas DataFrame in record format.\n",
    "    * Data\n",
    "      * **check_failures** (*List[Integer]*): Whether any validation checks were triggered.  For more information, see [Wallaroo SDK Essentials Guide: Pipeline Management: Anomaly Testing]({{<ref \"wallaroo-sdk-essentials-pipeline#anomaly-testing\">}}).\n",
    "      * **elapsed** (*List[Integer]*): A list of time in nanoseconds for:\n",
    "        * [0] The time to serialize the input.\n",
    "        * [1...n] How long each step took.\n",
    "      * **model_name** (*String*): The name of the model used.\n",
    "      * **model_version** (*String*): The version of the model in UUID format.\n",
    "      * **original_data**: The original input data.  Returns `null` if the input may be too long for a proper return.\n",
    "      * **outputs** (*List*): The outputs of the inference result separated by data type.\n",
    "        * **String**: The string outputs for the inference.\n",
    "          * **data** (*List[String]*): \n",
    "        * **dim** (*List[Integer]*): The dimension shape returned, always returned as `[1,1]` for this model deployment.\n",
    "        * **v** (*Integer*): The vector shape of the data, always returned as `1` for this mnodel deployment.\n",
    "      * **pipeline_name**  (*String*): The name of the pipeline.\n",
    "      * **shadow_data**: Any shadow deployed data inferences in the same format as **outputs**.\n",
    "      * **time** (*Integer*): The time since UNIX epoch.\n",
    "\n",
    "### Inference Endpoint Example\n",
    "\n",
    "The following example performs an inference using the pandas record input `./data/test_summarization.df.json` with a text string to summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb23c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to doc-example-llama.westus2.cloudapp.azure.com port 8080 after 2080 ms: Couldn't connect to server\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST doc-example-llama.westus2.cloudapp.azure.com:8080/pipelines/llama \\\n",
    "    -H \"Content-Type: application/json; format=pandas-records\" \\\n",
    "    -d @./data/llamaquery.df.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
