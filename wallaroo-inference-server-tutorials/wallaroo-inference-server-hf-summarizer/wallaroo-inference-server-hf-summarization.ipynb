{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b7ac3",
   "metadata": {},
   "source": [
    "The following tutorial is available on the [Wallaroo Github Repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/20231004-wallaroo-inference-server/wallaroo-inference-server-tutorials/wallaroo-inference-server-hf-summarizer).\n",
    "\n",
    "## Wallaroo Inference Server:  Hugging Face Summarizer\n",
    "\n",
    "This notebook is used in conjunction with the [Wallaroo Inference Server Free Edition](https://docs.wallaroo.ai/wallaroo-inferencing-server/) for Hugging Face Summarizer.  This provides a free license for performing inferences through the Hugging Face Summarizer model.  For full demonstrations of this model, see [Wallaroo Edge Hugging Face LLM Summarization Deployment Demonstration](https://docs.wallaroo.ai/20230300/wallaroo-tutorials/wallaroo-edge-publish/wallaroo-edge-hf-summarization-deployment-tutorial/).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* A deployed Wallaroo Inference Server Free Edition with one of the following options:\n",
    "  * **Wallaroo.AI HF Summarizer Standard - x64**\n",
    "  * **Wallaroo.AI HF Summarizer Onnx - x64** \n",
    "  * **Wallaroo.AI HF Summarizer Standard - GPU x64**\n",
    "* Access via port 8080 to the Wallaroo Inference Server Free Edition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e2edc",
   "metadata": {},
   "source": [
    "## Wallaroo Inference Server API Endpoints\n",
    "\n",
    "The following HTTPS API endpoints are available for Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4659e8",
   "metadata": {},
   "source": [
    "### Pipelines Endpoint\n",
    "\n",
    "* Endpoint: HTTPS GET `/pipelines`\n",
    "* Returns:\n",
    "  * List of `pipelines` with the following fields.\n",
    "    * **id** (*String*): The name of the pipeline.\n",
    "    * **status** (*String*): The pipeline status.  `Running` indicates the pipeline is available for inferences.\n",
    "\n",
    "#### Pipeline Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Pipelines endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9267efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"pipelines\":[{\"id\":\"hf-summarizer-standard\",\"status\":\"Running\"}]}"
     ]
    }
   ],
   "source": [
    "!curl mb-freemium-hfstd86.eastus.cloudapp.azure.com:8080/pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04d17c",
   "metadata": {},
   "source": [
    "### Models Endpoint\n",
    "\n",
    "* Endpoint: GET `/models`\n",
    "* Returns:\n",
    "  * List of `models` with the following fields.\n",
    "    * **name** (*String*):  The name of the model.\n",
    "    * **sha** (*String*):  The `sha` hash of the model.\n",
    "    * **status** (*String*):  The model status.  `Running` indicates the models is available for inferences.\n",
    "    * **version** (*String*): The model version in UUID format.\n",
    "\n",
    "#### Models Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Models endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eaa60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"models\":[{\"name\":\"hf-summarizer-standard\",\"sha\":\"ee71d066a83708e7ca4a3c07caf33fdc528bb000039b6ca2ef77fa2428dc6268\",\"status\":\"Running\",\"version\":\"7dbae7b4-20d0-40f7-a3f5-eeabdd77f418\"}]}"
     ]
    }
   ],
   "source": [
    "!curl doc-example-hf-summarizer.westus2.cloudapp.azure.com:8080/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8e6c2",
   "metadata": {},
   "source": [
    "### Inference Endpoint\n",
    "\n",
    "The inference endpoint takes the following pattern:\n",
    "\n",
    "* `/pipelines/{pipeline-name}`:  The `pipeline-name` is the same as returned from the [`/pipelines`](#list-pipelines) endpoint as `id`.\n",
    "\n",
    "Wallaroo inference endpoint URLs accept the following data inputs through the `Content-Type` header:\n",
    "\n",
    "* `Content-Type: application/vnd.apache.arrow.file`: For Apache Arrow tables.\n",
    "* `Content-Type: application/json; format=pandas-records`: For pandas DataFrame in record format.\n",
    "\n",
    "Once deployed, we can perform an inference through the deployment URL.\n",
    "\n",
    "The endpoint returns `Content-Type: application/json; format=pandas-records` by default with the following fields:\n",
    "\n",
    "* **check_failures** (*List[Integer]*): Whether any validation checks were triggered.  For more information, see [Wallaroo SDK Essentials Guide: Pipeline Management: Anomaly Testing]({{<ref \"wallaroo-sdk-essentials-pipeline#anomaly-testing\">}}).\n",
    "* **elapsed** (*List[Integer]*): A list of time in nanoseconds for:\n",
    "  * [0] The time to serialize the input.\n",
    "  * [1...n] How long each step took.\n",
    "* **model_name** (*String*): The name of the model used.\n",
    "* **model_version** (*String*): The version of the model in UUID format.\n",
    "* **original_data**: The original input data.  Returns `null` if the input may be too long for a proper return.\n",
    "* **outputs** (*List*): The outputs of the inference result separated by data type, where each data type includes:\n",
    "  * **data**: The returned values.\n",
    "  * **dim** (*List[Integer]*): The dimension shape returned.\n",
    "  * **v** (*Integer*): The vector shape of the data.\n",
    "* **pipeline_name**  (*String*): The name of the pipeline.\n",
    "* **shadow_data**: Any shadow deployed data inferences in the same format as **outputs**.\n",
    "* **time** (*Integer*): The time since UNIX epoch.\n",
    "\n",
    "\n",
    "### Inference Endpoint Example\n",
    "\n",
    "The following example performs an inference using the pandas record input `./data/test_summarization.df.json` with a text string to summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb23c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"check_failures\":[],\"elapsed\":[37000,3245048360],\"model_name\":\"hf-summarizer-standard\",\"model_version\":\"7dbae7b4-20d0-40f7-a3f5-eeabdd77f418\",\"original_data\":null,\"outputs\":[{\"String\":{\"data\":[\"LinkedIn is a business and employment-focused social media platform that works through websites and mobile apps. It launched on May 5, 2003. LinkedIn allows members (both workers and employers) to create profiles and connect with each other in an online social network which may represent real-world professional relationships.\"],\"dim\":[1,1],\"v\":1}}],\"pipeline_name\":\"hf-summarizer-standard\",\"shadow_data\":{},\"time\":1696454765559}]"
     ]
    }
   ],
   "source": [
    "!curl -X POST HOSTNAME:8080/pipelines/hf-summarizer-standard \\\n",
    "    -H \"Content-Type: application/json; format=pandas-records\" \\\n",
    "    -d @./data/test_summarization.df.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
