{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b7ac3",
   "metadata": {},
   "source": [
    "The following tutorial is available on the [Wallaroo Github Repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/blob/20231011-2023.4.0-testing/wallaroo-inference-server-tutorials/wallaroo-inference-server-cv-yolov8).\n",
    "\n",
    "## Wallaroo Inference Server:  Hugging Face Summarizer\n",
    "\n",
    "This notebook is used in conjunction with the [Wallaroo Inference Server Free Edition](https://docs.wallaroo.ai/wallaroo-inferencing-server/) for Hugging Face Summarizer.  This provides a free license for performing inferences through the [Computer Vision YoloV8n]([Yolov8](https://github.com/ultralytics/ultralytics) ) model.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* A deployed Wallaroo Inference Server Free Edition with one of the following options:\n",
    "  * **Wallaroo.AI Yolov8 Inference Server- x64**\n",
    "  * **Wallaroo.AI Yolov8 Inference Server- GPU**\n",
    "* Access via port 8080 to the Wallaroo Inference Server Free Edition.\n",
    "\n",
    "Note that GPU inference server require a VM with Nvidia GPU `cuda` support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a0c48",
   "metadata": {},
   "source": [
    "## Computer Vision Yolo8 Model Schemas\n",
    "\n",
    "### Inputs\n",
    "\n",
    "The Resnet Model takes the following inputs.\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `tensor` | Float | Tensor in the shape (n, 3, 480, 640) float.  This is the normalized pixel values of the 640x480 color image.\n",
    "\n",
    "### Outputs\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `output0` | Variable length *List[Float]* | A flattened numpy array of detected objects.  When reshaped into a `(1, 84, 8400)` returns where the bounding boxes for each detected object are elements `[0:3]` representing (x_coordinate, y_coordinate, width, height), the classes and scores are in elements `[4:]`. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e2edc",
   "metadata": {},
   "source": [
    "## Wallaroo Inference Server API Endpoints\n",
    "\n",
    "The following HTTPS API endpoints are available for Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4659e8",
   "metadata": {},
   "source": [
    "### Pipelines Endpoint\n",
    "\n",
    "* Endpoint: HTTPS GET `/pipelines`\n",
    "* Returns:\n",
    "  * List of `pipelines` with the following fields.\n",
    "    * **id** (*String*): The name of the pipeline.\n",
    "    * **status** (*String*): The pipeline status.  `Running` indicates the pipeline is available for inferences.\n",
    "\n",
    "#### Pipeline Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Pipelines endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9267efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"pipelines\":[{\"id\":\"yolo-v8\",\"status\":\"Running\"}]}"
     ]
    }
   ],
   "source": [
    "!curl HOSTNAME:8080/pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04d17c",
   "metadata": {},
   "source": [
    "### Models Endpoint\n",
    "\n",
    "* Endpoint: GET `/models`\n",
    "* Returns:\n",
    "  * List of `models` with the following fields.\n",
    "    * **name** (*String*):  The name of the model.\n",
    "    * **sha** (*String*):  The `sha` hash of the model.\n",
    "    * **status** (*String*):  The model status.  `Running` indicates the models is available for inferences.\n",
    "    * **version** (*String*): The model version in UUID format.\n",
    "\n",
    "#### Models Endpoint Example\n",
    "\n",
    "The following demonstrates using `curl` to retrieve the Models endpoint.  Replace the HOSTNAME with the address of your Wallaroo Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eaa60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"models\":[{\"name\":\"yolo-v8\",\"sha\":\"3ed5cd199e0e6e419bd3d474cf74f2e378aacbf586e40f24d1f8c89c2c476a08\",\"status\":\"Running\",\"version\":\"af82c216-4590-41ad-8579-48b7eccc7144\"}]}"
     ]
    }
   ],
   "source": [
    "!curl HOSTNAME:8080/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8e6c2",
   "metadata": {},
   "source": [
    "### Inference Endpoint\n",
    "\n",
    "The following endpoints are available from the Wallaroo Server for Computer Vision Yolov8n deployment.\n",
    "\n",
    "* Endpoint: HTTPS POST `/pipelines/hf-summarizer-standard`\n",
    "* Headers:\n",
    "  * `Content-Type: application/vnd.apache.arrow.file`: For Apache Arrow tables.\n",
    "  * `Content-Type: application/json; format=pandas-records`: For pandas DataFrame in record format.\n",
    "* Input Parameters:   The images **must** be in 640x640 format converted to a float tensor.DataFrame in `application/json; format=pandas-records` **OR** Apache Arrow table in `application/vnd.apache.arrow.file` with the shape `(n, 3, 640, 640)` then flattened, with the tensor values in the field `images`.\n",
    "\n",
    "The following code is used to create a DataFrame from a 640x640 image.\n",
    "\n",
    "  ```python\n",
    "  import cv2\n",
    "  import torch\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  \n",
    "  # load the image from disk, convert to BGR, resize to specified width, height, convert the image back to RGB\n",
    "  # convert the image to a float tensor and returns it.  Also return the original resized image for drawing bounding boxes in BGR\n",
    "  def imageResize(image, 640, 640):\n",
    "      #self.print(\"Image Mode:\"+image.mode)\n",
    "      im_pillow = np.array(image)\n",
    "      image = cv2.cvtColor(im_pillow, cv2.COLOR_BGR2RGB) #scott\n",
    "      image = cv2.flip(im_pillow, 1)\n",
    "      image = cv2.flip(image, 1)\n",
    "      #image = cv2.imread(im_pillow)\n",
    "      #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "      #image = cv2.cvtColor(im_pillow, cv2.COLOR_GRAY2BGR)\n",
    "      self.debug(\"Resizing to w:\"+str(width) + \" height:\"+str(height))\n",
    "      image = cv2.resize(image, (width, height))\n",
    "      \n",
    "      # convert the image from BGR to RGB channel ordering and change the\n",
    "      # image from channels last to channels first ordering\n",
    "      #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      image = image.transpose((2, 0, 1))\n",
    "\n",
    "      # add the batch dimension, scale the raw pixel intensities to the\n",
    "      # range [0, 1], and convert the image to a floating point tensor\n",
    "      image = np.expand_dims(image, axis=0)\n",
    "      image = image / 255.0\n",
    "      tensor = torch.FloatTensor(image)\n",
    "      tensor.flatten()\n",
    "\n",
    "      npArray = tensor.cpu().numpy()\n",
    "      dictData = {\"images\":[npArray]}\n",
    "      dataframedata = pd.DataFrame(dictData)\n",
    "  ```\n",
    "\n",
    "* Returns:\n",
    "  * Headers\n",
    "    * `Content-Type: application/json; format=pandas-records`: pandas DataFrame in record format.\n",
    "  * Data\n",
    "    * **time** (*Integer*): The time since UNIX epoch.\n",
    "    * **in**:  The original input.\n",
    "      * **images**:  The flattened tensor values for the original image.\n",
    "    * **out**: The outputs of the inference result separated by data type.\n",
    "      * **output0**: The float outputs for the inference.  This list is flattened, and when reshaped into `(1,84,8400)` with each **row** correlating to a detected object.  The elements break down as follows:\n",
    "        * [0:3]: The bounding box with the positions left, top, width, height.\n",
    "        * [4:]:  The classes and scores of the detected object.\n",
    "\n",
    "        For more details for breaking down the Yolo8n inference results into objects, see the `CVDemoUtils.py` module with the [Computer Vision Yolov8n Deployment in Wallaroo](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/wallaroo-model-cookbooks/computer-vision-yolov8)\n",
    "\n",
    "    * **check_failures** (*List[Integer]*): Whether any validation checks were triggered.  For more information, see [Wallaroo SDK Essentials Guide: Pipeline Management: Anomaly Testing](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/#anomaly-testing).\n",
    "    * **metadata**: Additional data for the inference.\n",
    "      * **last_model**:  The model used for the inference.\n",
    "        * **model_name** (*String*): The name of the model used.\n",
    "        * **model_sha** (*String*): The sha of the model used.\n",
    "      * **pipeline_version** (*String*): The pipeline version in UUID format.\n",
    "      * **elapsed** (*List[Integer]*): A list of time in nanoseconds for:\n",
    "        * [0] The time to serialize the input.\n",
    "        * [1...n] How long each step took.\n",
    "      * **dropped** (*List*): Any dropped input tables.\n",
    "\n",
    "\n",
    "### Inference Endpoint Example\n",
    "\n",
    "The Wallaroo Inference Server accepts pandas DataFrame or Apache Arrow tables as inference inputs.  The sample file `./data/dogbike.df.json` was converted from the file `./data/dogbike.png` as an example using the helper module `CVDemoUtils` and `WallarooUtils` are used to transform a sample image into a pandas DataFrame.  This DataFrame is then submitted to the Yolov8n model deployed in Wallaroo.\n",
    "\n",
    "The following code segment demonstrates converting the image to a DataFrame.\n",
    "\n",
    "```python\n",
    "from CVDemoUtils import CVDemo\n",
    "from WallarooUtils import Util\n",
    "cvDemo = CVDemo()\n",
    "util = Util()\n",
    "\n",
    "width, height = 640, 640\n",
    "tensor1, resizedImage1 = cvDemo.loadImageAndResize('./data/dogbike.png', width, height)\n",
    "tensor1.flatten()\n",
    "\n",
    "# add the tensor to a DataFrame and save the DataFrame in pandas record format\n",
    "df = util.convert_data(tensor1,'images')\n",
    "df.to_json(\"dogbike.df.json\", orient = 'records')\n",
    "```\n",
    "\n",
    "The following code segment demonstrates performing an inference through the Wallaroo Inference Server with the Yolov8n model deployed.  Replace `HOSTNAME`  with the hostname or IP address of your Wallaroo Inference Server instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb23c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28.7M  100 13.6M  100 15.0M  12.7M  14.1M  0:00:03  0:00:01  0:00:02 18.9M01  0:00:01 --:--:-- 27.0M\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST HOSTNAME:8080/pipelines/yolo-v8 \\\n",
    "    -H \"Content-Type: application/json; format=pandas-records\" \\\n",
    "    -d @./data/dogbike.df.json > edge-results.df.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
