{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d6daff",
   "metadata": {},
   "source": [
    "This can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/quickstartguide_samples/blob/20230314_2023.2_updates/pipeline-orchestrators/orchestration_sdk_simple_tutorial).\n",
    "\n",
    "## Pipeline Orchestrations API Tutorial\n",
    "\n",
    "This tutorial provides a quick set of methods and examples regarding Wallaroo Connections and Wallaroo ML Workload Orchestration.  For full details, see the Wallaroo Documentation site.\n",
    "\n",
    "Wallaroo provides Data Connections and ML Workload Orchestrations to provide organizations with a method of creating and managing automated tasks that can either be run on demand or a regular schedule.\n",
    "\n",
    "## Definitions\n",
    "\n",
    "* **Orchestration**: A set of instructions written as a python script with a requirements library.  Orchestrations are uploaded to the Wallaroo instance as a .zip file.\n",
    "* **Task**: An implementation of an orchestration.  Tasks are run either once when requested, on a repeating schedule, or as a service.\n",
    "* **Connection**: Definitions set by MLOps engineers that are used by other Wallaroo users for connection information to a data source.  Usually paired with orchestrations.\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "The tutorial will demonstrate the following:\n",
    "\n",
    "1. Create a workspace and pipeline with a sample model.\n",
    "1. Upload Wallaroo ML Workload Orchestration through the Wallaroo MLOps API.\n",
    "1. List available orchestrations through the Wallaroo MLOps API.\n",
    "1. Run the orchestration once as a Run Once Task through the Wallaroo MLOps API and verify that the information was saved the pipeline logs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67e1bb26",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* An installed Wallaroo instance.\n",
    "* The following Python libraries installed.  These are included by default in a Wallaroo instance's JupyterHub service.\n",
    "  * `os`\n",
    "  * [`wallaroo`](https://pypi.org/project/wallaroo/): The Wallaroo SDK. Included with the Wallaroo JupyterHub service by default.\n",
    "  * [`pandas`](https://pypi.org/project/pandas/): Pandas, mainly used for Pandas DataFrame\n",
    "  * [`pyarrow`](https://pypi.org/project/pyarrow/): PyArrow for Apache Arrow support"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b09330-0408-45eb-b321-b48b65041789",
   "metadata": {},
   "source": [
    "## Initial Steps\n",
    "\n",
    "For this tutorial, we'll create a workspace, upload our sample model and deploy a pipeline.  We'll perform some quick sample inferences to verify that everything it working.\n",
    "\n",
    "### Load Libraries\n",
    "\n",
    "Here we'll import the various libraries we'll use for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43ee5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError, RequiredAttributeMissing\n",
    "\n",
    "# to display dataframe tables\n",
    "from IPython.display import display\n",
    "# used to display dataframe information without truncating\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import pyarrow as pa\n",
    "\n",
    "import os\n",
    "# Used for the Wallaroo SDK version 2023.1\n",
    "os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "import time\n",
    "\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae645fd0",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance\n",
    "\n",
    "The first step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  If logging in externally, update the `wallarooPrefix` and `wallarooSuffix` variables with the proper DNS information.  For more information on Wallaroo DNS settings, see the [Wallaroo DNS Integration Guide](https://docs.wallaroo.ai/wallaroo-operations-guide/wallaroo-configuration/wallaroo-dns-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9d19a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "# wl = wallaroo.Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1d87a1b",
   "metadata": {},
   "source": [
    "### API URL\n",
    "\n",
    "The variable `APIURL` is used to specify the connection to the Wallaroo instance's MLOps API URL, and is composed of the Wallaroo DNS prefix and suffix.  For full details, see the [Wallaroo API Connection Guide\n",
    "](https://staging.docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-api-guide/wallaroo-mlops-connection-guide/).\n",
    "\n",
    "The variables `wallarooPrefix` and `wallarooSuffix` variables will be used to derive the API url.  For example, if the Wallaroo Prefix is `doc-test` and the url is `wallaroo.ai`, then the MLOps API URL would be `doc-test.api.example.com/v1/api/{request}`.\n",
    "\n",
    "Set the Wallaroo Prefix and Suffix in the code segment below based on your Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06a981ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variables for later steps\n",
    "\n",
    "wallarooPrefix = \"doc-test\"\n",
    "# wallarooPrefix = \"product-uat-ee\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "APIURL = f\"https://{wallarooPrefix}.api.{wallarooSuffix}\"\n",
    "\n",
    "workspace_name = 'apiorchestrationworkspace'\n",
    "pipeline_name = 'apipipeline'\n",
    "model_name = 'apiorchestrationmodel'\n",
    "model_file_name = './models/rf_model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "209c50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c46c722",
   "metadata": {},
   "source": [
    "### Helper Methods\n",
    "\n",
    "The following helper methods are used to either create or get workspaces, pipelines, and connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0361a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods to retrieve workspaces and pipelines\n",
    "\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "def get_connection(name, connection_type, connection_arguments):\n",
    "    try:\n",
    "        connection = wl.get_connection(name)\n",
    "    except RequiredAttributeMissing:\n",
    "        connection =wl.create_connection(name, \n",
    "                  connection_type, \n",
    "                  connection_arguments)\n",
    "    return connection\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98b78cf9",
   "metadata": {},
   "source": [
    "### Create the Workspace and Pipeline\n",
    "\n",
    "We'll now create our workspace and pipeline for the tutorial.  If this tutorial has been run previously, then this will retrieve the existing ones with the assumption they're for us with this tutorial.\n",
    "\n",
    "We'll set the retrieved workspace as the current workspace in the SDK, so all commands will default to that workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59aa845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "workspace_id = workspace.id()\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fad528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'apiorchestrationworkspace', 'id': 5, 'archived': False, 'created_by': '3aac9f67-3050-4502-915f-fc2f871ee350', 'created_at': '2023-05-16T14:21:22.505757+00:00', 'models': [{'name': 'apiorchestrationmodel', 'versions': 1, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 5, 16, 14, 21, 24, 176271, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 5, 16, 14, 21, 24, 176271, tzinfo=tzutc())}], 'pipelines': [{'name': 'apipipeline', 'create_time': datetime.datetime(2023, 5, 16, 14, 21, 23, 460351, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d524d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(workspace_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a9fc274",
   "metadata": {},
   "source": [
    "### Upload the Model and Deploy Pipeline\n",
    "\n",
    "We'll upload our model into our sample workspace, then add it as a pipeline step before deploying the pipeline to it's ready to accept inference requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6a69610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>apipipeline</td></tr><tr><th>created</th> <td>2023-05-16 14:21:23.460351+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-16 14:28:06.455835+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>5ebe6b6b-2fa6-43a7-9aa9-587c862a9c0c, 0a47ee10-571e-4d70-b924-c8767f022457, ee90fce5-716e-4f3a-8d57-60b21ebc0b49, dc895034-7647-42c4-be97-2cf3a4d8732d, 379c054f-5998-4695-84c1-14268b9d668b, 5c875ee6-6a77-42b3-ad66-6bf82a45ea17</td></tr><tr><th>steps</th> <td>apiorchestrationmodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'apipipeline', 'create_time': datetime.datetime(2023, 5, 16, 14, 21, 23, 460351, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'apiorchestrationmodel', 'version': 'be6e6570-91e7-4367-b7bd-8ad4dec11aca', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}]}}]\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the model\n",
    "\n",
    "housing_model_control = wl.upload_model(model_name, model_file_name).configure()\n",
    "\n",
    "# Add the model as a pipeline step\n",
    "\n",
    "pipeline.add_model_step(housing_model_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a484796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>apipipeline</td></tr><tr><th>created</th> <td>2023-05-16 14:21:23.460351+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-16 15:58:10.959650+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>4877027a-e027-4ae1-aba4-d0a2a7275e4e, 5ebe6b6b-2fa6-43a7-9aa9-587c862a9c0c, 0a47ee10-571e-4d70-b924-c8767f022457, ee90fce5-716e-4f3a-8d57-60b21ebc0b49, dc895034-7647-42c4-be97-2cf3a4d8732d, 379c054f-5998-4695-84c1-14268b9d668b, 5c875ee6-6a77-42b3-ad66-6bf82a45ea17</td></tr><tr><th>steps</th> <td>apiorchestrationmodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'apipipeline', 'create_time': datetime.datetime(2023, 5, 16, 14, 21, 23, 460351, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'apiorchestrationmodel', 'version': 'be6e6570-91e7-4367-b7bd-8ad4dec11aca', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}]}}]\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deploy the pipeline\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a97aa9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-16 15:58:23.287</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-05-16 15:58:23.287   \n",
       "\n",
       "                                                                                                            in.tensor  \\\n",
       "0  [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0   [718013.7]               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inference sample\n",
    "\n",
    "normal_input = pd.DataFrame.from_records({\"tensor\": [[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]]})\n",
    "result = pipeline.infer(normal_input)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94146dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>apipipeline</td></tr><tr><th>created</th> <td>2023-05-16 14:21:23.460351+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-16 15:58:10.959650+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>4877027a-e027-4ae1-aba4-d0a2a7275e4e, 5ebe6b6b-2fa6-43a7-9aa9-587c862a9c0c, 0a47ee10-571e-4d70-b924-c8767f022457, ee90fce5-716e-4f3a-8d57-60b21ebc0b49, dc895034-7647-42c4-be97-2cf3a4d8732d, 379c054f-5998-4695-84c1-14268b9d668b, 5c875ee6-6a77-42b3-ad66-6bf82a45ea17</td></tr><tr><th>steps</th> <td>apiorchestrationmodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'apipipeline', 'create_time': datetime.datetime(2023, 5, 16, 14, 21, 23, 460351, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'apiorchestrationmodel', 'version': 'be6e6570-91e7-4367-b7bd-8ad4dec11aca', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}]}}]\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8d44dc7",
   "metadata": {},
   "source": [
    "## Wallaroo ML Workload Orchestration Example\n",
    "\n",
    "With the pipeline deployed and our connections set, we will now generate our ML Workload Orchestration.  See the [Wallaroo ML Workload Orchestrations guide](https://staging.docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-ml-workload-orchestration/) for full details.\n",
    "\n",
    "Orchestrations are uploaded to the Wallaroo instance as a ZIP file with the following requirements:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| **User Code** | (*Required*) Python script as `.py` files | If `main.py` exists, then that will be used as the task entrypoint. Otherwise, the **first** `main.py` found in any subdirectory will be used as the entrypoint. |\n",
    "| Python Library Requirements | (*Optional*) `requirements.txt` file in the [requirements file format](https://pip.pypa.io/en/stable/reference/requirements-file-format/).  A standard Python requirements.txt for any dependencies to be provided in the task environment. The Wallaroo SDK will already be present and **should not be included in the requirements.txt**. Multiple requirements.txt files are not allowed. |\n",
    "| Other artifacts | &nbsp; | Other artifacts such as files, data, or code to support the orchestration.\n",
    "\n",
    "For our example, our orchestration will:\n",
    "\n",
    "1. Use the `inference_results_connection` to open a HTTP Get connection to the inference data file and use it in an inference request in the deployed pipeline.\n",
    "1. Submit the inference results to the location specified in the `external_inference_connection`.\n",
    "\n",
    "This sample script is stored in `remote_inference/main.py` with an empty `requirements.txt` file, and packaged into the orchestration as `./remote_inference/remote_inference.zip`.  We'll display the steps in uploading the orchestration to the Wallaroo instance.\n",
    "\n",
    "Note that the orchestration assumes the pipeline is already deployed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c54d9602",
   "metadata": {},
   "source": [
    "### API Upload the Orchestration\n",
    "\n",
    "Orchestrations are uploaded via POST as a `application/octet-stream` with MLOps API route:\n",
    "\n",
    "`/v1/api/orchestration/upload`\n",
    "\n",
    "The following parameters are required:\n",
    "\n",
    "* The upload is POST as a `multipart/form-data`.\n",
    "* Included in the upload is:\n",
    "  * The file with Content-Type as `application/octet-stream`.\n",
    "  * The metadata specifying the workspace id and Content-Type as `application/json`.\n",
    "\n",
    "Once uploaded, the deployment will be prepared and any requirements will be downloaded and installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00e6e6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "\n",
    "url = f\"{APIURL}/v1/api/orchestration/upload\"\n",
    "\n",
    "fp = open(\"./api_inference_orchestration.zip\", \"rb\")\n",
    "\n",
    "metadata = {\n",
    "    \"workspace_id\": workspace_id\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    url,\n",
    "    headers=headers,\n",
    "    files=[(\"file\", (\"api_inference_orchestration.zip\", fp, \"application/octet-stream\")), \n",
    "         (\"metadata\", (\"metadata\", '{\"workspace_id\": 5}', \"application/json\"))],\n",
    ").json()\n",
    "\n",
    "display(response)\n",
    "orchestration_id = response['id']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8efa8c85",
   "metadata": {},
   "source": [
    "### API List Orchestrations\n",
    "\n",
    "A list of orchestrations retrieved via POST MLOps API route:\n",
    "\n",
    "`/v1/api/orchestration/list`\n",
    "\n",
    "The following parameters are required:\n",
    "\n",
    "* **workspace_id**:  The numerical identifier of the workspace associated with the orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3245c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       "  'workspace_id': 5,\n",
       "  'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'name': None,\n",
       "  'file_name': 'api_inference_orchestration.zip',\n",
       "  'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       "  'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'status': 'pending_packaging',\n",
       "  'created_at': '2023-05-16T15:59:02.767417+00:00',\n",
       "  'updated_at': '2023-05-16T15:59:02.767417+00:00'},\n",
       " {'id': '18a45be0-e383-42d9-8c28-06ee7397b306',\n",
       "  'workspace_id': 5,\n",
       "  'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'name': None,\n",
       "  'file_name': 'api_inference_orchestration.zip',\n",
       "  'task_id': '504ecc9a-74a7-4c2f-a41c-ec6be5abdcbe',\n",
       "  'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'status': 'ready',\n",
       "  'created_at': '2023-05-16T15:28:55.331946+00:00',\n",
       "  'updated_at': '2023-05-16T15:29:49.807671+00:00'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "url = f\"{APIURL}/v1/api/orchestration/list\"\n",
    "\n",
    "data = {\n",
    "    'workspace_id': workspace_id\n",
    "}\n",
    "\n",
    "response=requests.post(url, headers=headers, json=data)\n",
    "display(response.json())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06c3b56d",
   "metadata": {},
   "source": [
    "### API Get Orchestration\n",
    "\n",
    "A list of orchestrations retrieved via POST MLOps API route:\n",
    "\n",
    "`/v1/api/orchestration/get_by_id`\n",
    "\n",
    "The following parameters are required:\n",
    "\n",
    "* **id**:  The UUID of the orchestration being retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "406c0c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'pending_packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'pending_packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'packaging'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'fd823818-91cf-4d78-9ec2-f74faa1a05f3',\n",
       " 'workspace_id': 5,\n",
       " 'sha': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       " 'file_name': 'api_inference_orchestration.zip',\n",
       " 'task_id': '46ac1273-3481-458c-822d-fb7cca524b67',\n",
       " 'owner_id': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       " 'status': 'ready'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "url = f\"{APIURL}/v1/api/orchestration/get_by_id\"\n",
    "\n",
    "data = {\n",
    "    'id': orchestration_id\n",
    "}\n",
    "\n",
    "# loop until status is ready\n",
    "status = None\n",
    "\n",
    "while status != 'ready':\n",
    "    response=requests.post(url, headers=headers, json=data).json()\n",
    "    display(response)\n",
    "    status = response['status']\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45beade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>id</th><th>name</th><th>status</th><th>type</th><th>created at</th><th>updated at</th></tr><tr><td>33a2b093-b34f-46f1-9c59-7c4d7c0f3188</td><td>None</td><td>started</td><td>Temporary Run</td><td>2023-16-May 14:23:56</td><td>2023-16-May 14:24:06</td></tr></table>"
      ],
      "text/plain": [
       "[<wallaroo.task.Task at 0x17e589ac0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.list_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf028e54",
   "metadata": {},
   "source": [
    "## Task Management Tutorial\n",
    "\n",
    "Once an Orchestration has the status `ready`, it can be run as a task.  Tasks have three run options.\n",
    "\n",
    "| Type | SDK Call |  How triggered |\n",
    "|---|---|:---|\n",
    "| Once       | `orchestration.run_once(json_args)` | User makes one api call. Task runs once and exits.| Single batch, experimentation. |\n",
    "| Scheduled  | `orchestration.run_scheduled(name, schedule, timeout, json_args)` | User provides schedule. Task runs exits whenever schedule dictates. | Recurrent batch. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de1423fb",
   "metadata": {},
   "source": [
    "### Run Task Once via API\n",
    "\n",
    "We'll do both a Run Once task and generate our Run Once Task from our orchestration.  Orchestrations are started as a run once task with the following request:\n",
    "\n",
    "`v1/api//v1/api/orchestration/task/run_once`\n",
    "\n",
    "The following parameters are required.\n",
    "\n",
    "* **workspace_id**:  The numerical identifier of the workspace associated with the orchestration.\n",
    "* **orch_id**:  The orchestration ID represented by a UUID.\n",
    "* **json**:  The parameters to pass to the task.\n",
    "\n",
    "Tasks are generated and run once with the Orchestration `run_once(arguments)` method.  Any arguments for the orchestration are passed in as a `Dict`.  If there are no arguments, then an empty set `{}` is passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5cf9203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1cb1b550-384f-4476-8619-03e0aca71409'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "data = {\n",
    "    \"workspace_id\": workspace_id,\n",
    "    \"orch_id\": orchestration_id,\n",
    "    \"json\": {}\n",
    "}\n",
    "\n",
    "import datetime\n",
    "task_start = datetime.datetime.now()\n",
    "\n",
    "url=f\"{APIURL}/v1/api/task/run_once\"\n",
    "\n",
    "response=requests.post(url, headers=headers, json=data).json()\n",
    "display(response)\n",
    "task_id = response['id']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dcbc1d4",
   "metadata": {},
   "source": [
    "### Task Status via API\n",
    "\n",
    "The list of tasks in the Wallaroo instance is retrieves through the Wallaroo MLOPs API request:\n",
    "\n",
    "The following parameters are required.\n",
    "\n",
    "* **task**:  The numerical identifier of the workspace associated with the orchestration.\n",
    "* **orch_id**:  The orchestration ID represented by a UUID.\n",
    "* **json**:  The parameters to pass to the task.\n",
    "\n",
    "For this example, the status of the previously created task will be generated, then looped until it has reached status `started`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d070781e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'id': '1cb1b550-384f-4476-8619-03e0aca71409',\n",
       " 'image': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/arbex-orch-deploy',\n",
       " 'image_tag': 'v2023.2.0-main-3228',\n",
       " 'bind_secrets': ['minio'],\n",
       " 'extra_env_vars': {'MINIO_URL': 'http://minio.wallaroo.svc.cluster.local:9000',\n",
       "  'ORCH_OWNER_ID': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'ORCH_SHA': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'TASK_ID': '1cb1b550-384f-4476-8619-03e0aca71409'},\n",
       " 'auth_init': True,\n",
       " 'workspace_id': 5,\n",
       " 'flavor': 'exec_orch_oneshot',\n",
       " 'reap_threshold_secs': 900,\n",
       " 'exec_type': 'job',\n",
       " 'status': 'pending',\n",
       " 'input_data': {},\n",
       " 'killed': False,\n",
       " 'created_at': '2023-05-16T15:59:57.496421+00:00',\n",
       " 'updated_at': '2023-05-16T15:59:57.496421+00:00',\n",
       " 'last_runs': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'id': '1cb1b550-384f-4476-8619-03e0aca71409',\n",
       " 'image': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/arbex-orch-deploy',\n",
       " 'image_tag': 'v2023.2.0-main-3228',\n",
       " 'bind_secrets': ['minio'],\n",
       " 'extra_env_vars': {'MINIO_URL': 'http://minio.wallaroo.svc.cluster.local:9000',\n",
       "  'ORCH_OWNER_ID': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'ORCH_SHA': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'TASK_ID': '1cb1b550-384f-4476-8619-03e0aca71409'},\n",
       " 'auth_init': True,\n",
       " 'workspace_id': 5,\n",
       " 'flavor': 'exec_orch_oneshot',\n",
       " 'reap_threshold_secs': 900,\n",
       " 'exec_type': 'job',\n",
       " 'status': 'pending',\n",
       " 'input_data': {},\n",
       " 'killed': False,\n",
       " 'created_at': '2023-05-16T15:59:57.496421+00:00',\n",
       " 'updated_at': '2023-05-16T15:59:57.496421+00:00',\n",
       " 'last_runs': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'id': '1cb1b550-384f-4476-8619-03e0aca71409',\n",
       " 'image': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/arbex-orch-deploy',\n",
       " 'image_tag': 'v2023.2.0-main-3228',\n",
       " 'bind_secrets': ['minio'],\n",
       " 'extra_env_vars': {'MINIO_URL': 'http://minio.wallaroo.svc.cluster.local:9000',\n",
       "  'ORCH_OWNER_ID': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'ORCH_SHA': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'TASK_ID': '1cb1b550-384f-4476-8619-03e0aca71409'},\n",
       " 'auth_init': True,\n",
       " 'workspace_id': 5,\n",
       " 'flavor': 'exec_orch_oneshot',\n",
       " 'reap_threshold_secs': 900,\n",
       " 'exec_type': 'job',\n",
       " 'status': 'started',\n",
       " 'input_data': {},\n",
       " 'killed': False,\n",
       " 'created_at': '2023-05-16T15:59:57.496421+00:00',\n",
       " 'updated_at': '2023-05-16T16:00:07.961995+00:00',\n",
       " 'last_runs': [{'run_id': '70dd85b7-8e64-47b4-8b3b-ab4811ab222c',\n",
       "   'status': 'running',\n",
       "   'created_at': '2023-05-16T16:00:03.823515+00:00'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "url=f\"{APIURL}/v1/api/task/get_by_id\"\n",
    "\n",
    "data = {\n",
    "    \"id\": task_id\n",
    "}\n",
    "\n",
    "status = None\n",
    "\n",
    "while status != 'started':\n",
    "    response=requests.post(url, headers=headers, json=data).json()\n",
    "    display(response)\n",
    "    status = response['status']\n",
    "    time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bd6a79a",
   "metadata": {},
   "source": [
    "### Task Results\n",
    "\n",
    "We can view the inferences from our logs and verify that new entries were added from our task.  In our case, we'll assume the task once started takes about 1 minute to run (deploy the pipeline, run the inference, undeploy the pipeline).  We'll add in a wait of 1 minute, then display the logs during the time period the task was running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "818b5f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 5, 16, 10, 1, 13, 659194)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-16 16:00:20.381</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-05-16 16:00:20.381   \n",
       "\n",
       "                                                                                                            in.tensor  \\\n",
       "0  [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0   [718013.7]               0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(60)\n",
    "\n",
    "task_end = datetime.datetime.now()\n",
    "display(task_end)\n",
    "\n",
    "pipeline.logs(start_datetime = task_start, end_datetime = task_end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "346d44cc",
   "metadata": {},
   "source": [
    "### Run Task Scheduled via API\n",
    "\n",
    "The other method of using tasks is as a **scheduled run** through the Orchestration `run_scheduled(name, schedule, timeout, json_args)`.  This sets up a task to run on an regular schedule as defined by the `schedule` parameter in the `cron` service format.  For example:\n",
    "\n",
    "```python\n",
    "schedule={'42 * * * *'}\n",
    "```\n",
    "\n",
    "Runs on the 42nd minute of every hour.\n",
    "\n",
    "The Run Scheduled Task request is available at the following address:\n",
    "\n",
    "`/v1/api/task/run_scheduled`\n",
    "\n",
    "And takes the following parameters.\n",
    "\n",
    "* **orch_id** (*String* *Required*): The UUID orchestration ID to create the task from.\n",
    "* **workspace_id**  (*Integer* *Required*):  The numberical identifier for the workspace.\n",
    "* **schedule** (*String* *Required*): The schedule as a single string in `cron` format.\n",
    "* **timeout**(*Integer* *Optional*):  The timeout to complete the task in seconds.\n",
    "* **json** (*String* *Required*): The arguments to pass to the task.\n",
    "\n",
    "For our example, we will create a scheduled task to run every 1 minute, display the inference results, then use the Orchestration `kill` task to keep the task from running any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a06c12ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "data = {\n",
    "    \"workspace_id\": workspace_id,\n",
    "    \"orch_id\": orchestration_id,\n",
    "    \"schedule\": \"*/1 * * * *\",\n",
    "    \"json\": {}\n",
    "}\n",
    "\n",
    "import datetime\n",
    "task_start = datetime.datetime.now()\n",
    "\n",
    "url=f\"{APIURL}/v1/api/task/run_scheduled\"\n",
    "\n",
    "response=requests.post(url, headers=headers, json=data).json()\n",
    "display(response)\n",
    "scheduled_task_id = response['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2f4f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'id': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599',\n",
       " 'image': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/arbex-orch-deploy',\n",
       " 'image_tag': 'v2023.2.0-main-3228',\n",
       " 'bind_secrets': ['minio'],\n",
       " 'extra_env_vars': {'MINIO_URL': 'http://minio.wallaroo.svc.cluster.local:9000',\n",
       "  'ORCH_OWNER_ID': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'ORCH_SHA': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'TASK_ID': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599'},\n",
       " 'auth_init': True,\n",
       " 'workspace_id': 5,\n",
       " 'schedule': '*/1 * * * *',\n",
       " 'reap_threshold_secs': 900,\n",
       " 'status': 'pending',\n",
       " 'input_data': {},\n",
       " 'killed': False,\n",
       " 'created_at': '2023-05-16T16:01:15.947982+00:00',\n",
       " 'updated_at': '2023-05-16T16:01:15.951921+00:00',\n",
       " 'last_runs': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'id': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599',\n",
       " 'image': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/arbex-orch-deploy',\n",
       " 'image_tag': 'v2023.2.0-main-3228',\n",
       " 'bind_secrets': ['minio'],\n",
       " 'extra_env_vars': {'MINIO_URL': 'http://minio.wallaroo.svc.cluster.local:9000',\n",
       "  'ORCH_OWNER_ID': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'ORCH_SHA': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'TASK_ID': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599'},\n",
       " 'auth_init': True,\n",
       " 'workspace_id': 5,\n",
       " 'schedule': '*/1 * * * *',\n",
       " 'reap_threshold_secs': 900,\n",
       " 'status': 'started',\n",
       " 'input_data': {},\n",
       " 'killed': False,\n",
       " 'created_at': '2023-05-16T16:01:15.947982+00:00',\n",
       " 'updated_at': '2023-05-16T16:01:16.456502+00:00',\n",
       " 'last_runs': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loop until the task is started\n",
    "\n",
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "url=f\"{APIURL}/v1/api/task/get_by_id\"\n",
    "\n",
    "data = {\n",
    "    \"id\": scheduled_task_id\n",
    "}\n",
    "\n",
    "status = None\n",
    "\n",
    "while status != 'started':\n",
    "    response=requests.post(url, headers=headers, json=data).json()\n",
    "    display(response)\n",
    "    status = response['status']\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4f3ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 5, 16, 10, 3, 26, 673540)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.tensor</th>\n",
       "      <th>out.variable</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-16 16:03:16.714</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-16 16:02:16.258</td>\n",
       "      <td>[4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]</td>\n",
       "      <td>[718013.7]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  \\\n",
       "0 2023-05-16 16:03:16.714   \n",
       "1 2023-05-16 16:02:16.258   \n",
       "\n",
       "                                                                                                            in.tensor  \\\n",
       "0  [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "1  [4.0, 2.5, 2900.0, 5505.0, 2.0, 0.0, 0.0, 3.0, 8.0, 2900.0, 0.0, 47.6063, -122.02, 2970.0, 5251.0, 12.0, 0.0, 0.0]   \n",
       "\n",
       "  out.variable  check_failures  \n",
       "0   [718013.7]               0  \n",
       "1   [718013.7]               0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the updated results\n",
    "\n",
    "time.sleep(120)\n",
    "\n",
    "task_end = datetime.datetime.now()\n",
    "display(task_end)\n",
    "\n",
    "pipeline.logs(start_datetime = task_start, end_datetime = task_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04232723",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/_cj0q9d51s365wksymljdz4h0000gn/T/ipykernel_10916/4294061735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_workspaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wl' is not defined"
     ]
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "url=f\"{APIURL}/v1/api/task/list\"\n",
    "\n",
    "data = {\n",
    "    \"workspace_id\": workspace_id\n",
    "}\n",
    "\n",
    "response=requests.post(url, headers=headers, json=data).json()\n",
    "display(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58207f04",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "With the tutorial complete, we can undeploy the pipeline and return the resources back to the Wallaroo instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53defd1",
   "metadata": {},
   "source": [
    "### Kill Task via API\n",
    "\n",
    "Started tasks are killed through the following request:\n",
    "\n",
    "`/v1/api/task/kill`\n",
    "\n",
    "And takes the following parameters.\n",
    "\n",
    "* **orch_id** (*String* *Required*): The UUID orchestration ID to create the task from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f234ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'id': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599',\n",
       " 'image': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/arbex-orch-deploy',\n",
       " 'image_tag': 'v2023.2.0-main-3228',\n",
       " 'bind_secrets': ['minio'],\n",
       " 'extra_env_vars': {'MINIO_URL': 'http://minio.wallaroo.svc.cluster.local:9000',\n",
       "  'ORCH_OWNER_ID': '3aac9f67-3050-4502-915f-fc2f871ee350',\n",
       "  'ORCH_SHA': 'd3b93c9f280734106376e684792aa8b4285d527092fe87d89c74ec804f8e169e',\n",
       "  'TASK_ID': 'd81c6e65-3b1f-42d7-8d2f-3cfc0eb51599'},\n",
       " 'auth_init': True,\n",
       " 'workspace_id': 5,\n",
       " 'schedule': '*/1 * * * *',\n",
       " 'reap_threshold_secs': 900,\n",
       " 'status': 'pending_kill',\n",
       " 'input_data': {},\n",
       " 'killed': False,\n",
       " 'created_at': '2023-05-16T16:01:15.947982+00:00',\n",
       " 'updated_at': '2023-05-16T16:01:16.456502+00:00',\n",
       " 'last_runs': [{'run_id': '3ff90356-b7b3-4909-b5c0-963acd19f3f5',\n",
       "   'status': 'success',\n",
       "   'created_at': '2023-05-16T16:02:02.159514+00:00'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieve the authorization token\n",
    "headers = wl.auth.auth_header()\n",
    "\n",
    "url=f\"{APIURL}/v1/api/task/kill\"\n",
    "\n",
    "data = {\n",
    "    \"id\": scheduled_task_id\n",
    "}\n",
    "\n",
    "response=requests.post(url, headers=headers, json=data).json()\n",
    "display(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f33d5d02",
   "metadata": {},
   "source": [
    "## Close Resources\n",
    "\n",
    "With the tutorial complete, we'll verify the pipeline is closed so the resources are assigned back to the Wallaroo instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb96a086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>apipipeline</td></tr><tr><th>created</th> <td>2023-05-16 14:21:23.460351+00:00</td></tr><tr><th>last_updated</th> <td>2023-05-16 15:58:10.959650+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>4877027a-e027-4ae1-aba4-d0a2a7275e4e, 5ebe6b6b-2fa6-43a7-9aa9-587c862a9c0c, 0a47ee10-571e-4d70-b924-c8767f022457, ee90fce5-716e-4f3a-8d57-60b21ebc0b49, dc895034-7647-42c4-be97-2cf3a4d8732d, 379c054f-5998-4695-84c1-14268b9d668b, 5c875ee6-6a77-42b3-ad66-6bf82a45ea17</td></tr><tr><th>steps</th> <td>apiorchestrationmodel</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'apipipeline', 'create_time': datetime.datetime(2023, 5, 16, 14, 21, 23, 460351, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'apiorchestrationmodel', 'version': 'be6e6570-91e7-4367-b7bd-8ad4dec11aca', 'sha': 'e22a0831aafd9917f3cc87a15ed267797f80e2afa12ad7d8810ca58f173b8cc6'}]}}]\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8e812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
