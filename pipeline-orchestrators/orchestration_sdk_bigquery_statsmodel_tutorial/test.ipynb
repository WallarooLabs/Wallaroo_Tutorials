{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'bigquerystatsmodelworkspace', 'id': 6, 'archived': False, 'created_by': 'eafd452e-1b6a-4ca4-aac9-1c1da3ee8301', 'created_at': '2023-05-11T18:51:50.813231+00:00', 'models': [{'name': 'bigquerystatsmodelmodel', 'versions': 2, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 5, 11, 18, 57, 59, 121701, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 5, 11, 18, 51, 53, 252933, tzinfo=tzutc())}], 'pipelines': [{'name': 'bigquerystatsmodelpipeline02', 'create_time': datetime.datetime(2023, 5, 11, 19, 50, 20, 988291, tzinfo=tzutc()), 'definition': '[]'}, {'name': 'bigquerystatsmodelpipeline', 'create_time': datetime.datetime(2023, 5, 11, 18, 51, 52, 266084, tzinfo=tzutc()), 'definition': '[]'}]}\n",
      "\n",
      "Deploying pipeline.\n",
      "bigquerystatsmodelpipeline02\n",
      "\n",
      "{'temp': {0: 0.291304, 1: 0.243333, 2: 0.254167, 3: 0.253333, 4: 0.253333, 5: 0.255833, 6: 0.215833}, 'holiday': {0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}, 'workingday': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0, 6: 1}, 'windspeed': {0: 0.168726, 1: 0.316546, 2: 0.350133, 3: 0.155471, 4: 0.124383, 5: 0.350754, 6: 0.154846}}\n",
      "\n",
      "[1231.2556997246595, 1627.3643469089343, 1674.3769827243134, 1621.9273295873882, 1140.7465817903185, 1211.5223974364667, 1457.1896450382922]\n",
      "\n",
      "                              date  \\\n",
      "0 2023-05-11 20:02:08.732396+00:00   \n",
      "1 2023-05-11 19:59:19.455953+00:00   \n",
      "2 2023-05-11 19:41:22.771550+00:00   \n",
      "3 2023-05-11 19:34:56.549412+00:00   \n",
      "4 2023-05-11 19:24:26.946916+00:00   \n",
      "\n",
      "                                            forecast  \n",
      "0  [1231.2556997246595, 1627.3643469089343, 1674....  \n",
      "1  [1231.2556997246595, 1627.3643469089343, 1674....  \n",
      "2  [1231.2556997246595, 1627.3643469089343, 1674....  \n",
      "3  [1231.2556997246595, 1627.3643469089343, 1674....  \n",
      "4  [1231.2556997246595, 1627.3643469089343, 1674....  \n",
      "\n",
      "Undeploying pipeline.\n"
     ]
    }
   ],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "import pandas as pd\n",
    "import os\n",
    "#Used for the Wallaroo SDK version 2023.1\n",
    "os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "# bigquery library\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import db_dtypes\n",
    "\n",
    "# wl = wallaroo.Client()\n",
    "# get the arguments\n",
    "\n",
    "# wallarooPrefix = \"product-uat-ee\"\n",
    "# wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wallarooPrefix = \"doc-test\"\n",
    "wallarooSuffix = \"wallaroocommunity.ninja\"\n",
    "\n",
    "wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "                    auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "                    auth_type=\"sso\")\n",
    "\n",
    "if wl.in_task():\n",
    "    arguments = wl.task_args()\n",
    "    print(wl.task_args())\n",
    "\n",
    "    if \"workspace_name\" in arguments:\n",
    "        workspace_name = arguments['workspace_name']\n",
    "    else:\n",
    "        workspace_name=\"bigquerystatsmodelworkspace\"\n",
    "\n",
    "    if \"pipeline_name\" in arguments:\n",
    "        pipeline_name = arguments['pipeline_name']\n",
    "    else:\n",
    "        pipeline_name=\"bigquerystatsmodelpipeline\"\n",
    "\n",
    "    if \"bigquery_connection_input_name\" in arguments:\n",
    "        bigquery_connection_input_name = arguments['bigquery_connection_input_name']\n",
    "    else:\n",
    "        bigquery_connection_input_name = \"bigqueryforecastinputs\"\n",
    "\n",
    "    if \"bigquery_connection_output_name\" in arguments:\n",
    "        bigquery_connection_output_name = arguments['bigquery_connection_output_name']\n",
    "    else:\n",
    "        bigquery_connection_output_name = \"bigqueryforecastoutputs\"\n",
    "else:\n",
    "    # we're not in the task, so use the default values\n",
    "    workspace_name = 'bigquerystatsmodelworkspace'\n",
    "    pipeline_name = 'bigquerystatsmodelpipeline02'\n",
    "\n",
    "    bigquery_connection_input_name = \"bigqueryforecastinputs\"\n",
    "    \n",
    "    bigquery_connection_output_name = \"bigqueryforecastoutputs\"\n",
    "    \n",
    "# helper methods to retrieve workspaces and pipelines\n",
    "\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(name)\n",
    "    return pipeline\n",
    "\n",
    "# set the workspace and pipeline\n",
    "workspace = get_workspace(workspace_name)\n",
    "wl.set_current_workspace(workspace)\n",
    "print(wl.get_current_workspace())\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "\n",
    "# deploy the pipeline\n",
    "print(\"\\nDeploying pipeline.\")\n",
    "print(pipeline_name)\n",
    "pipeline.deploy()\n",
    "\n",
    "# get the connections\n",
    "big_query_input_connection = wl.get_connection(name=bigquery_connection_input_name)\n",
    "big_query_output_connection = wl.get_connection(name=bigquery_connection_output_name)\n",
    "\n",
    "# Set the bigquery input and output credentials\n",
    "bigquery_input_credentials = service_account.Credentials.from_service_account_info(\n",
    "    big_query_input_connection.details())\n",
    "\n",
    "bigquery_output_credentials = service_account.Credentials.from_service_account_info(\n",
    "    big_query_output_connection.details())\n",
    "\n",
    "# start the input and output clients\n",
    "bigqueryinputclient = bigquery.Client(\n",
    "    credentials=bigquery_input_credentials, \n",
    "    project=big_query_input_connection.details()['project_id']\n",
    ")\n",
    "bigqueryoutputclient = bigquery.Client(\n",
    "    credentials=bigquery_output_credentials, \n",
    "    project=big_query_output_connection.details()['project_id']\n",
    ")\n",
    "\n",
    "inference_dataframe_input = bigqueryinputclient.query(\n",
    "        f\"\"\"\n",
    "        (select dteday, temp, holiday, workingday, windspeed\n",
    "        FROM {big_query_input_connection.details()['dataset']}.{big_query_input_connection.details()['table']}\n",
    "        ORDER BY dteday DESC LIMIT 7)\n",
    "        ORDER BY dteday\n",
    "        \"\"\"\n",
    "    ).to_dataframe().drop(columns=['dteday'])\n",
    "\n",
    "# convert to a dict, show the first 7 rows\n",
    "print(f\"\\n{inference_dataframe_input.to_dict()}\")\n",
    "\n",
    "# perform the inference and display the result\n",
    "results = pipeline.infer(inference_dataframe_input.to_dict())\n",
    "print(f\"\\n{results[0]['forecast']}\")\n",
    "\n",
    "# Get the output table, then upload the inference results\n",
    "output_table = bigqueryoutputclient.get_table(f\"{big_query_output_connection.details()['dataset']}.{big_query_output_connection.details()['table']}\")\n",
    "\n",
    "job = bigqueryoutputclient.query(\n",
    "        f\"\"\"\n",
    "        INSERT {big_query_output_connection.details()['dataset']}.{big_query_output_connection.details()['table']}\n",
    "        VALUES\n",
    "        (current_timestamp(), \"{results[0]['forecast']}\")\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "# Show the last 5 output inserts \n",
    "# Get the last insert to the output table to verify\n",
    "\n",
    "task_inference_results = bigqueryoutputclient.query(\n",
    "        f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {big_query_output_connection.details()['dataset']}.{big_query_output_connection.details()['table']}\n",
    "        ORDER BY date DESC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "    ).to_dataframe()\n",
    "\n",
    "print(f\"\\n{task_inference_results}\")\n",
    "\n",
    "# close the bigquery clients\n",
    "bigqueryinputclient.close()\n",
    "bigqueryoutputclient.close()\n",
    "\n",
    "# deploy the pipeline\n",
    "print(\"\\nUndeploying pipeline.\")\n",
    "pipeline.undeploy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wallaroosdk202302preview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
