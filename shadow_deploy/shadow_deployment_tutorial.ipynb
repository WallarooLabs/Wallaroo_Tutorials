{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial and the assets can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/shadow_deploy).\n",
    "\n",
    "## Shadow Deployment Tutorial\n",
    "\n",
    "Wallaroo provides a method of testing the same data against two different models or sets of models at the same time through **shadow deployments** otherwise known as **parallel deployments**.  This allows data to be submitted to a pipeline with inferences running on two different sets of models.  Typically this is performed on a model that is known to provide accurate results - the **champion** - and a model that is being tested to see if it provides more accurate or faster responses depending on the criteria known as the **challengers**.  Multiple challengers can be tested against a single champion.\n",
    "\n",
    "As described in the Wallaroo blog post [The What, Why, and How of Model A/B Testing](https://www.wallaroo.ai/blog/the-what-why-and-how-of-a/b-testing):\n",
    "\n",
    "> In data science, A/B tests can also be used to choose between two models in production, by measuring which model performs better in the real world. In this formulation, the control is often an existing model that is currently in production, sometimes called the champion. The treatment is a new model being considered to replace the old one. This new model is sometimes called the challenger....\n",
    "\n",
    "> Keep in mind that in machine learning, the terms experiments and trials also often refer to the process of finding a training configuration that works best for the problem at hand (this is sometimes called hyperparameter optimization).\n",
    "\n",
    "When a shadow deployment is created, only the inference from the champion is returned in the [InferenceResult Object](https://docs.wallaroo.ai/staging.documentation/wallaroo-sdk/wallaroo-sdk-essentials-guide/#inferenceresult-object) `data`, while the result data for the shadow deployments is stored in the [InferenceResult Object](https://docs.wallaroo.ai/staging.documentation/wallaroo-sdk/wallaroo-sdk-essentials-guide/#inferenceresult-object) `shadow_data`.\n",
    "\n",
    "The following tutorial will demonstrate how:\n",
    "\n",
    "* Upload champion and challenger models into a Wallaroo instance.\n",
    "* Create a shadow deployment in a Wallaroo pipeline.\n",
    "* Perform an inference through a pipeline with a shadow deployment.\n",
    "* View the `data` and `shadow_data` results from the InferenceResult Object.\n",
    "* View the pipeline logs and pipeline shadow logs.\n",
    "\n",
    "This tutorial provides the following:\n",
    "\n",
    "* `dev_smoke_test.json`:  Sample test data used for the inference testing.\n",
    "* `models/keras_ccfraud.onnx`:  The champion model.\n",
    "* `models/modelA.onnx`: A challenger model.\n",
    "* `models/xgboost_ccfraud.onnx`: A challenger model.\n",
    "\n",
    "All models are similar to the ones used for the Wallaroo-101 example included in the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "The first step is to import the libraries required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Connect to your Wallaroo instance and save the connection as the variable `wl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables\n",
    "\n",
    "The following variables are used to create or use existing workspaces, pipelines, and upload the models.  Adjust them based on your Wallaroo instance and organization requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_name = 'ccfraud-comparison-demo'\n",
    "pipeline_name = 'cc-shadow'\n",
    "pipeline_name_multi = 'cc-shadow-multi'\n",
    "champion_model_name = 'ccfraud-lstm'\n",
    "champion_model_file = 'models/keras_ccfraud.onnx'\n",
    "shadow_model_01_name = 'ccfraud-xgb'\n",
    "shadow_model_01_file = 'models/xgboost_ccfraud.onnx'\n",
    "shadow_model_02_name = 'ccfraud-rf'\n",
    "shadow_model_02_file = 'models/modelA.onnx'\n",
    "sample_data_file = './smoke_test.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace and Pipeline\n",
    "\n",
    "The following creates or connects to an existing workspace based on the variable `workspace_name`, and creates or connects to a pipeline based on the variable `pipeline_name`.  Note that workspace and pipeline names are not forced to be unique in a Wallaroo instance, and it is recommended to use a organization standard to ensure that users to not connect to the incorrect workspace or pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>cc-shadow</td></tr><tr><th>created</th> <td>2022-10-19 17:52:00.508852+00:00</td></tr><tr><th>last_updated</th> <td>2022-10-19 17:52:00.508852+00:00</td></tr><tr><th>deployed</th> <td>(none)</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td></td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'cc-shadow', 'create_time': datetime.datetime(2022, 10, 19, 17, 52, 0, 508852, tzinfo=tzutc()), 'definition': '[]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "wl.set_current_workspace(workspace)\n",
    "\n",
    "pipeline = get_pipeline(pipeline_name)\n",
    "pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Models\n",
    "\n",
    "The models will be uploaded into the current workspace based on the variable names set earlier and listed as the `champion`, `model2` and `model3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "champion = wl.upload_model(champion_model_name, champion_model_file).configure()\n",
    "model2 = wl.upload_model(shadow_model_01_name, shadow_model_01_file).configure()\n",
    "model3 = wl.upload_model(shadow_model_02_name, shadow_model_02_file).configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Shadow Deployment\n",
    "\n",
    "A shadow deployment is created using the `add_shadow_deploy(champion, challengers[])` method where:\n",
    "\n",
    "* `champion`: The model that will be primarily used for inferences run through the pipeline.  Inference results will be returned through the Inference Object's `data` element.\n",
    "* `challengers[]`: An array of models that will be used for inferences iteratively.  Inference results will be returned through the Inference Object's `shadow_data` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ..... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>cc-shadow</td></tr><tr><th>created</th> <td>2022-10-19 17:52:00.508852+00:00</td></tr><tr><th>last_updated</th> <td>2022-10-19 17:52:01.298216+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>ccfraud-lstm</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'cc-shadow', 'create_time': datetime.datetime(2022, 10, 19, 17, 52, 0, 508852, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'ccfraud-lstm', 'version': '1f7b2360-0d52-4000-b540-244fb33ad706', 'sha': 'bc85ce596945f876256f41515c7501c399fd97ebcb9ab3dd41bf03f8937b4507'}, {'name': 'ccfraud-xgb', 'version': '3e28754a-7bf4-41c8-b46a-b592ae20dfb2', 'sha': '054810e3e3ebbdd34438d9c1a08ed6a6680ef10bf97b9223f78ebf38e14b3b52'}, {'name': 'ccfraud-rf', 'version': 'c2d62c6b-6723-496b-8702-292cfdd2444c', 'sha': '438cd2762590b712106235dc4d635ca50b21304f42ee9529c7acd0b0aecac624'}]}}, {'AuditResults': {'from': 1, 'to': None}}, {'MultiOut': {}}]\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.add_shadow_deploy(champion, [model2, model3])\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Test Inference\n",
    "\n",
    "Using the data from `sample_data_file`, a test inference will be made.  As mentioned earlier, the inference results from the `champion` model will be available in the returned InferenceResult Object's `data` element, while inference results from each of the `challenger` models will be in the returned InferenceResult Object's `shadow_data` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for inference response - this will take up to 45s ........ ok\n"
     ]
    }
   ],
   "source": [
    "response = pipeline.infer_from_file(sample_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InferenceResult({'check_failures': [],\n",
       "  'elapsed': 226951,\n",
       "  'model_name': 'ccfraud-lstm',\n",
       "  'model_version': '1f7b2360-0d52-4000-b540-244fb33ad706',\n",
       "  'original_data': {'tensor': [[1.0678324729342086,\n",
       "                                0.21778102664937624,\n",
       "                                -1.7115145261843976,\n",
       "                                0.6822857209662413,\n",
       "                                1.0138553066742804,\n",
       "                                -0.43350000129006655,\n",
       "                                0.7395859436561657,\n",
       "                                -0.28828395953577357,\n",
       "                                -0.44726268795990787,\n",
       "                                0.5146124987725894,\n",
       "                                0.3791316964287545,\n",
       "                                0.5190619748123175,\n",
       "                                -0.4904593221655364,\n",
       "                                1.1656456468728569,\n",
       "                                -0.9776307444180006,\n",
       "                                -0.6322198962519854,\n",
       "                                -0.6891477694494687,\n",
       "                                0.17833178574255615,\n",
       "                                0.1397992467197424,\n",
       "                                -0.35542206494183326,\n",
       "                                0.4394217876939808,\n",
       "                                1.4588397511627804,\n",
       "                                -0.3886829614721505,\n",
       "                                0.4353492889350186,\n",
       "                                1.7420053483337177,\n",
       "                                -0.4434654615252943,\n",
       "                                -0.15157478906219238,\n",
       "                                -0.26684517248765616,\n",
       "                                -1.454961775612449]]},\n",
       "  'outputs': [{'Float': {'data': [0.001497417688369751],\n",
       "                         'dim': [1, 1],\n",
       "                         'v': 1}}],\n",
       "  'pipeline_name': 'cc-shadow',\n",
       "  'shadow_data': {'ccfraud-rf': [{'Float': {'data': [1.0],\n",
       "                                            'dim': [1, 1],\n",
       "                                            'v': 1}}],\n",
       "                  'ccfraud-xgb': [{'Float': {'data': [0.0005066990852355957],\n",
       "                                             'dim': [1, 1],\n",
       "                                             'v': 1}}]},\n",
       "  'time': 1666201934875})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Pipeline Logs\n",
    "\n",
    "With the inferences complete, we can retrieve the log data from the pipeline with the pipeline `logs` method.  Note that for **each** inference request, the logs return **one entry per model**.  For this example, for one inference request three log entries will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Timestamp</th>\n",
       "                <th>Output</th>\n",
       "                <th>Input</th>\n",
       "                <th>Anomalies</th>\n",
       "            </tr>\n",
       "            \n",
       "        <tr style=\"\">\n",
       "            <td>2022-19-Oct 17:52:14</td>\n",
       "            <td>[array([[0.0005067]])]</td>\n",
       "            <td>[[1.0678324729342086, 0.21778102664937624, -1.7115145261843976, 0.6822857209662413, 1.0138553066742804, -0.43350000129006655, 0.7395859436561657, -0.28828395953577357, -0.44726268795990787, 0.5146124987725894, 0.3791316964287545, 0.5190619748123175, -0.4904593221655364, 1.1656456468728569, -0.9776307444180006, -0.6322198962519854, -0.6891477694494687, 0.17833178574255615, 0.1397992467197424, -0.35542206494183326, 0.4394217876939808, 1.4588397511627804, -0.3886829614721505, 0.4353492889350186, 1.7420053483337177, -0.4434654615252943, -0.15157478906219238, -0.26684517248765616, -1.454961775612449]]</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "\n",
       "        <tr style=\"\">\n",
       "            <td>2022-19-Oct 17:52:14</td>\n",
       "            <td>[array([[1.]])]</td>\n",
       "            <td>[[1.0678324729342086, 0.21778102664937624, -1.7115145261843976, 0.6822857209662413, 1.0138553066742804, -0.43350000129006655, 0.7395859436561657, -0.28828395953577357, -0.44726268795990787, 0.5146124987725894, 0.3791316964287545, 0.5190619748123175, -0.4904593221655364, 1.1656456468728569, -0.9776307444180006, -0.6322198962519854, -0.6891477694494687, 0.17833178574255615, 0.1397992467197424, -0.35542206494183326, 0.4394217876939808, 1.4588397511627804, -0.3886829614721505, 0.4353492889350186, 1.7420053483337177, -0.4434654615252943, -0.15157478906219238, -0.26684517248765616, -1.454961775612449]]</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "\n",
       "        <tr style=\"\">\n",
       "            <td>2022-19-Oct 17:52:14</td>\n",
       "            <td>[array([[0.00149742]])]</td>\n",
       "            <td>[[1.0678324729342086, 0.21778102664937624, -1.7115145261843976, 0.6822857209662413, 1.0138553066742804, -0.43350000129006655, 0.7395859436561657, -0.28828395953577357, -0.44726268795990787, 0.5146124987725894, 0.3791316964287545, 0.5190619748123175, -0.4904593221655364, 1.1656456468728569, -0.9776307444180006, -0.6322198962519854, -0.6891477694494687, 0.17833178574255615, 0.1397992467197424, -0.35542206494183326, 0.4394217876939808, 1.4588397511627804, -0.3886829614721505, 0.4353492889350186, 1.7420053483337177, -0.4434654615252943, -0.15157478906219238, -0.26684517248765616, -1.454961775612449]]</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "[<wallaroo.logs.LogEntry at 0x7f7a97aedbe0>,\n",
       " <wallaroo.logs.LogEntry at 0x7f7a97ae5a00>,\n",
       " <wallaroo.logs.LogEntry at 0x7f7a97ae5eb0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Logs Per Model\n",
    "\n",
    "Another way of displaying the logs would be to specify my model.  The following code will display the log data based based on the model name and the inference output for that specific model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ccfraud-xgb', [array([[0.0005067]])]),\n",
       " ('ccfraud-rf', [array([[1.]])]),\n",
       " ('ccfraud-lstm', [array([[0.00149742]])])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = pipeline.logs()\n",
    "\n",
    "[(log.model_name, log.output) for log in logs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Shadow Deploy Pipeline Logs\n",
    "\n",
    "To view the inputs and results for the shadow deployed models, use the pipeline `logs_shadow_deploy()` method.  The results will be grouped by the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <h2>Shadow Deploy Logs</h2>\n",
       "                <p>\n",
       "                    <em>Logs from a shadow pipeline, grouped by their input.</em>\n",
       "                </p>\n",
       "                <table>\n",
       "                    <tbody>\n",
       "                        \n",
       "                    <tr><td colspan='6'>Log Entry 0</td></tr>\n",
       "                    <tr><td colspan='6'></td></tr>\n",
       "                    <tr>\n",
       "\t\t\t<td>\n",
       "\t\t\t\t<strong><em>Input</em></strong>\n",
       "\t\t\t</td>\n",
       "                        <td colspan='6'>[[1.0678324729342086, 0.21778102664937624, -1.7115145261843976, 0.6822857209662413, 1.0138553066742804, -0.43350000129006655, 0.7395859436561657, -0.28828395953577357, -0.44726268795990787, 0.5146124987725894, 0.3791316964287545, 0.5190619748123175, -0.4904593221655364, 1.1656456468728569, -0.9776307444180006, -0.6322198962519854, -0.6891477694494687, 0.17833178574255615, 0.1397992467197424, -0.35542206494183326, 0.4394217876939808, 1.4588397511627804, -0.3886829614721505, 0.4353492889350186, 1.7420053483337177, -0.4434654615252943, -0.15157478906219238, -0.26684517248765616, -1.454961775612449]]</td>\n",
       "                    </tr>\n",
       "                \n",
       "                    <tr>\n",
       "                        <td>Model Type</td>\n",
       "                        <td>\n",
       "                            <strong>Model Name</strong>\n",
       "                        </td>\n",
       "                        <td>\n",
       "                            <strong>Output</strong>\n",
       "                        </td>\n",
       "                        <td>\n",
       "                            <strong>Timestamp</strong>\n",
       "                        </td>\n",
       "                        <td>\n",
       "                            <strong>Model Version</strong>\n",
       "                        </td>\n",
       "                        <td>\n",
       "                            <strong>Elapsed</strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td><strong><em>Primary</em></strong></td>\n",
       "                        <td>ccfraud-lstm</td>\n",
       "                        <td>[array([[0.00149742]])]</td>\n",
       "                        <td>2022-10-19T17:52:14.875000</td>\n",
       "                        <td>1f7b2360-0d52-4000-b540-244fb33ad706</td>\n",
       "                        <td>226951</td>\n",
       "                    </tr>\n",
       "                \n",
       "                    <tr>\n",
       "                        <td><strong><em>Challenger</em></strong></td>\n",
       "                        <td>ccfraud-rf</td>\n",
       "                        <td>[{'Float': {'v': 1, 'dim': [1, 1], 'data': [1.0]}}]</td>\n",
       "                        <td colspan=3></td>\n",
       "                    </tr>\n",
       "                \n",
       "                    <tr>\n",
       "                        <td><strong><em>Challenger</em></strong></td>\n",
       "                        <td>ccfraud-xgb</td>\n",
       "                        <td>[{'Float': {'v': 1, 'dim': [1, 1], 'data': [0.0005066990852355957]}}]</td>\n",
       "                        <td colspan=3></td>\n",
       "                    </tr>\n",
       "                \n",
       "                    </tbody>\n",
       "                <table>\n",
       "            "
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = pipeline.logs_shadow_deploy()\n",
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy the Pipeline\n",
    "\n",
    "With the tutorial complete, we undeploy the pipeline and return the resources back to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for undeployment - this will take up to 45s .................................... ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>cc-shadow</td></tr><tr><th>created</th> <td>2022-10-19 17:52:00.508852+00:00</td></tr><tr><th>last_updated</th> <td>2022-10-19 17:52:01.298216+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>steps</th> <td>ccfraud-lstm</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'cc-shadow', 'create_time': datetime.datetime(2022, 10, 19, 17, 52, 0, 508852, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'ccfraud-lstm', 'version': '1f7b2360-0d52-4000-b540-244fb33ad706', 'sha': 'bc85ce596945f876256f41515c7501c399fd97ebcb9ab3dd41bf03f8937b4507'}, {'name': 'ccfraud-xgb', 'version': '3e28754a-7bf4-41c8-b46a-b592ae20dfb2', 'sha': '054810e3e3ebbdd34438d9c1a08ed6a6680ef10bf97b9223f78ebf38e14b3b52'}, {'name': 'ccfraud-rf', 'version': 'c2d62c6b-6723-496b-8702-292cfdd2444c', 'sha': '438cd2762590b712106235dc4d635ca50b21304f42ee9529c7acd0b0aecac624'}]}}, {'AuditResults': {'from': 1, 'to': None}}, {'MultiOut': {}}]\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
