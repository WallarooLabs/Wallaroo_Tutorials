{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c18c8461-a00a-4a16-b3d7-2dee9187f672",
   "metadata": {},
   "source": [
    "## Scikit-Learn Logistic Regression\n",
    "\n",
    "The following example will:\n",
    "\n",
    "* Set the input and output schemas.\n",
    "* Upload a SKLearn Logistic Regression model to Wallaroo.\n",
    "* Deploy a pipeline with the uploaded SKLearn model as a pipeline step.\n",
    "* Perform a test inference.\n",
    "* Undeploy the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3436bb69-bb45-4d18-bc19-d82f76ae9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import wallaroo\n",
    "from wallaroo.pipeline   import Pipeline\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "from wallaroo.framework import Framework\n",
    "\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0783db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log into the following URL in a web browser:\n",
      "\n",
      "\thttps://keycloak.autoscale-uat-ee.wallaroo.dev/auth/realms/master/device?user_code=GWEK-NNCP\n",
      "\n",
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "wl = wallaroo.Client()\n",
    "\n",
    "# wallarooPrefix = \"\"\n",
    "# wallarooSuffix = \"autoscale-uat-ee.wallaroo.dev\"\n",
    "\n",
    "# wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}api.{wallarooSuffix}\", \n",
    "#                     auth_endpoint=f\"https://{wallarooPrefix}keycloak.{wallarooSuffix}\", \n",
    "#                     auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170bf187-321c-45ea-867a-0cc2879b0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "prefix = \"sklearn-kmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df649fa-329a-41c9-a5e6-6676383f1330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sklearn-kmeans-jch', 'id': 34, 'archived': False, 'created_by': 'd9a72bd9-2a1c-44dd-989f-3c7c15130885', 'created_at': '2023-06-27T22:01:20.995281+00:00', 'models': [{'name': 'sklearn-kmeans', 'versions': 3, 'owner_id': '\"\"', 'last_update_time': datetime.datetime(2023, 7, 5, 14, 53, 37, 366702, tzinfo=tzutc()), 'created_at': datetime.datetime(2023, 6, 27, 22, 1, 26, 539571, tzinfo=tzutc())}], 'pipelines': [{'name': 'sklearn-kmeans-pipeline', 'create_time': datetime.datetime(2023, 6, 27, 22, 1, 35, 606699, tzinfo=tzutc()), 'definition': '[]'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = get_workspace(f\"{prefix}-jch\")\n",
    "wl.set_current_workspace(workspace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a7ab7eb-90de-4e94-90d5-316e13eae5ab",
   "metadata": {},
   "source": [
    "## Data & Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1167694d-d0ac-4432-9fde-4ba7a5e65846",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = pa.schema([\n",
    "    pa.field('inputs', pa.list_(pa.float64(), list_size=4))\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('predictions', pa.int32())\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af676365-ebc8-48ce-b008-389ea3af91cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3700515d-f91c-481f-a495-29ad82cab91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for model conversion... It may take up to 10.0min.\n",
      "Model is Pending conversion........Converting..........Ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'sklearn-kmeans', 'version': 'cb9e5d91-a01a-4dc3-bcee-3e4949959779', 'file_name': 'model-auto-conversion_sklearn_kmeans.pkl', 'image_path': 'proxy.replicated.com/proxy/wallaroo/ghcr.io/wallaroolabs/mlflow-deploy:v2023.3.0-main-3466', 'last_update_time': datetime.datetime(2023, 7, 5, 14, 56, 24, 691475, tzinfo=tzutc())}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = wl.upload_model(f\"{prefix}\", \n",
    "                        'models/model-auto-conversion_sklearn_kmeans.pkl', \n",
    "                        framework=Framework.SKLEARN, \n",
    "                        input_schema=input_schema, \n",
    "                        output_schema=output_schema)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47fcab28-dce9-4385-802c-70a8f48fec38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure model and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a709f2c-1332-4984-9cf8-87c6328d6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = DeploymentConfigBuilder() \\\n",
    "    .cpus(0.25).memory('1Gi') \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ecc0a18-5912-4052-98a7-074b9db350b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 90s ........... ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.7.5',\n",
       "   'name': 'engine-889d9c745-qk6lw',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'sklearn-kmeans-pipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'sklearn-kmeans',\n",
       "      'version': 'cb9e5d91-a01a-4dc3-bcee-3e4949959779',\n",
       "      'sha': 'b378a614854619dd573ec65b9b4ac73d0b397d50a048e733d96b68c5fdbec896',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.5.5',\n",
       "   'name': 'engine-lb-584f54c899-brj9z',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': [{'ip': '10.244.0.206',\n",
       "   'name': 'engine-sidekick-sklearn-kmeans-116-f6b696c89-bbn7h',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'statuses': '\\n'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_name = f\"{prefix}-pipeline\"\n",
    "pipeline = wl.build_pipeline(pipeline_name)\n",
    "pipeline.add_model_step(model)\n",
    "\n",
    "pipeline.deploy(deployment_config=deployment_config)\n",
    "pipeline.status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60cb4aa0-601d-4556-a3f8-cdc59e758add",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "SKLearn models must have all of the data as one line to prevent columns from being read out of order when submitting in JSON.  The following will take in the data, convert the rows into a single `inputs` for the table, then perform the inference.  From the `output_schema` we have defined the output as `predictions` which will be displayed in our inference result output as `out.predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eab3c59-c7a2-4e79-a468-e5bcb65d916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('data/test-sklearn-kmeans.json')\n",
    "data\n",
    "\n",
    "# pipeline.infer_from_file('data/test-sklearn-kmeans.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02640e52-4d0b-4bb2-80e1-29231f0865f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.1, 3.5, 1.4, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4.9, 3.0, 1.4, 0.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 inputs\n",
       "0  [5.1, 3.5, 1.4, 0.2]\n",
       "1  [4.9, 3.0, 1.4, 0.2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({\"inputs\": data[:2].values.tolist()})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e0314a1-ffb2-49e7-b85c-d80ff9143e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.inputs</th>\n",
       "      <th>out.predictions</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-05 15:02:15.030</td>\n",
       "      <td>[5.1, 3.5, 1.4, 0.2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-05 15:02:15.030</td>\n",
       "      <td>[4.9, 3.0, 1.4, 0.2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time             in.inputs  out.predictions  \\\n",
       "0 2023-07-05 15:02:15.030  [5.1, 3.5, 1.4, 0.2]                1   \n",
       "1 2023-07-05 15:02:15.030  [4.9, 3.0, 1.4, 0.2]                1   \n",
       "\n",
       "   check_failures  \n",
       "0               0  \n",
       "1               0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.infer(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc5a2e-266f-4da8-a88d-1733aca72f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
