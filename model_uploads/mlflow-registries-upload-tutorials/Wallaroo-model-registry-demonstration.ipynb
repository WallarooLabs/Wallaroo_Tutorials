{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial can be downloaded as part of the [Wallaroo Tutorials repository](https://github.com/WallarooLabs/Wallaroo_Tutorials/tree/main/model_uploads/mlflow-registries-upload-tutorials).\n",
    "\n",
    "## MLFLow Registry Model Upload Demonstration\n",
    "\n",
    "Wallaroo users can register their trained machine learning models from a model registry into their Wallaroo instance and perform inferences with it through a Wallaroo pipeline.\n",
    "\n",
    "This guide details how to add ML Models from a model registry service into a Wallaroo instance.\n",
    "\n",
    "## Artifact Requirements\n",
    "\n",
    "Models are uploaded to the Wallaroo instance as the specific **artifact** - the \"file\" or other data that represents the file itself.  This **must** comply with the [Wallaroo model requirements framework and version](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/) or it will not be deployed.\n",
    "\n",
    "This tutorial will:\n",
    "\n",
    "* Create a Wallaroo workspace and pipeline.\n",
    "* Show how to connect a Wallaroo Registry that connects to a Model Registry Service.\n",
    "* Use the registry connection details to upload a sample model to Wallaroo.\n",
    "* Perform a sample inference.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* A Wallaroo version 2023.2.1 or above instance.\n",
    "* A Model (aka Artifact) Registry Service\n",
    "\n",
    "### References\n",
    "\n",
    "* [Wallaroo SDK Essentials Guide: Pipeline Management](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline/)\n",
    "* [Python Models](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-model-uploads/wallaroo-sdk-model-upload-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Steps\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "We'll start with importing the libraries we need for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.2.1+903061ec8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wallaroo\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "from wallaroo.framework import Framework\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#import os\n",
    "# import json\n",
    "import pyarrow as pa\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Wallaroo Instance through the User Interface\n",
    "\n",
    "The next step is to connect to Wallaroo through the Wallaroo client.  The Python library is included in the Wallaroo install and available through the Jupyter Hub interface provided with your Wallaroo environment.\n",
    "\n",
    "This is accomplished using the `wallaroo.Client()` command, which provides a URL to grant the SDK permission to your specific Wallaroo environment.  When displayed, enter the URL into a browser and confirm permissions.  Store the connection into a variable that can be referenced later.\n",
    "\n",
    "If logging into the Wallaroo instance through the internal JupyterHub service, use `wl = wallaroo.Client()`.  For more information on Wallaroo Client settings, see the [Client Connection guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-client/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Wallaroo Registry\n",
    "\n",
    "The Wallaroo Registry stores the URL and authentication token to the Model Registry service, with the assigned name.  Note that in this demonstration all URLs and token are examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = wl.create_model_registry(name=\"JamieRegistry\", \n",
    "                                    token=\"abcdefg\", \n",
    "                                    url=\"https://model.registry.wallaroo.ai\"\n",
    "                                    )\n",
    "registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Schemas\n",
    "\n",
    "To upload a ML Model to Wallaroo, the input and output schemas must be defined in `pyarrow.lib.Schema` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wallaroo.framework import Framework\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "input_schema = pa.schema([\n",
    "    pa.field('inputs', pa.list_(pa.float64(), list_size=4))\n",
    "])\n",
    "\n",
    "output_schema = pa.schema([\n",
    "    pa.field('predictions', pa.int32()),\n",
    "    pa.field('probabilities', pa.list_(pa.float64(), list_size=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a Model from a Registry\n",
    "\n",
    "Models uploaded to the Wallaroo workspace are uploaded from a MLFlow Registry with the `Wallaroo.Registry.upload` method.\n",
    "\n",
    "#### Upload a Model from a Registry Parameters\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "|---|---|---|\n",
    "| `name` | string (*Required*) | The name to assign the model once uploaded.  Model names are unique within a workspace.  Models assigned the same name as an existing model will be uploaded as a new model version.|\n",
    "| `path` | string (*Required*) | The full path to the model artifact in the registry. |\n",
    "| `framework` | string (*Required*) | The Wallaroo model `Framework`.  See [Model Uploads and Registrations Supported Frameworks]({{<ref \"wallaroo-sdk-model-uploads#supported-frameworks\">}}) |\n",
    "|`input_schema` | `pyarrow.lib.Schema` (*Required for non-native runtimes*) | The input schema in Apache Arrow schema format. |\n",
    "|`output_schema` | `pyarrow.lib.Schema` (*Required for non-native runtimes*) | The output schema in Apache Arrow schema format. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registry.upload_model(\n",
    "  name=\"sample-sklearn-model\", \n",
    "  path=\"https://model.registry.wallaroo.ai/api/2.0/dbfs/read?path=/databricks/mlflow-registry/9168792a16cb40a88de6959ef31e42a2/models/âˆšerified-working/model.pkl\", \n",
    "    framework=Framework.SKLEARN,\n",
    "  input_schema=input_schema,\n",
    "  output_schema=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Runtime\n",
    "\n",
    "Once uploaded and converted, the model runtime is derived.  This determines whether to allocate resources to pipeline's native runtime environment or containerized runtime environment.  For more details, see the [Wallaroo SDK Essentials Guide: Pipeline Deployment Configuration guide](https://docs.wallaroo.ai/wallaroo-developer-guides/wallaroo-sdk-guides/wallaroo-sdk-essentials-guide/wallaroo-sdk-essentials-pipelines/wallaroo-sdk-essentials-pipeline-deployment-config/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config().runtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the Model Status\n",
    "\n",
    "Once uploaded, the model will undergo conversion.  The following will loop through the model status until it is ready.  Once ready, it is available for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n",
      "converting\n",
      "converting\n",
      "pending_conversion\n",
      "pending_conversion\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "converting\n",
      "ready\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while model.status() != \"ready\" and model.status() != \"error\":\n",
    "    print(model.status())\n",
    "    time.sleep(3)\n",
    "print(model.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Pipeline\n",
    "\n",
    "The model is uploaded and ready for use.  We'll add it as a step in our pipeline, then deploy the pipeline.  For this example we're allocated 0.5 cpu to the runtime environment and 1 CPU to the containerized runtime environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 90s ........ ok\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from wallaroo.deployment_config import DeploymentConfigBuilder\n",
    "deployment_config = (DeploymentConfigBuilder().cpus(0.5).sidekick_cpus(model, 1).build())\n",
    "\n",
    "pipeline = wl.build_pipeline(\"sklearn-jamie-test-1\")\n",
    "\n",
    "pipeline = pipeline.add_model_step(model)\n",
    "\n",
    "deployment = pipeline.deploy(deployment_config=deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': [],\n",
       " 'engines': [{'ip': '10.244.2.230',\n",
       "   'name': 'engine-76b8d9d6f9-7c627',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'sklearn-jamie-test-1',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'jamie-reg-12',\n",
       "      'version': 'd0784ad9-61d0-403c-9337-79da6d049255',\n",
       "      'sha': '5f4c25b0b564ab9fe0ea437424323501a460aa74463e81645a6419be67933ca4',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.244.0.103',\n",
       "   'name': 'engine-lb-584f54c899-ppkms',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': []}],\n",
       " 'sidekicks': [{'ip': '10.244.2.229',\n",
       "   'name': 'engine-sidekick-jamie-reg-12-14-67cb7f8b86-sv5dd',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'details': [],\n",
       "   'statuses': '\\n'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference\n",
    "\n",
    "A sample inference will be run.  First the pandas DataFrame used for the inference is created, then the inference run through the pipeline's `infer` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.1, 3.5, 1.4, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4.9, 3.0, 1.4, 0.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 inputs\n",
       "0  [5.1, 3.5, 1.4, 0.2]\n",
       "1  [4.9, 3.0, 1.4, 0.2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris(as_frame=True)\n",
    "\n",
    "X = data['data'].values\n",
    "dataframe = pd.DataFrame({\"inputs\": data['data'][:2].values.tolist()})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>in.inputs</th>\n",
       "      <th>out.predictions</th>\n",
       "      <th>out.probabilities</th>\n",
       "      <th>check_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-14 21:55:22.827</td>\n",
       "      <td>[5.1, 3.5, 1.4, 0.2]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.981814913291491, 0.018185072312411506, 1.43...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-14 21:55:22.827</td>\n",
       "      <td>[4.9, 3.0, 1.4, 0.2]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9717552971628304, 0.02824467272952288, 3.01...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time             in.inputs  out.predictions  \\\n",
       "0 2023-07-14 21:55:22.827  [5.1, 3.5, 1.4, 0.2]                0   \n",
       "1 2023-07-14 21:55:22.827  [4.9, 3.0, 1.4, 0.2]                0   \n",
       "\n",
       "                                   out.probabilities  check_failures  \n",
       "0  [0.981814913291491, 0.018185072312411506, 1.43...               0  \n",
       "1  [0.9717552971628304, 0.02824467272952288, 3.01...               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment.infer(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undeploy Pipelines\n",
    "\n",
    "With the tutorial complete, the pipeline is undeployed to return the resources back to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.undeploy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
