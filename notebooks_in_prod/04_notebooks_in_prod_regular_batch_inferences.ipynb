{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on this tutorial's setup and process, see `00_Introduction.ipynb`.\n",
    "\n",
    "# Stage 4: Regular Batch Inference\n",
    "\n",
    "In Stage 3: Deploy the Model in Wallaroo, the housing model created and tested in Stage 2: Training Process Automation Setup was uploaded to a Wallaroo instance and added to the pipeline `housing-pipe` in the workspace `housepricing`.  This pipeline can be deployed at any point and time and used with new inferences.\n",
    "\n",
    "For the purposes of this demo, let's say that every month we find the newly entered and still-unsold houses and predict their sale price.\n",
    "\n",
    "The predictions are entered into a staging table, for further inspection before being joined to the primary housing data table.\n",
    "\n",
    "We show this as a notebook, but this can also be scripted and scheduled, using CRON or some other process.\n",
    "\n",
    "## Resources\n",
    "\n",
    "The following resources are used as part of this tutorial:\n",
    "\n",
    "* **data**\n",
    "  * `data/seattle_housing_col_description.txt`: Describes the columns used as part data analysis.\n",
    "  * `data/seattle_housing.csv`: Sample data of the Seattle, Washington housing market between 2014 and 2015.\n",
    "* **code**\n",
    "  * `postprocess.py`: Formats the data after inference by the model is complete.\n",
    "  * `preprocess.py`: Formats the incoming data for the model.\n",
    "  * `simdb.py`: A simulated database to demonstrate sending and receiving queries.\n",
    "  * `wallaroo_client.py`: Additional methods used with the Wallaroo instance to create workspaces, etc.\n",
    "* **models**\n",
    "  * `housing_model_xgb.onnx`: Model created in Stage 2: Training Process Automation Setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "This process will use the following steps:\n",
    "\n",
    "* [Connect to Wallaroo](#connect-to-wallaroo): Connect to the Wallaroo instance and the `housepricing` workspace.\n",
    "* [Deploy the Pipeline](#deploy-the-pipeline): Deploy the pipeline to prepare it to run inferences.\n",
    "* [Read In New House Listings](#read-in-new-house-listings): Read in the previous month's house listings and submit them to the pipeline for inference.\n",
    "* [Send Predictions to Results Staging Table](#send-predictions-to-results-staging-table): Add the inference results to the results staging table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Wallaroo\n",
    "\n",
    "Connect to the Wallaroo instance and set the `housepricing` workspace as the current workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import wallaroo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import simdb # module for the purpose of this demo to simulate pulling data from a database\n",
    "\n",
    "from wallaroo_client import get_workspace\n",
    "\n",
    "# used to display dataframe information without truncating\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login through local Wallaroo instance\n",
    "\n",
    "wl = wallaroo.Client()\n",
    "\n",
    "# SSO login through keycloak\n",
    "\n",
    "# wallarooPrefix = \"YOUR PREFIX\"\n",
    "# wallarooSuffix = \"YOUR PREFIX\"\n",
    "\n",
    "# wl = wallaroo.Client(api_endpoint=f\"https://{wallarooPrefix}.api.{wallarooSuffix}\", \n",
    "#                     auth_endpoint=f\"https://{wallarooPrefix}.keycloak.{wallarooSuffix}\", \n",
    "#                     auth_type=\"sso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrow Support\n",
    "\n",
    "As of the 2023.1 release, Wallaroo provides support for dataframe and Arrow for inference inputs.  This tutorial allows users to adjust their experience based on whether they have enabled Arrow support in their Wallaroo instance or not.\n",
    "\n",
    "If Arrow support has been enabled, `arrowEnabled=True`. If disabled or you're not sure, set it to `arrowEnabled=False`\n",
    "\n",
    "The examples below will be shown in an arrow enabled environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Only set the below to make the OS environment ARROW_ENABLED to TRUE.  Otherwise, leave as is.\n",
    "# os.environ[\"ARROW_ENABLED\"]=\"True\"\n",
    "\n",
    "if \"ARROW_ENABLED\" not in os.environ or os.environ[\"ARROW_ENABLED\"].casefold() == \"False\".casefold():\n",
    "    arrowEnabled = False\n",
    "else:\n",
    "    arrowEnabled = True\n",
    "print(arrowEnabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_workspace = get_workspace(\"housepricing\")\n",
    "_ = wl.set_current_workspace(new_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Pipeline\n",
    "\n",
    "Deploy the `housing-pipe` workspace established in Stage 3: Deploy the Model in Wallaroo (`03_deploy_model.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>housing-pipe</td></tr><tr><th>created</th> <td>2023-02-27 21:00:26.107908+00:00</td></tr><tr><th>last_updated</th> <td>2023-02-27 21:01:46.967774+00:00</td></tr><tr><th>deployed</th> <td>True</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>fbb12aa3-7fa2-4553-9955-3dc7146bcd36, d92c7f3d-0b61-44fa-83e2-264d8a045879, b309144d-b5b0-4ca7-a073-4f4ad4145de7</td></tr><tr><th>steps</th> <td>preprocess</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'housing-pipe', 'create_time': datetime.datetime(2023, 2, 27, 21, 0, 26, 107908, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess', 'version': '06f6fb5b-acb6-4719-b6b2-8091c974ddc6', 'sha': '5df8669368dcd1834f369f8502cbf906ee0e7b731cfa9c19e393424701448be3'}]}}, {'ModelInference': {'models': [{'name': 'housepricemodel', 'version': '6e4eb53d-820d-484e-a78c-f1e4bc809fa6', 'sha': '7404007c88906331c8159c42379f30966a21fd29fe2629049e69541d0083db9a'}]}}, {'ModelInference': {'models': [{'name': 'postprocess', 'version': 'bd4623df-8c58-49a9-ba9c-568be50beef1', 'sha': 'c20e924ba4c9ae5b9b67cf0d72705c7f34995da4c5d9c4963d1591e1780c32bc'}]}}]\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = wl.pipelines_by_name(\"housing-pipe\")[-1]\n",
    "pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In New House Listings\n",
    "\n",
    "From the data store, load the previous month's house listing and submit them to the deployed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from house_listings where date > DATE(DATE(), '-1 month') AND sale_price is NULL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1090, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = simdb.simulate_db_connection()\n",
    "\n",
    "# create the query\n",
    "query = f\"select * from {simdb.tablename} where date > DATE(DATE(), '-1 month') AND sale_price is NULL\"\n",
    "print(query)\n",
    "\n",
    "# read in the data\n",
    "newbatch = pd.read_sql_query(query, conn)\n",
    "newbatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if arrowEnabled is True:\n",
    "    query = {'query': newbatch.to_json()}\n",
    "    result = pipeline.infer(query)\n",
    "    #display(result)\n",
    "    predicted_prices = result[0]['prediction']\n",
    "else:\n",
    "    query = {'query': newbatch.to_json()}\n",
    "    result = pipeline.infer(query)[0]\n",
    "    predicted_prices = result.data()[0]\n",
    "len(predicted_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Predictions to Results Staging Table\n",
    "\n",
    "Take the predicted prices based on the inference results so they can be joined into the `house_listings` table.\n",
    "\n",
    "Once complete, undeploy the pipeline to return the resources back to the Kubernetes environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.DataFrame({\n",
    "    'id': newbatch['id'],\n",
    "    'saleprice_estimate': predicted_prices,\n",
    "})\n",
    "\n",
    "result_table.to_sql('results_table', conn, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>saleprice_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9215400105</td>\n",
       "      <td>508255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1695900060</td>\n",
       "      <td>500198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9545240070</td>\n",
       "      <td>539598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1432900240</td>\n",
       "      <td>270739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6131600075</td>\n",
       "      <td>191304.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  saleprice_estimate\n",
       "0  9215400105            508255.0\n",
       "1  1695900060            500198.0\n",
       "2  9545240070            539598.0\n",
       "3  1432900240            270739.0\n",
       "4  6131600075            191304.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the top of the table for confirmation\n",
    "pd.read_sql_query(\"select * from results_table limit 5\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>name</th> <td>housing-pipe</td></tr><tr><th>created</th> <td>2023-02-27 21:00:26.107908+00:00</td></tr><tr><th>last_updated</th> <td>2023-02-27 21:01:46.967774+00:00</td></tr><tr><th>deployed</th> <td>False</td></tr><tr><th>tags</th> <td></td></tr><tr><th>versions</th> <td>fbb12aa3-7fa2-4553-9955-3dc7146bcd36, d92c7f3d-0b61-44fa-83e2-264d8a045879, b309144d-b5b0-4ca7-a073-4f4ad4145de7</td></tr><tr><th>steps</th> <td>preprocess</td></tr></table>"
      ],
      "text/plain": [
       "{'name': 'housing-pipe', 'create_time': datetime.datetime(2023, 2, 27, 21, 0, 26, 107908, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess', 'version': '06f6fb5b-acb6-4719-b6b2-8091c974ddc6', 'sha': '5df8669368dcd1834f369f8502cbf906ee0e7b731cfa9c19e393424701448be3'}]}}, {'ModelInference': {'models': [{'name': 'housepricemodel', 'version': '6e4eb53d-820d-484e-a78c-f1e4bc809fa6', 'sha': '7404007c88906331c8159c42379f30966a21fd29fe2629049e69541d0083db9a'}]}}, {'ModelInference': {'models': [{'name': 'postprocess', 'version': 'bd4623df-8c58-49a9-ba9c-568be50beef1', 'sha': 'c20e924ba4c9ae5b9b67cf0d72705c7f34995da4c5d9c4963d1591e1780c32bc'}]}}]\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.close()\n",
    "pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, organizations can automate this process.  Other features could be used such as data analysis using Wallaroo assays, or other features such as shadow deployments to test champion and challenger models to find which models provide the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrowtests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dda4bf3640b7fafcd1648658b879b4cc9f6ba6084e8fb356fdaaa1a461d1690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
